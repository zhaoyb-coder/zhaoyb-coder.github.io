<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Raft论文-中文 | 赵宇博的技术博客</title>
    <meta name="generator" content="VuePress 1.9.5">
    <link rel="icon" href="/img/favicon.ico">
    <meta name="description" content="沉淀，静待花开">
    
    <link rel="preload" href="/assets/css/0.styles.2eb69015.css" as="style"><link rel="preload" href="/assets/js/app.e85e8bd5.js" as="script"><link rel="preload" href="/assets/js/2.75aeda74.js" as="script"><link rel="preload" href="/assets/js/27.009e71e1.js" as="script"><link rel="prefetch" href="/assets/js/10.e10c2452.js"><link rel="prefetch" href="/assets/js/11.c368328e.js"><link rel="prefetch" href="/assets/js/12.cfabdd67.js"><link rel="prefetch" href="/assets/js/13.f89c3b99.js"><link rel="prefetch" href="/assets/js/14.b4ca3b35.js"><link rel="prefetch" href="/assets/js/15.16e19980.js"><link rel="prefetch" href="/assets/js/16.f8b3bec5.js"><link rel="prefetch" href="/assets/js/17.b05312ef.js"><link rel="prefetch" href="/assets/js/18.97e23894.js"><link rel="prefetch" href="/assets/js/19.eb105480.js"><link rel="prefetch" href="/assets/js/20.d3fe8ac4.js"><link rel="prefetch" href="/assets/js/21.bd04f23f.js"><link rel="prefetch" href="/assets/js/22.2d33e957.js"><link rel="prefetch" href="/assets/js/23.16b7793b.js"><link rel="prefetch" href="/assets/js/24.02ae4a04.js"><link rel="prefetch" href="/assets/js/25.8dca327d.js"><link rel="prefetch" href="/assets/js/26.87634791.js"><link rel="prefetch" href="/assets/js/3.69bde70c.js"><link rel="prefetch" href="/assets/js/4.24c9ae9d.js"><link rel="prefetch" href="/assets/js/5.6d25220f.js"><link rel="prefetch" href="/assets/js/6.8f03b34d.js"><link rel="prefetch" href="/assets/js/7.549b9c4a.js"><link rel="prefetch" href="/assets/js/8.59452c52.js"><link rel="prefetch" href="/assets/js/9.35ac9493.js">
    <link rel="stylesheet" href="/assets/css/0.styles.2eb69015.css">
  </head>
  <body class="theme-mode-light">
    <div id="app" data-server-rendered="true"><div class="theme-container sidebar-open have-rightmenu"><header class="navbar blur"><div title="目录" class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/img/logo.png" alt="赵宇博的技术博客" class="logo"> <span class="site-name can-hide">赵宇博的技术博客</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/fe/" class="nav-link">前端</a></div><div class="nav-item"><a href="/be/" class="nav-link">后端</a></div><div class="nav-item"><a href="/data/" class="nav-link">数据库专栏</a></div><div class="nav-item"><a href="/k8s/" class="nav-link">k8s专栏</a></div><div class="nav-item"><a href="/dcs/" class="nav-link">分布式专栏</a></div><div class="nav-item"><a href="/more/" class="nav-link router-link-active">随笔</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div> <a href="https://github.com/zhaoyb-coder" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav></div></header> <div class="sidebar-mask"></div> <div class="sidebar-hover-trigger"></div> <aside class="sidebar" style="display:none;"><!----> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">首页</a></div><div class="nav-item"><a href="/fe/" class="nav-link">前端</a></div><div class="nav-item"><a href="/be/" class="nav-link">后端</a></div><div class="nav-item"><a href="/data/" class="nav-link">数据库专栏</a></div><div class="nav-item"><a href="/k8s/" class="nav-link">k8s专栏</a></div><div class="nav-item"><a href="/dcs/" class="nav-link">分布式专栏</a></div><div class="nav-item"><a href="/more/" class="nav-link router-link-active">随笔</a></div><div class="nav-item"><a href="/about/" class="nav-link">关于</a></div> <a href="https://github.com/zhaoyb-coder" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></nav>  <ul class="sidebar-links"><li><a href="/more/251dfe/" class="sidebar-link">分享一次项目压测导致的并发问题</a></li><li><a href="/more/2512fe/" aria-current="page" class="active sidebar-link">Raft论文-中文</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level2"><a href="/more/2512fe/#第一章" class="sidebar-link">第一章</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/more/2512fe/#引言" class="sidebar-link">引言</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/more/2512fe/#第二章" class="sidebar-link">第二章</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/more/2512fe/#动机" class="sidebar-link">动机</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_2-1、利用复制状态机实现容错" class="sidebar-link">2.1、利用复制状态机实现容错</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_2-2-、复制状态机的常用用例" class="sidebar-link">2.2 、复制状态机的常用用例</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_2-3、paxos怎么了" class="sidebar-link">2.3、Paxos怎么了?</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/more/2512fe/#第三章" class="sidebar-link">第三章</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/more/2512fe/#基本raft算法" class="sidebar-link">基本Raft算法</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-1、为可理解性而设计" class="sidebar-link">3.1、为可理解性而设计</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-2、raft概况" class="sidebar-link">3.2、Raft概况</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-3、raft基础" class="sidebar-link">3.3、Raft基础</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-4、首领选举" class="sidebar-link">3.4、首领选举</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-5、日志复制" class="sidebar-link">3.5、日志复制</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-6、安全性" class="sidebar-link">3.6、安全性</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_3-6-1、选举限制" class="sidebar-link">3.6.1、选举限制</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_3-6-2、从以前的任期提交条目" class="sidebar-link">3.6.2、从以前的任期提交条目</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_3-6-3、安全论证" class="sidebar-link">3.6.3、安全论证</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-7、跟随者和候选者崩溃" class="sidebar-link">3.7、跟随者和候选者崩溃</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-8、持续状态和服务器重启" class="sidebar-link">3.8、持续状态和服务器重启</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-9、时间与有效性" class="sidebar-link">3.9、时间与有效性</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-10、领导者转移扩展" class="sidebar-link">3.10、领导者转移扩展</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_3-11、总结" class="sidebar-link">3.11、总结</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/more/2512fe/#第四章" class="sidebar-link">第四章</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/more/2512fe/#群集成员资格更改" class="sidebar-link">群集成员资格更改</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_4-1、安全性" class="sidebar-link">4.1、安全性</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_4-2、有效性" class="sidebar-link">4.2、有效性</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_4-2-1、追赶新的服务器" class="sidebar-link">4.2.1、追赶新的服务器</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_4-2-2、撤销现任领导者" class="sidebar-link">4.2.2、撤销现任领导者</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_4-2-3、中断服务器" class="sidebar-link">4.2.3、中断服务器</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_4-2-4、可用性论证" class="sidebar-link">4.2.4、可用性论证</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_4-3、使用联合共识进行任意配置变化" class="sidebar-link">4.3、使用联合共识进行任意配置变化</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_4-4、系统集成" class="sidebar-link">4.4、系统集成</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_4-5、总结" class="sidebar-link">4.5、总结</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/more/2512fe/#第五章" class="sidebar-link">第五章</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/more/2512fe/#日志压缩" class="sidebar-link">日志压缩</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_5-1、基于内存的状态机快照" class="sidebar-link">5.1、基于内存的状态机快照</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_5-1-1、并发快照" class="sidebar-link">5.1.1、并发快照</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_5-1-2、何时进行快照" class="sidebar-link">5.1.2、何时进行快照</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_5-1-3、实现关系" class="sidebar-link">5.1.3、实现关系</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_5-2、基于磁盘状态机的快照" class="sidebar-link">5.2、基于磁盘状态机的快照</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_5-3、增量清除方法" class="sidebar-link">5.3、增量清除方法</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_5-3-1、日志清除的基础知识" class="sidebar-link">5.3.1、日志清除的基础知识</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_5-3-2、日志结构合并树的基础知识" class="sidebar-link">5.3.2、日志结构合并树的基础知识</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_5-3-3、raft中的日志清理和日志结构合并树" class="sidebar-link">5.3.3、Raft中的日志清理和日志结构合并树</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_5-4、替代方案-基于领导者的方法" class="sidebar-link">5.4、替代方案：基于领导者的方法</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_5-4-1、在日志中存储快照" class="sidebar-link">5.4.1、在日志中存储快照</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_5-4-2、针对非常小的状态机的leader-based方法" class="sidebar-link">5.4.2、针对非常小的状态机的Leader - based方法</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_5-5、总结" class="sidebar-link">5.5、总结</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/more/2512fe/#第六章" class="sidebar-link">第六章</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/more/2512fe/#客户端交互" class="sidebar-link">客户端交互</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_6-1、寻找集群" class="sidebar-link">6.1、寻找集群</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_6-2、路由请求给领导者" class="sidebar-link">6.2、路由请求给领导者</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_6-3、实现可线性化的语义" class="sidebar-link">6.3、实现可线性化的语义</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_6-4、更高效地处理只读查询" class="sidebar-link">6.4、更高效地处理只读查询</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_6-4-1、使用时钟来减少只读查询的消息传递" class="sidebar-link">6.4.1、使用时钟来减少只读查询的消息传递</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_6-5、总结" class="sidebar-link">6.5、总结</a></li></ul></li><li class="sidebar-sub-header level2"><a href="/more/2512fe/#第七章" class="sidebar-link">第七章</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header level3"><a href="/more/2512fe/#raft用户研究" class="sidebar-link">Raft用户研究</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_7-1、研究问题与假设" class="sidebar-link">7.1、研究问题与假设</a></li><li class="sidebar-sub-header level3"><a href="/more/2512fe/#_7-2、关于方法的讨论" class="sidebar-link">7.2、关于方法的讨论</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_7-2-1、参加者" class="sidebar-link">7.2.1、参加者</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_7-2-2、教学" class="sidebar-link">7.2.2、教学</a></li><li class="sidebar-sub-header level4"><a href="/more/2512fe/#_7-2-3、测试理解" class="sidebar-link">7.2.3、测试理解</a></li></ul></li></ul></li></ul> </aside> <div><main class="page"><div class="theme-vdoing-wrapper "><div class="articleInfo-wrap" data-v-06225672><div class="articleInfo" data-v-06225672><ul class="breadcrumbs" data-v-06225672><li data-v-06225672><a href="/" title="首页" class="iconfont icon-home router-link-active" data-v-06225672></a></li> <li data-v-06225672><a href="/more/#随笔" data-v-06225672>随笔</a></li></ul> <div class="info" data-v-06225672><div title="作者" class="author iconfont icon-touxiang" data-v-06225672><a href="https://github.com/zhaoyb-coder" target="_blank" title="作者" class="beLink" data-v-06225672>zhaoyb</a></div> <div title="创建时间" class="date iconfont icon-riqi" data-v-06225672><a href="javascript:;" data-v-06225672>2023-12-15</a></div> <!----></div></div></div> <!----> <div class="content-wrapper"><div class="right-menu-wrapper"><div class="right-menu-margin"><div class="right-menu-title">目录</div> <div class="right-menu-content"></div></div></div> <h1><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAB4AAAAeCAYAAAA7MK6iAAAAAXNSR0IArs4c6QAABGpJREFUSA3tVVtoXFUU3fvOI53UlmCaKIFmwEhsE7QK0ipFEdHEKpXaZGrp15SINsXUWvBDpBgQRKi0+KKoFeJHfZA+ED9KKoIU2gYD9UejTW4rVIzm0VSTziPzuNu1z507dibTTjL4U/DAzLn3nL3X2o91ziX6f9wMFdh6Jvbm9nNSV0msViVO6tN1Rm7NMu2OpeJ9lWBUTDxrJbYTS0hInuwciu9eLHlFxCLCZEk3MegsJmZ5K/JD6t7FkFdEvGUo1g7qJoG3MHImqRIn8/nzY1K9UPKKiJmtnUqHVE3Gbuay6vJE/N2FEmuxFjW2nUuE0yQXRRxLiTUAzs36zhZvOXJPdX850EVnnLZkB8prodQoM5JGj7Xk2mvC7JB8tG04Ef5PiXtG0UtxupRQSfTnBoCy554x18yJHI6I+G5Eru4LHmPJZEQsrvPUbMiA8G/WgMK7w7I+ez7++o2ANfbrjvaOl1tFMs+htG3IrZH9/hDX1Pr8Tc0UvH8tcX29KzAgIGcEkINyW5BF9x891hw6VYqgJHEk0huccS7vh3C6gTiODL+26huuBtbct8eZnqLML8PkxGYpuPZBqtqwkSjgc4mB5gbgig5i+y0UDK35LMxXisn9xQtK+nd26gTIHsHe/oblK/b29fUmN/8Y+9jAQrnBp56m1LcDlDp9irKTExSKduXJVWSqdBMA08pEJnEIOB3FPPMybu/oeV8zFeYN3xx576Q6RH+VmplE4ncQV5v+5rzSoyOU7PuEAg8g803PwBJ0CExno/jcMbN8tONYeOmHiuUNryvm3fRUy4tMPVLdAGkUhNWuggGrJcXPv+ouCjz0MKUHz1J2/E8IC9nqTabcxgaBYM0hPhD5Y65FsbxRQKxCQrDjDctW7PUM3HuZunFyifSAqEfuzCp48Il24luWUWZoyJCaPR82jE0+kFA643wRFVni4RYSq3ohJO2pZ7B5dO4xkDWbEpossJPLSrPjYID8rS2UHTlvyNxqIGsg674XJJ7vnh5L7PNwC4hh2sjCI96mzszOTpxLF0T7l88Yz7lAuK6OnL8gXLOnTvpzSb22YG8W7us3jSebFHeeqnXRG1vt+MoUM84LQIBmMsCTAcOauTh0T0l0neQK7m2bLMt2mGxU3HYssS0J2cdv5wljlPsrIuZLAG/2DOZIXgCYT8uMGZN+e2kSirfxZOPCsC0f24nTZzspnVn9VePS1Z5vubmAGGXG8ZFno9Hel0yfA5ZPhF7Dh972BQJ2qCpgH67lmWtBYbvk6sz02wjky2vXyz0XErP/kFB619js1BtwfOV4OPRqOQBjy3Qbk18vigUPPSD5ceHnwck7W9bhAqZdd7SuG7w4/P2F/GaJh8c7e9qgow+Q7cGBo+98WsLkuktFqiZabtXuQTu/Y5ETbR0v7tNSFnvrmu6pjdoan2KjMu8q/Hmj1EfCO2ZGfEIbIXKUlw8qaX9/b2oeSJmFksSeT/Fn0V3nSypChh4Gjh74ybO9aeZ/AN2dwciu2/MhAAAAAElFTkSuQmCC">Raft论文-中文<!----></h1>  <div class="theme-vdoing-content content__default"><h1 id="raft论文-中文"><a href="#raft论文-中文" class="header-anchor">#</a> Raft论文-中文</h1> <h2 id="第一章"><a href="#第一章" class="header-anchor">#</a> 第一章</h2> <h3 id="引言"><a href="#引言" class="header-anchor">#</a> 引言</h3> <p>​		当今的数据中心系统和应用运行在高度动态的环境中。它们通过利用额外服务器的资源进行扩展，并根据需求进行增长和收缩。服务器和网络故障也是司空见惯的事情：在现代数据中心中，每年约有2 - 4 %的磁盘驱动器发生故障[ 103 ]，服务器崩溃的频率也很高[ 22 ]，每天有数十条网络链路发生故障[ 31 ]。</p> <p>​		因此，系统在正常运行过程中必须应对来来往往的服务器。它们必须对变化做出反应，并在几秒钟内自动适应；对于人类来说引人注目的外出活动通常是不可接受的。这是当今系统面临的重大挑战；在这样的动态环境中，故障处理、协调、服务发现和配置管理都是非常困难的。</p> <p>​		幸运的是，分布式共识可以帮助应对这些挑战。&quot;共识&quot;允许机器集合作为一个连贯的群体工作，能够在其部分成员的失败中幸存下来。在共识组内，以有原则和证明的方式处理故障。由于共识组具有较高的可用性和可靠性，其他系统组件可以使用共识组作为自身容错的基础。因此，共识在构建可靠的大规模软件系统中起着关键作用。</p> <p>​		当我们开始这项工作时，协商一致的必要性正在变得明朗，但许多制度仍然在与协商一致所能解决的问题作斗争。一些大型系统仍受限于单个协调服务器作为单点故障(例如HDFS [ 81 , 2 ])。许多其他算法包括不安全地处理(例如, MongoDB和Redis )故障的ad hoc复制算法。新的系统很少有可供选择的共识实现方案(最受欢迎的是ZooKeeper )，迫使系统建设者遵守其中的一种或建立自己。</p> <p>​		那些选择执行共识的人通常会转向Paxos [ 48、49 ]。在过去的二十年里，INTRODUCTION主导了共识算法的讨论：大多数共识的实现都是基于Paxos或受其影响，Paxos已成为教授学生共识的主要工具。</p> <p>​		遗憾的是，尽管Paxos试图让自己变得更加平易近人，但却很难理解。此外，其架构需要复杂的变化以支持实际系统，而基于Paxos构建一个完整的系统需要开发多个扩展，而这些扩展的细节尚未公布或达成一致。结果，无论是制度建设者还是学生，都与Paxos斗争。</p> <p>​		另外两个著名的共识算法是ZooKeeper中使用的Viewstamped Replication [ 83、82、66]和Zab [ 42 ]。虽然我们认为这两种算法在结构上都比Paxos用于构建系统的算法要好，但两者都没有明确地提出这个论点；它们不是以简单性或可理解性作为主要目标而设计的。理解和实现这些算法的负担仍然太重。</p> <p>​		这些共识选项中的每一个都是难以理解、难以实施的。不幸的是，当使用已证明的算法实现共识的成本太高时，系统建设者就留下了一个艰难的决定。他们可以完全避免共识，牺牲系统的容错性或一致性，或者开发自己的临时算法，往往会导致不安全行为。而且，当解释和理解共识的成本过高时，并不是所有的指导者都试图教授共识，也不是所有的学生都成功地学习了共识。共识与两阶段承诺一样具有根本性；理想的情况是，像许多学生一样应该学习(尽管达成共识在根本上更加困难)。</p> <p>​		经过与帕克斯本人的斗争，我们开始寻找一种新的共识算法，为系统构建和教育提供更好的基础。我们的方法是不寻常的，因为我们的主要目标是可理解性：我们可以为实际系统定义一个共识算法，并以一种比Paxos更容易学习的方式来描述它?此外，我们希望该算法能够促进对系统构建者至关重要的直觉的开发。重要的不仅是算法能起作用，更重要的是要看它为什么能起作用。</p> <p>​		该算法还必须足够完整，以解决构建实际系统的所有方面，并且它必须具有足够好的性能，以用于实际部署。核心算法不仅要指定接收消息的效果，还要描述应该发生什么和什么时候发生；这些对于系统建设者来说同样重要。同样，它必须保证一致性，并且它还必须提供尽可能的可用性。它还必须解决一个超越达成共识的制度的许多方面，例如改变共识小组的成员。</p> <p>​		这些在实际中都是必要的，而将这一负担留给系统建设者将有特设的、次优的甚至错误的解决方案的风险。</p> <p>​		这项工作的结果是一个名为Raft的共识算法。在设计Raft时，我们使用了特定的技术来提高可理解性，包括分解( Raft分离了领导者选举、日志复制和安全性)和状态空间缩减( Raft降低了非确定性的程度,并且服务器之间的方式可以是不一致的)。我们还讨论了建立一个完整的基于共识的体系所需要的所有问题。我们仔细考虑了每一个设计选择，不仅是为了我们自己的实施，也是为了我们希望能够实现的许多其他设计。</p> <p>​		我们认为，Raft优于Paxos和其他共识算法，无论是出于教育目的，还是作为实现的基础。它比其他算法更简单、更容易理解；它被完全描述，足以满足实际系统的需要；它有多个开源实现，被多个公司使用；其安全特性已被正式规定和证明；而且其效率与其他算法相当。</p> <p>​		本论文的主要贡献如下：</p> <ul><li>Raft共识算法的设计、实现和评估。Raft在很多方面与现有的一致性算法(最值得注意的是, Oki和Liskov ' s Viewstamped Replication [ 83,66 ] )类似，但它是为了可理解性而设计的。这导致了几个新奇的特征。例如，Raft使用了比其他共识算法更强的领导形式。这简化了对复制日志的管理，使Raft更易于理解。</li> <li>Raft的可理解性评价。一项针对两所大学43名学生的用户研究表明，Raft明显比Paxos更容易理解：在学习了两种算法后，这些学生中有33人能够比Paxos更好地回答关于Raft的问题。我们相信这是第一项基于教与学来评估共识算法的科学研究。</li> <li>拉夫特领导人选举机制的设计、实施与评估。虽然许多共识算法没有规定特定的领导者选举算法，但Raft包含了一个包含随机定时器的特定算法。这对任何共识算法已经需要的心跳只增加了少量的机制，同时简单快速地解决了冲突。对领导人选举的评估调查了其行为和绩效，结论是这种简单的方法在各种各样的实际环境中是足够的。它通常在20倍以下的集群单向网络延迟中选举一个领导者。</li> <li>Raft的簇成员变更机制的设计与实现。Raft允许一次添加或移除单个服务器；这些操作简单地保护了安全性，因为在变化期间至少有一个服务器重叠了任何大多数。更复杂的成员关系变化是通过一系列单服务器的变化来实现的。Raft允许集群在变化时继续正常运行，成员关系的变化只需要对基本共识算法进行少量的扩展就可以实现。</li> <li>对完整的基于共识的系统所需的其他组件，包括客户端交互和日志压缩，进行了深入的讨论和实现。虽然我们不认为《筏子》的这些方面特别新颖，但完整的描述对于可理解性和使其他人能够构建真正的系统很重要。我们已经实现了一个完整的基于共识的服务来探索和解决所有涉及的设计决策。</li> <li>Raft算法的安全性证明和形式化规约。形式化规格说明的精确程度有助于仔细地推理算法，并澄清算法的非形式化描述中的细节。安全性的证明有助于建立对Raft正确性的信心。它还通过阐明Raft扩展的安全含义来帮助其他希望扩展Raft的人。</li></ul> <p>我们在Raft的一个开源实现LogCabin [ 86 ]中实现了本文中的许多设计。Log Cabin是我们在Raft中对新想法的测试平台，也是验证我们理解构建一个完整且实用的系统的问题的一种方式。在第10章中对实现进行了较为详细的描述。</p> <p>​		本文的后半部分介绍了复制状态机问题，并讨论了Paxos的优点和缺点(第二章)；介绍了Raft共识算法及其在簇成员变化和日志压缩方面的扩展，以及客户端如何与Raft (第3 - 6章)进行交互；评估Raft的可理解性、正确性、领导者选举和日志复制性能(第7 - 10章)；并对相关工作进行讨论(第11章)。</p> <h2 id="第二章"><a href="#第二章" class="header-anchor">#</a> 第二章</h2> <h3 id="动机"><a href="#动机" class="header-anchor">#</a> 动机</h3> <p>​		一致性是容错系统中的一个基本问题：即使在出现故障的情况下，服务器如何就共享状态达成一致?这个问题出现在各种各样的系统中，这些系统需要提供高水平的可用性，并且不能在一致性上妥协；因此，一致性几乎被用于所有一致的大规模存储系统中。2.1节描述了共识通常如何用于创建复制状态机，这是容错系统的通用构建模块；2.2节讨论了复制状态机在更大系统中的各种使用方式；和第2.3节讨论了Raft旨在解决的Paxos共识协议存在的问题。</p> <h3 id="_2-1、利用复制状态机实现容错"><a href="#_2-1、利用复制状态机实现容错" class="header-anchor">#</a> 2.1、利用复制状态机实现容错</h3> <p>一致性算法通常出现在复制状态机的环境中[ 102 ]。在这种方法中，服务器集合上的状态机计算相同状态的相同副本，即使部分服务器宕机也可以继续运行。复制状态机用于解决分布式系统中的各种容错问题，如第2.2节所述。复制状态机的例子包括Chubby [ 11 ]和ZooKeeper [ 38 ]，它们都为少量的配置数据提供了层次键值存储。除了get和put等基本操作外，它们还提供了类似比较并交换的同步原语，使得并发客户端能够安全地进行协调。</p> <p>​		复制状态机通常使用复制日志来实现，如图2.1所示。每个服务器存储一个包含一系列命令的日志，其状态机按顺序执行。每个日志中包含相同的命令，顺序相同。因此每个状态机都进行处理同样的命令序列。由于状态机是确定性的，每个状态机计算相同的状态和相同的输出序列。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215105959665.png" alt="image-20231215105959665"></p> <p>​		保持复制日志的一致性是共识算法的工作。服务器上的共识模块接收来自客户端的命令并将其添加到日志中。它与其他服务器上的共识模块进行通信，以确保每个日志最终以相同的顺序包含相同的请求，即使某些服务器出现故障。一旦命令被正确地复制，它们就被称之为承诺。每个服务器的状态机按照日志顺序处理提交的命令，并将输出返回给客户端。因此，服务器似乎形成了一个单一的、高度可靠的状态机。</p> <p>用于实际系统的共识算法通常具有以下属性：</p> <ul><li>它们确保了所有非拜占庭条件下的安全(从不返回错误的结果)，包括网络延迟、分区和数据包丢失、重复和重新排序。</li> <li>只要任何大多数服务器都可以运行，并且可以相互通信和与客户端通信，它们都是功能齐全的(可用的)。因此，一个典型的五台服务器集群可以容忍任意两台服务器的故障。假设服务器通过停止而失败；它们稍后可以从稳定存储上的状态恢复并重新加入集群。</li> <li>它们不依赖于时序来保证日志的一致性：错误的时钟和极端的消息延迟在最坏的情况下会导致可用性问题。也就是说，它们在异步模型下保持安全[ 71 ]，其中消息和处理器以任意速度进行。</li> <li>在常见的情况下，只要大部分集群响应了单轮远程过程调用，一个命令就可以完成；少数慢速服务器不必影响系统整体性能。</li></ul> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215110523057.png" alt="image-20231215110523057"></p> <h3 id="_2-2-、复制状态机的常用用例"><a href="#_2-2-、复制状态机的常用用例" class="header-anchor">#</a> 2.2 、复制状态机的常用用例</h3> <p>复制状态机是使系统具有容错性的通用构造块。它们可以有多种使用方式，本部分讨论了一些典型的使用模式。</p> <p>​		大多数常见的共识部署仅有3个或5个服务器组成一个复制状态机。其他服务器可以使用这个状态机来协调它们的活动，如图2.2 ( a )所示。这些系统通常使用复制状态机来提供组成员、配置管理或锁[ 38 ]。作为更具体的例子，复制状态机可以提供一个容错的工作队列，其他服务器可以协调使用复制状态机为自己分配工作。</p> <p>​		这种用法的常见简化如图2.2 ( b )所示。在这种模式中，一个服务器充当领导者，管理其余的服务器。领导者将其关键数据存储在共识系统中。如果它失效，其他备用服务器竞争领导者的位置，如果它们成功，它们使用共识系统中的数据继续运作。许多具有单个集群领导者的大型存储系统，如GFS [ 30 ]，HDFS [ 105 ]和内存云[ 90 ]，都使用了这种方法。</p> <p>​		共识有时也被用来复制非常大量的数据，如图2.3所示。大型存储系统，如大型商场[ 5 ]，施潘纳[ 20 ]和Scatter [ 32 ]。存储大量的数据要适合在单一的服务器群中。它们在许多复制的状态机中对数据进行分区，跨越多个分区的操作使用两阶段提交协议( 2PC )来保持一致性。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215111101276.png" alt="image-20231215111101276"></p> <h3 id="_2-3、paxos怎么了"><a href="#_2-3、paxos怎么了" class="header-anchor">#</a> 2.3、Paxos怎么了?</h3> <p>在过去的十年中，莱斯利·兰伯特的Paxos协议[ 48 ]几乎成为共识的代名词：它是课程中最常用的协议，共识的大多数实现都以它为起点。Paxos首先定义了一个能够对单个决策达成一致的协议，例如单个复制的日志条目。我们称这个子集为single - decree Paxos。然后，Paxos组合该协议的多个实例，以方便进行日志( Multi-Paxos )等一系列决策。单阶Paxos汇总于图2.4，多阶Paxos汇总于图A。5 . Paxos保证了(它最终达成共识,假设一个适当的失效检测器被用来避免提议者活锁)的安全性和活性，其正确性已被证明</p> <p>​		遗憾的是，Paxos有两个显著的缺陷。第一个缺点是Paxos非常难以理解。完整的解释[ 48 ]是出了名的不透明；只有极少数人能够成功地理解它，并且付出了巨大的努力。因此，有几次尝试用更简单的术语[ 49、60、61 ]来解释Paxos。这些解释聚焦于单一政令子集，但仍具有挑战性。在2012年NSDI对与会者的非正式调查中，我们发现，即使是在经验丰富的研究人员中，也很少有人对Paxos感到舒适。我们自己与帕克索斯进行了斗争；直到阅读了几个解释并设计了自己的替代方案之后，我们才能够理解完整的方案，这个过程花费了将近一年的时间。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215111432424.png" alt="image-20231215111432424"></p> <p>​		我们假设帕克斯的不透明性源于其选择了单一法令子集作为基础。单一法令帕克斯是密集而微妙的：它分为两个阶段，没有简单的直观解释，无法独立理解。正因为如此，很难发展关于单令协议为什么工作的直觉。MultiPaxos的组合规则增加了显著的额外复杂性和微妙性。我们认为，对多个决策达成共识的整体问题(也就是说,日志而不是单个条目)可以通过其他更直接、更明显的方式进行分解。</p> <p>​		Paxos的第二个问题是它没有为构建实际的实现提供良好的基础。一个原因是Multi - Paxos没有得到广泛认同的算法。兰波特的描述多是关于单令帕克索斯的；他为Multi - Paxos勾勒出了可能的实现途径，但遗漏了许多细节。对Paxos进行充实和优化的尝试已有几次，如[ 77 ]、[ 108 ]、[ 46 ]等，但彼此之间以及与兰波特的草图有所不同。类似Chubby [ 15 ]的系统已经实现了Paxos - like算法，但在大多数情况下，它们的细节还没有公布。</p> <p>​		此外，Paxos架构对于构建实际系统来说是一个很差的架构；这是单一政令分解的另一个后果。例如，独立地选择日志条目的集合，然后将它们融合成一个顺序日志的方法几乎没有好处；这只是增加了复杂性。设计一个围绕日志的系统更加简单和高效，其中新的条目是MOTIVATION按约束顺序依次添加。另一个问题是Paxos在其核心(尽管这也表明了作为绩效优化的一种弱领导形式)处使用了对称对等方法。这在一个简化的世界里很有意义，那里只会做出一个决定，但很少有实际系统使用这种方法</p> <p>​		因此，实际系统与Paxos几乎没有什么相似之处。每一次实现都从Paxos开始，发现实现的困难，然后发展出截然不同的架构。这既费时又容易出错，理解帕克斯语的困难又加剧了问题。Paxos公式对于证明关于其正确性的定理可能是一个很好的公式，但实际的实现与Paxos公式有很大的不同，以至于证明的价值不大。下面Chubby实施者的评论是典型的：</p> <blockquote><p>Paxos算法的描述与现实世界系统的需求之间存在着巨大的差距.. ..最终的系统将基于一个未经证明的协议[ 15 ]。</p></blockquote> <p>​		正因为这些问题，我们得出结论，帕克斯无论是在制度建设方面，还是在教育方面，都没有提供良好的基础。鉴于共识在大规模软件系统中的重要性，我们决定看看能否设计出一种性能优于Paxos的替代共识算法。Raft就是该实验的结果。</p> <h2 id="第三章"><a href="#第三章" class="header-anchor">#</a> 第三章</h2> <h3 id="基本raft算法"><a href="#基本raft算法" class="header-anchor">#</a> 基本Raft算法</h3> <p>本章介绍了Raft算法。我们设计的Raft是尽可能容易理解的；第一部分描述了我们为可理解性而设计的方法。接下来的部分描述了算法本身，并包括我们为可理解性所做的设计选择的例子。</p> <h3 id="_3-1、为可理解性而设计"><a href="#_3-1、为可理解性而设计" class="header-anchor">#</a> 3.1、为可理解性而设计</h3> <p>​		我们在设计Raft时有几个目标：它必须为系统构建提供一个完整且实用的基础，这样它就大大减少了开发人员所需的设计工作量；它必须在所有条件下都是安全的，并在典型的操作条件下可用；而且它必须对常见操作高效。但我们最重要的目标- -也是最困难的挑战- -是可理解性。必须有可能让广大受众能够舒服地理解算法。此外，必须能够开发关于算法的直觉，以便系统构建者能够做出在现实世界实现中不可避免的扩展。</p> <p>​		在Raft的设计中有许多要点，我们必须在备选方法中进行选择。在这些情况下，我们评估了基于可理解性的备选方案：解释每个备选方案(例如,它的状态空间有多复杂,它是否有微妙的含义?)有多困难，以及读者完全理解该方法及其含义有多容易?</p> <p>​		我们认识到这样的分析存在着高度的主观性；尽管如此，我们使用了两种普遍适用的技术。第一种技术是众所周知的问题分解方法：在可能的情况下，我们将问题分解为可以相对独立地解决、解释和理解的独立部分。例如，在Raft中，我们分离了BASIC RAFT ALGORITHM的领导者选举、日志复制和安全性。</p> <p>​		我们的第二种方法是通过减少要考虑的状态数来简化状态空间，使系统更加连贯，并在可能的情况下消除不确定性。具体来说，日志不允许有漏洞，Raft限制了日志之间不一致的方式。虽然在大多数情况下，我们试图消除非决定论，有些情况下，非决定论实际上提高了可理解性。特别地，随机方法引入了非决定论，但它们倾向于通过以类似( '选一个;它不重要')的方式处理所有可能的选择来减少状态空间。我们使用随机化来简化Raft领导人选举算法。</p> <h3 id="_3-2、raft概况"><a href="#_3-2、raft概况" class="header-anchor">#</a> 3.2、Raft概况</h3> <p>Raft是管理2.1节所述表单复制日志的算法。图3.1以浓缩的形式总结了算法以供参考，图3.2列出了算法的关键性质；在本章的其余部分，对这些图形的元素进行了分段讨论。</p> <p>​		Raft通过首先选举一个服务器作为领导者，然后赋予领导者管理复制日志的完整责任来实现共识。管理者接受来自客户端的日志项，在其他服务器上进行复制，并告诉服务器何时可以将日志项安全地应用到自己的状态机中。有了领导者，简化了对复制日志的管理。例如，领导者可以在不咨询其他服务器的情况下决定在日志中放置新条目的位置，并且数据以简单的方式从领导者流向其他服务器。一个领导者可以失败或与其他服务器断开连接，在这种情况下选举一个新的领导者。</p> <p>​		考虑到领导者方法，Raft将共识问题分解为三个相对独立的子问题，在接下来的小节中讨论：</p> <ul><li>领导人选举：在集群启动和现有领导人失败时，必须选择新的领导人( 3.4节)。</li> <li>日志复制：领导者必须接受来自客户的日志条目，并在整个集群中复制它们，迫使其他日志与自己一致(第3.5节)。</li> <li>安全性：Raft的关键安全属性是状态机安全属性( State Machine Safety Property )，如图3.2：如果任何服务器对其状态机应用了特定的日志项，那么任何其他服务器都不可能对相同的日志索引应用不同的命令。第3.6节描述了Raft是如何保证这一点的，解决方案涉及对第3.4节所述选举机制的额外限制。</li></ul> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215112257285.png" alt="image-20231215112257285"></p> <p>在提出共识算法之后，本章讨论了可用性问题和时间在系统中的作用(第3.9节)，以及在服务器之间传递领导权的可选扩展(第3.10节)。</p> <h3 id="_3-3、raft基础"><a href="#_3-3、raft基础" class="header-anchor">#</a> 3.3、Raft基础</h3> <p>一个Raft集群包含若干个服务器；五是一个典型的数，它允许系统容忍两个故障。在任意给定的时刻，每个服务器都处于三种状态之一：领导者、跟随者或候选者。在正常运行时，只有一个领导者，其他服务器都是跟随者。追随者是被动的：他们自己不发出任何请求，只是简单地回应来自领导和候选人的请求。领导处理所有客户端请求(如果一个客户接触一个跟随者,跟随者将它重定向到领导者)。第三个状态，候选人，用于选举一个新的领导者，如第3.4节所述。图3.3显示了状态和它们的转变；下面对这些转变进行讨论。</p> <p>​		Raft将时间划分为任意长度的项，如图3.4所示。术语用连续的整数编号。每个任期都始于选举，在选举中，一个或多个候选人试图成为领导者，如第3.4节所述。如果一个候选人在选举中获胜，那么它将在剩下的任期内担任领导者。在某些情况下，选举会导致分裂投票。任期将以没有领导者而结束；一个新的名词(伴随着一场新的选举)即将开始。Raft保证在给定的任期内最多只有一个领导者。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215112437227.png" alt="image-20231215112437227"></p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215112451882.png" alt="image-20231215112451882"></p> <p>​		不同的服务器可能会在不同的时间观察到条款之间的转换，在某些情况下，服务器可能不会观察到一个选举甚至整个条款。术语在Raft中充当逻辑时钟[ 47 ]，允许服务器检测过时的信息，如过时的领导者。每个服务器存储一个当前项数，该项数随时间单调递增。每当服务器进行通信时，都会交换当前的术语；如果一个服务器的当前项小于另一个服务器的当前项，则更新其当前项到更大的值。如果候选人或领导人发现自己的任期已经过时，立即回复到追随者状态。如果服务器接收到一个具有固定项号的请求，则拒绝该请求。</p> <p>​		Raft服务器之间使用远程过程调用( Remote Procedure Calls，RPCs )进行通信，而基本的共识算法只需要服务器之间的两种RPCs。RequestVote RPCs由候选人在选举过程中发起(第3.4节)，AppendEntries RPCs由领导者发起以复制日志条目并提供心跳形式(第3.5节)。领导转移( 3.10节)和后续章节所述的机制在核心共识算法中引入了除二者之外的额外RPC。</p> <p>​		我们选择在Raft中构造通信作为RPC，以简化其通信模式。每个请求类型都有对应的响应类型，也作为请求的确认。Raft假设RPC请求和响应可能在网络中丢失；如果RPC没有及时收到响应，请求者有责任重试RPC。服务器并行地发布RPC以获得最佳性能，而Raft并不假定网络保持RPC之间的顺序。</p> <h3 id="_3-4、首领选举"><a href="#_3-4、首领选举" class="header-anchor">#</a> 3.4、首领选举</h3> <p>Raft使用心跳机制触发领导人选举。当服务器启动时，它们以跟随者的身份开始。只要服务器从领导者或候选者那里接收到有效的RPC，它就一直处于跟随者状态。领导者为了维护自己的权威，向所有追随者发送周期性心跳(附录不带日志项的RPC)。如果一个追随者在一段时间内没有收到任何通信，称为选举超时，那么它假设没有可行的领导者，并开始选举以选择新的领导者。</p> <p>​		为了开始选举，追随者增加当前任期并过渡到候选国。然后，它自己投票，并在集群中的每个其他服务器上并行地发出RequestVote RPC。一个候选人在这个状态中持续下去，直到三种情况之一发生：( a )它赢得了选举，( b )另一个服务器确立自己为领导者，或( c )另一个选举超时，没有赢家。这些结果在下面的段落中分别讨论。</p> <p>​		如果候选人从整个集群中的大多数服务器中获得了相同期限的选票，则该候选人将赢得选举。每个服务器将在给定的任期内最多为一个候选人投票，基于先到先服务的基础(注:第3.6节增加了对投票的额外限制)。多数决原则保证了在特定任期(图3.2中的选举安全属性)的选举中至多有一名候选人获胜。候选人一旦赢得选举，就成为领导者。然后，它向所有其他服务器发送心跳消息，以建立其权威并防止新的选举。</p> <p>​		候选人在等待投票时，可以从另一个候选人那里获得一个实体RPC自称是领导者。如果领导者的(包括在其RPC中)项至少与候选人当前的(包括在其RPC中)项一样大，那么候选人就认为领导者是合法的，并返回到跟随者状态。如果RPC中的项小于候选人当前的项，则该候选人拒绝RPC，继续处于候选状态。</p> <p>​		第三种可能的结果是，一个候选人既没有赢得选举，也没有输掉选举：如果许多追随者同时成为候选人，那么就可以分割选票，从而没有候选人获得多数。当这种情况发生时，每个候选人将超时并通过增加其任期和启动另一轮RequestVote RPCs来启动新的选举。然而，如果没有额外的措施，分裂投票可以无限期地重复。</p> <p>​		拉夫特使用随机的选举超时，以确保分裂的选票是罕见的，并迅速解决。首先，为了防止分裂投票，选举超时从一个固定的间隔(例如, 150 - 300毫秒)中随机选择。这样就将服务器分散开来，以至于在大多数情况下只有单个服务器会超时；它在选举中获胜，并在任何其他服务器超时之前发送心跳。同样的机制用于处理分裂投票。每个候选人在选举开始时重新启动其随机选举超时，并在开始下一次选举前等待该超时时间流逝；这降低了在新的选举中再次分裂投票的可能性。第九章表明，这种方式可以快速选举出领导人。</p> <p>​		选举是可理解性如何指导我们在设计方案之间进行选择的一个例子。最初我们计划使用一个排名系统：每个候选人被分配一个独特的排名，用于在竞争候选人之间进行选择。如果一个候选人发现了另一个排名较高的候选人，那么它就会回到追随者状态，这样排名较高的候选人就更容易赢得下一次选举。我们发现，这种方法在可用性(如果较高等级的服务器失败,较低等级的服务器可能需要暂停工作,重新成为候选人,但如果它做得太快,它可以重置进展,以选举领导者)附近产生了微妙的问题。我们对算法进行了多次调整，但每次调整后都会出现新的拐角情况。最终我们得出结论</p> <h3 id="_3-5、日志复制"><a href="#_3-5、日志复制" class="header-anchor">#</a> 3.5、日志复制</h3> <p>一旦领导人当选，就开始为客户请求提供服务。每个客户机请求都包含一个由复制状态机执行的命令。领导者将命令追加到其日志中作为新的条目，然后在其他服务器上并行地发出AppendEntries RPCs来复制该条目。当入口已安全复制(如下所述)时，首领进入其状态机，并将该执行结果返回给客户端。如果跟随者崩溃或运行缓慢，或者网络数据包丢失，领导者无限期地检索AppendEntries RPCs (甚至在其对客户做出反应后)，直到所有跟随者最终存储所有日志条目。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215123120213.png" alt="image-20231215123120213"></p> <p>​		日志整理如图3.5所示。每个日志条目存储一个状态机命令以及条目被领导接收时的项号。日志条目中的词条编号用于检测日志之间的不一致性，并确保图3.2中的一些属性。每个日志条目也有一个整数索引标识其在日志中的位置。</p> <p>​		领导者决定何时向状态机申请日志条目是安全的；这样的进入被称为承诺。Raft保证提交的条目是持久的，最终将由所有可用的状态机执行。一旦创建该条目的领导者在大多数服务器(例如,图3.5中的第7项)上复制了该条目，日志条目就会被提交。这也提交了领导者日志中的所有前项，包括先前领导者创建的项。第3.6节讨论了领导者变更后适用该规则时的一些细微之处，同时也表明这种承诺的定义是安全的。领导者跟踪其知道要提交的最高索引，并将该索引包含在未来的AppendEntries RPCs (包括心跳)中，以便另一个</p> <p>​		我们设计了Raft日志机制，使不同服务器上的日志之间保持较高的一致性。这不仅简化了系统的行为，使其更具有可预测性，而且是保证安全的重要组成部分。Raft保持了以下特性，它们共同构成了图3.2中的Log Matching特性：</p> <ul><li>如果不同日志中的两个条目具有相同的索引和术语，那么它们存储相同的命令。</li> <li>如果不同日志中的两个条目具有相同的索引和术语，那么日志在所有前面的条目中都是相同的。</li></ul> <p>第一个性质来自于领导者在给定的术语中最多创建一个带有给定日志索引的条目，并且日志条目不会改变它们在日志中的位置。第二个性质由Append Entries执行的一致性检查来保证。当发送AppendEntries RPC时，Leader在其日志中包含项的索引和项，该项立即位于新项之前。如果跟随者在其日志中未找到具有相同索引和术语的条目，则拒绝新条目。一致性检查作为一个归纳步骤：日志的初始空状态满足日志匹配属性，并且当日志被扩展时，一致性检查保持日志匹配属性。因此，每当AppendEntries成功返回时，领导者通过新的条目知道跟随者的日志与自己的日志相同。</p> <p>​		正常运行时，领导者和跟随者的日志保持一致，因此Append Entries一致性检查不会失败。然而，Leader崩溃可能会留下日志不一致的(老的领导者可能没有完全复制其日志中的所有条目)。这些不一致性会叠加在一系列领导者和跟随者崩溃事件上。图3.6说明了跟随者的日志可能与新领导者不同的方式。跟随者可能缺失存在于领导者身上的条目，也可能拥有不存在于领导者身上的额外条目，或者两者兼而有之。日志中的缺失项和无关项可能跨越多个术语。</p> <p>​		在Raft中，领导者通过强迫跟随者的日志复制自己的日志来处理不一致性。这意味着追随者日志中相互冲突的条目会被来自领导者日志的条目覆盖。第3.6节将表明，当加上对选举的限制时，这是安全的。</p> <p>​		为了使跟随者的日志与自己的日志保持一致，领导者必须找到两个日志一致的最新日志条目，在该点之后删除跟随者日志中的任何条目，并在该点之后向跟随者发送所有领导者的条目。所有这些操作都是响应AppendEntries RPC执行的一致性检查。领导者为每个跟随者维护一个下一个索引，该索引是领导者将下一个日志条目的索引发送给该跟随者。当领导人首次上台执政时，它将所有next Index值初始化为指数刚好在最后一个跟随者日志中。每个方框代表一个日志条目；箱子中的数字是它的术语。跟随者可能是缺失词条( a-b )，也可能有额外的未提交词条( c-d )，或者两者兼而有之( e-f )。例如，场景( f )可以发生，如果该服务器是第2项的领导者，在其日志中添加若干条目，然后在提交任何条目之前崩溃；它很快重新启动，成为第3项的领导者，并在其日志中增加了几个条目；在第2项或第3项中的任何一个条目被提交之前，服务器再次崩溃，并保持了几个术语。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215123502001.png" alt="image-20231215123502001"></p> <p>其log (图3.6中的11个) .如果一个追随者的日志与领导者的日志不一致，那么在下一个AppendEntries RPC中，AppendEntries一致性检查将失败。被拒绝后，领导者对跟随者的next Index进行减量，并重试Append Entries RPC。最终，下一个Index将达到领导者和跟随者日志匹配的点。当这种情况发生时，AppendEntries会成功，它会删除跟随者日志中任何冲突的条目，并从领导者日志中追加条目(如果有的话)。一旦AppendEntries成功，跟随者的日志将与领导者的日志保持一致，并且在其余时间内将保持这种方式。</p> <p>​		直到领导者发现它和跟随者的日志匹配的地方，领导者可以发送没有条目(如心跳)的AppendEntries来节省带宽。然后，一旦匹配后的Index立即先于下一个Index，领导者就应该开始发送实际的条目。</p> <p>​		如果需要，可以对协议进行优化，以减少被拒绝的AppendEntries RPC的数量。例如，当拒绝AppendEntries请求时，跟随者可以包括冲突项的词条和它为该词条存储的第一个索引。利用这些信息，领导者可以减少下一个索引，以绕过该词项中所有冲突的条目；对于每个词条有冲突的词条，需要一个Append Entries RPC，而不是每个词条需要一个RPC。或者，领导者可以使用二分搜索方法来找到跟随者的日志与自己不同的第一个条目；这具有更好的最坏情况行为。在实践中，我们怀疑这些优化是必要的，因为故障很少发生，并且不太可能会出现许多不一致的条目。</p> <p>​		通过这种机制，领导者在上台时不需要采取任何特殊的行动来恢复日志一致性。它刚开始正常运行，日志自动收敛，以应对AppendEntries一致性检查的失败。领导者从不覆盖或删除自己日志(图3.2中的领导者附属性)中的条目。</p> <p>​		这种日志复制机制表现出了第2.1节所描述的理想的一致性特性：只要大多数服务器处于运行状态，Raft就可以接受、复制和应用新的日志条目；在正常情况下，一个新的入口可以用单轮RPC复制到集群的大多数；并且单个慢跟随者不会对性能产生影响。由于AppendEntries请求的大小为(领导者从不需要在单个AppendEntries中发送多个表项请求来取得进步)，因此日志复制算法的实现也很实用。一些其他的一致性算法被描述为在网络上发送整个日志；这就给实施者带来了制定实际实施所需的优化方案的负担。</p> <h3 id="_3-6、安全性"><a href="#_3-6、安全性" class="header-anchor">#</a> 3.6、安全性</h3> <p>前几部分描述了Raft如何选举领导者和复制日志条目。然而，到目前为止所描述的机制还不足以保证每个状态机以相同的顺序执行完全相同的命令。例如，当领导者提交多个日志条目时，一个跟随者可能是不可用的，那么它可以被选为领导者，并用新的日志条目覆盖这些日志条目；因此，不同的状态机可能执行不同的命令序列。本节通过增加对哪些服务器可能被选为领导者的限制来完成Raft算法。该限制保证了对于任意给定的词条，领导者包含了之前词条(由图3.2可知, Leader Completeness Property)中提交的所有词条。最后，我们给出了Leader Completeness属性的证明示意图，并展示了它如何导致复制状态机的正确行为。</p> <h4 id="_3-6-1、选举限制"><a href="#_3-6-1、选举限制" class="header-anchor">#</a> 3.6.1、选举限制</h4> <p>在任何强领导者共识算法中，领导者最终都必须存储所有提交的日志条目。在一些共识算法中，如Viewstamped Replication [ 66 ]，即使领导人最初不包含所有提交的条目，也可以被选举出来。这些算法包含额外的机制来识别缺失的条目，并将其传送给新的领导人，无论是在选举过程中还是在选举后不久。遗憾的是，这导致了相当大的额外机制和复杂性。拉夫特使用了一种更简单的方法，它保证每位新领导人从当选的那一刻起就有来自前任的所有承诺条目，而不需要将这些条目移交给领导人。这意味着日志条目只在一个方向上流动。</p> <p>​		Raft使用投票过程来阻止候选人赢得选举，除非其日志包含所有提交的条目。候选人必须联系集群中的大多数才能当选，这意味着每个提交的条目必须至少存在于其中一个服务器中。如果候选者的日志至少与该多数(其中&quot; up-to-date &quot;的定义如下)中的任何其他日志一样是最新的，那么它将保留所有提交的条目。RequestVote RPC实现了这一限制：RPC包含关于候选人日志的信息，如果投票人自己的日志比候选人的日志更新，则投票人拒绝投票。</p> <p>​		Raft通过比较日志中最后一个表项的索引和词项来确定两个日志中哪个更新快。如果日志中最后的词条具有不同的术语，然后与后面的日志从旧词条中提取词条。在( a )中，S1是领导者，并在索引2处部分复制日志项。在( b ) S1崩溃；S5以S3、S4和自身的票数当选第3任期的领导人，并在对数指标2处接受不同的进入。在( c ) S5碰撞中；S1重启，被选为领导者，并继续复制。此时，term 2中的日志项已经在大多数服务器上被复制，但并没有被提交。如果S1像( d1 )那样崩溃，S5可以当选领导人(得到S2、S3和S4的投票)，并从第3期开始用自己的条目覆盖该条目。然而，如果S1在崩溃之前，如( d2 )中一样，在大多数服务器上复制一个从其当前期限开始的条目，那么这个条目被提交到( S5不能赢得选举)中。此时，日志中的所有前项也被提交。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215123830621.png" alt="image-20231215123830621"></p> <p>任期(term)更具有时代性。如果日志以相同的期限结束，那么哪个日志更长则代表更具有时代性。</p> <h4 id="_3-6-2、从以前的任期提交条目"><a href="#_3-6-2、从以前的任期提交条目" class="header-anchor">#</a> 3.6.2、从以前的任期提交条目</h4> <p>正如第3.5节所描述的那样，一个领导者知道，一旦该条目存储在大多数服务器上，则其当前期限的条目将被提交。如果领导者在提交一个入口之前崩溃，未来的领导者将试图完成入口的复制。但是，一个领导者不能立即断定一个前一个词条一旦被存储在大多数服务器上就被提交了。图3.7说明了一个旧的日志记录存储在大多数服务器上，但仍然可以被未来的领导者覆盖的情况。</p> <p>​		为了消除如图3.7所示的问题，Raft从不通过统计副本来提交以前的日志项。只有来自领导者当前任期的日志条目通过计数副本提交；一旦以这种方式提交了来自当前项的一个条目，那么之前的所有条目都是间接提交的，因为存在&quot;日志匹配&quot;属性。在某些情况下，领导者可以安全地断定一个较老的日志条目提交了(例如,如果该条目存储在每个服务器上)，但Raft为了简单起见采取了更保守的方法。</p> <p>​		Raft在承诺规则中引入了这种额外的复杂性，因为当领导者从以前的词条中复制词条时，日志条目保留了它们的原始词条数。在其他一致性算法中，如果一个新的领导者从以前的&quot;词条&quot;中重新复制条目，那么它必须使用新的&quot;词条数&quot;。Raft的方法使日志条目的推理变得更容易，因为它们在时间和日志之间保持相同的术语数。此外，与其他算法相比，Raft中新的领导者发送的前项日志条目更少，因为其他算法在提交前必须发送冗余的日志条目重新编号；然而，这在实践中可能并不十分重要，因为领导人变更应该是罕见的。</p> <h4 id="_3-6-3、安全论证"><a href="#_3-6-3、安全论证" class="header-anchor">#</a> 3.6.3、安全论证</h4> <p>考虑到完全Raft算法，我们现在可以更精确地论证Leader Completeness Property成立(这种论证是建立在安全证明的基础上的;见第8章)。我们假设领导者完备性不成立，那么我们证明了一个矛盾。假设术语T的领导者( leaderT )提交一个来自其术语的日志条目，但该日志条目不是由某个未来术语的领导者存储的。考虑最小的项U &gt; T，它的领导者( leaderU )不存储项.</p> <p>1、承诺的条目必须在领导人U选举时从其日志中缺席（领导者从不删除或改写词条）</p> <p>2、Leader T在多数集群上复制了该条目，Leader U获得了多数集群的投票。因此，至少有一个服务器( &quot;选民&quot;)既接受了leaderT的进入，又投票给leaderU，如图3.8所示。选民是达成矛盾的关键。</p> <p>3、投票者在投票给领导人U之前，必须接受领导人T的承诺进入；否则将拒绝Leader T (其当前任期将高于T)的Append Entries请求。</p> <p>4、投票者在投票给leaderU时仍然保存条目，因为每个干预的领导者都包含条目(假设)，领导者从不删除条目，而追随者只有在与领导者发生冲突时才删除条目。</p> <p>5、选民将投票权授予领导人U，因此领导人U的日志必须与选民的日志一样最新。这就引出了两个矛盾之一。</p> <p>6、首先，如果投票者和leaderU共享同一个最后一个日志项，那么leaderU的日志必须至少和投票者的日志一样长，所以它的日志包含了投票者日志中的每个条目。这是一个矛盾，因为选民包含承诺的进入，而领导人U被假定不包含承诺的进入。</p> <p>7、否则，领导人U的最后一个对数期一定大于选民的最后一个对数期。此外，它比T大，因为选民的最后一个对数期至少是T (它包含来自术语T的承诺项)。创建leaderU的前一个leader的最后一个日志项必须包含在其日志中提交条目(假设)。然后，根据日志匹配特性，leaderU的日志中也必须包含已提交的表项，这是一个矛盾。</p> <p>8、这就完成了矛盾。因此，大于T的所有词条的领导人必须包含T词条中承诺的所有词条。</p> <p>9、日志匹配属性保证未来的领导者也会包含间接提交的条目，如图3.7 ( d2 )中的索引2。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215124337880.png" alt="image-20231215124337880"></p> <p>​		给定Leader Completeness Property，我们可以从图3.2中证明状态机安全属性，即如果一个服务器在其状态机中应用了一个给定索引的日志项，那么任何其他服务器都不会为相同的索引应用不同的日志项。当服务器向其状态机应用一个日志条目时，其日志必须与通过该条目的领导登录完全相同，并且该条目必须提交。现在考虑任意服务器应用给定日志索引的最低项；Leader Completeness Property保证所有高阶项的领导者都会存储相同的日志项，因此在后面的项中应用索引的服务器将应用相同的值。因此，状态机安全属性成立。</p> <p>​		最后，Raft要求服务器按照日志索引顺序申请条目。结合状态机安全属性，这意味着所有服务器将以相同的顺序向其状态机应用完全相同的日志项集。</p> <h3 id="_3-7、跟随者和候选者崩溃"><a href="#_3-7、跟随者和候选者崩溃" class="header-anchor">#</a> 3.7、跟随者和候选者崩溃</h3> <p>在此之前，我们关注的是领导者的失败。跟随者和候选崩溃的处理比领导者崩溃简单得多，并且它们都以相同的方式处理。如果追随者或候选程序崩溃(或者它与领导者之间的网络链接失败)，那么未来发送给它的RequestVote和AppendEntries RPCs就会失败。Raft通过无限期地重试来处理这些失败；如果崩溃的服务器重新启动，那么RPC将成功完成。如果一个服务器在完成一个RPC之后，但在响应之前就崩溃了，那么它将在重启后再次收到相同的RPC。筏式RPC重复作用效果相同，因此不会产生危害。例如，如果跟随者收到一个AppendEntries请求，其中包含日志中已经存在的日志条目，那么它就忽略了那些在th中的日志条目</p> <h3 id="_3-8、持续状态和服务器重启"><a href="#_3-8、持续状态和服务器重启" class="header-anchor">#</a> 3.8、持续状态和服务器重启</h3> <p>Raft服务器必须保持足够的信息以稳定存储，才能在服务器重启后安全生存。特别地，每个服务器都坚持当前的任期和投票；这是很有必要的，以防止服务器在同一时间内进行两次投票，或者将新领导者的日志条目替换为已撤销领导者的日志条目。每个服务器也会保存新的日志条目，然后计算它们对条目的承诺；这可以防止服务器重新启动时提交的条目丢失或&quot;未提交&quot;。</p> <p>​		其他状态变量在重启动时是安全的，因为它们都可以重新创建。最有趣的例子是提交索引，它可以在重新启动时安全地重新初始化为零。即使每个服务器同时重启，提交指数也只会暂时滞后于其真实值。一旦一个领导者被选举出来并能够提交一个新的条目，那么它的提交指数就会提前，并且它会迅速地将这个提交指数传播给它的追随者。</p> <p>​		状态机可以是易变的，也可以是持久的。一个易失性状态机必须在重新启动后通过重新应用日志项(应用最新快照后;见第5章)来恢复。然而，一个持久化的状态机在重启后已经应用了大多数条目；为了避免重新应用，其最后应用的指标也必须具有持久性。</p> <p>​		如果服务器失去任何一个持久化状态，它就不能以其先前的身份安全地重新加入集群。这样的服务器通常可以通过调用集群成员更改(见第4章)，以新的身份回加到集群中。但是，如果大部分集群失去了持久化状态，则日志条目可能会丢失，无法在集群成员变更方面取得进展；为此，系统管理员需要承认数据丢失的可能性。</p> <h3 id="_3-9、时间与有效性"><a href="#_3-9、时间与有效性" class="header-anchor">#</a> 3.9、时间与有效性</h3> <p>我们对Raft的要求之一是安全不能依赖于时机：系统不能仅仅因为某些事件发生得比预期的更快或更慢而产生不正确的结果。然而，可用性(系统及时响应客户的能力)必然依赖于时间。例如，如果消息交换的时间比服务器崩溃之间的典型时间长，那么候选人就不会在选举中获胜；没有稳定的领导者，Raft就无法进步。</p> <p>领导人选举是Raft最为关键的环节。当系统满足下面的时间要求时，Raft将能够选举并维持一个稳定的领导者：</p> <p>​																		<code>broadcastTime &lt;&lt; electionTimeout &lt;&lt;MTBF</code></p> <p>​		在这个不等式中，广播时间是一个服务器并行地向集群中的每个服务器发送RPC并接收它们的响应所花费的平均时间；ElectionTimeout是第3.4节中描述的选举超时；和MTBF为单台服务器平均(平均)故障间隔时间。广播时间应该比选举超时少一个数量级，以便领导人能够可靠地发送阻止追随者开始选举所需的心跳消息；考虑到用于选举超时的随机方法，这种不平等也使得分裂投票不太可能。选举超时应该比MTBF少几个数量级，才能使系统稳定运行。当领导人崩溃时，系统将概的选举超时而不可用；我们希望这只代表整体时间的一小部分。</p> <p>​		播出时间和MTBF是底层系统的属性，而选举超时是我们必须选择的。Raft的RPCs通常要求接收者将信息持久化到稳定的存储状态，因此根据存储技术的不同，广播时间可能在0.5 - 20ms之间。因此，选举超时很可能在10 - 500毫秒之间。典型的服务器MTBF为几个月甚至更长时间，很容易满足定时要求。第九章更详细地探讨了如何设定选举超时及其对可获得性和领导人选举绩效的影响。</p> <h3 id="_3-10、领导者转移扩展"><a href="#_3-10、领导者转移扩展" class="header-anchor">#</a> 3.10、领导者转移扩展</h3> <p>这一部分描述了对Raft的一个可选扩展，它允许一个服务器将其领导权转移到另一个服务器。在两种类型的情况下，领导转移可能是有用的：</p> <p>1、有时领导者必须下台。例如，可能需要重新启动以进行维护，也可能从集群(见第4章)中移除。当它下台时，集群将被空闲用于选举超时，直到另一个服务器超时并赢得选举。这种短暂的不可用性可以通过让领导者在下台之前将其领导权转移到另一个服务器来避免。</p> <p>2、在某些情况下，一个或多个服务器可能比其他服务器更适合领导集群。例如，一个高负载的服务器不会成为一个好的领导者，或者在广域网部署中，为了最大限度地减少客户端和领导者之间的延迟，可能会优先选择位于主要数据中心的服务器。其他共识算法也许能够在领导人选举时容纳这些偏好，但是 Raft需要一个具有足够最新日志的服务器去成为领导，可能不是最喜欢的领导。相反，Raft中的一个领导者可以定期检查其可用的追随者中的一个是否更合适，如果是，则将其领导权转移到该服务器。(不仅仅只有人类的领袖才是如此的优雅。)</p> <p>为了在Raft中传递领导权，先前的领导者将其日志条目发送给目标服务器，然后目标服务器执行一次选举，而不等待选举超时结束。因此，先前的领导者确保目标服务器在其任期开始时拥有所有承诺的条目，并且，与正常选举一样，多数投票保证安全属性(如领导者的完全性属性)得到维护。以下步骤对该过程进行了较为详细的描述：</p> <p>1、先前的领导者停止接受新的客户请求。</p> <p>2、先前的领导者完全更新目标服务器的日志以匹配自己，使用第3.5节中描述的正常日志复制机制。</p> <p>3、上级领导向目标服务器发送Timeout Now请求。该请求与目标服务器的选举计时器触发具有相同的效果：目标服务器启动新的选举(增加其任期并成为候选人)。</p> <p>一旦目标服务器收到Timeout Now请求，它极有可能在其他服务器之前开始选举，并在下一个任期内成为领导者。它给前任领导人的下一个信息将包括其新的任期号，导致前任领导人下台。此时，领导权转移是完全的。</p> <p>​		目标服务器也有可能出现故障；在这种情况下，集群必须恢复客户端的操作。如果在大约一个选举超时之后领导权转移没有完成，则前任领导人中止转移并恢复接受客户请求。如果先前的领导者是错误的，而目标服务器是实际运行的，那么最坏的情况是这个错误会导致一个额外的选举，在这个选举之后，客户端的操作将被恢复。</p> <p>​		这种方法通过在Raft集群的正常转换范围内操作来保持安全性。例如，即使时钟以任意速度运行，Raft也已经保证了安全性；当目标服务器收到Timeout Now请求时，相当于目标服务器的时钟快速向前跳转，是安全的。然而，我们目前还没有实施或评估这种领导力转移方法。</p> <h3 id="_3-11、总结"><a href="#_3-11、总结" class="header-anchor">#</a> 3.11、总结</h3> <p>本章解决了基于共识的系统的所有核心问题。&quot;筏子&quot;超越了就单一价值达成共识，正如帕克索斯的&quot;单一法令&quot;；它在不断增长的命令日志上达成共识，这需要建立复制状态机。它还包括在协议达成后传播信息，以便其他服务器学习已提交的日志条目。Raft通过选举一个集群领导者单方面做出决策，并在新领导者上台时只传输必要的日志条目，以一种实用且高效的方式达成共识。我们在复制状态机(描述于第10章)的LogCabin中实现了Raft的思想。</p> <p>​		Raft仅使用少量的机制来解决完全共识问题。例如，它只使用了两个RPC (请求投票和附录)。也许令人惊讶的是，创建一个紧凑的算法/实现并不是Raft的明确目标。相反，它是我们为可理解性而设计的结果，其中的每一点机制都必须得到充分的激励和解释。我们发现冗余或曲折的机制很难被激励，因此在设计过程中自然会被淘汰。</p> <p>​		除非我们相信某个特定的问题会影响到Raft部署的很大一部分，否则我们不会在Raft中解决这个问题。因此，Raft的部分可能会显得幼稚。例如，Raft中的服务器通过等待选举超时来检测分裂投票；原则上，他们通常可以通过计算授予任何候选人的选票来尽早发现甚至解决分裂选票。我们选择不为Raft开发这种优化，因为它增加了复杂性，但可能不会带来实际的好处：在配置良好的部署中，分裂投票是罕见的。Raft的其他部分可能显得过于保守。例如，领导者只能直接提交当前任期的条目，即使在某些特殊情况下，它可以安全地提交先前任期的条目，采用更复杂的承诺规则将损害可理解性，不会对绩效产生显著影响；承诺仅在当前规则下被短暂延迟。在与其他人讨论Raft时，我们发现很多人不禁会想到这样的优化并提出，但当目标是可理解时，过早的优化应该被排除在外。</p> <p>​		不可避免的是，本章可能遗漏了一些在实践中有用的特征或优化。随着开发人员对Raft有了更多的经验，他们会学习什么时候以及为什么某些额外的功能可能是有用的，并且他们可能需要实现这些功能来进行一些实际的部署。在整个章节中，我们简述了一些我们目前认为不必要的可选扩展，但这可能有助于指导实施者应需而生。通过聚焦在可理解性上，我们希望已经为实施者根据经验调整Raft提供了坚实的基础。由于Raft在我们的测试环境中工作，我们希望这些是简单的扩展，而不是根本性的改变。</p> <h2 id="第四章"><a href="#第四章" class="header-anchor">#</a> 第四章</h2> <h3 id="群集成员资格更改"><a href="#群集成员资格更改" class="header-anchor">#</a> 群集成员资格更改</h3> <p>到目前为止，我们假设集群配置(参与共识算法的服务器集合)是固定的。在实际应用中，偶尔会需要改变配置，例如当服务器出现故障时更换或者改变复制的程度。这可以通过手动完成，使用两种方法之一：</p> <ul><li>配置更改可以通过离线取整个集群，更新配置文件，然后重新启动集群来完成。然而，这将使集群在转换期间不可用。</li> <li>或者，一个新的服务器可以通过获取一个集群成员的网络地址来替换该成员。但是，管理员必须保证被替换的服务器永远不会回来，否则系统将失去其安全属性(例如,会有额外的投票)。</li></ul> <p>这两种方法对成员资格的修改都有很大的缺点，如果有任何手动步骤，他们会冒着操作员出错的风险。</p> <p>​		为了避免这些问题，我们决定自动化配置更改，并将其纳入到Raft共识算法中。Raft允许集群在变化时继续正常运行，成员关系的变化只需对基本共识算法进行少量扩展即可实现。图4.1总结了用于改变聚类成员关系的RPCs，其元素在本章剩余部分进行了描述。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215125434632.png" alt="image-20231215125434632"></p> <h3 id="_4-1、安全性"><a href="#_4-1、安全性" class="header-anchor">#</a> 4.1、安全性</h3> <p>保持安全性是配置变更面临的第一个挑战。为了确保机制的安全，在过渡时期必须没有一点，在那里，有可能选举两位领导人担任同一任期。如果单个配置更改增加或删除了许多服务器，直接将集群从旧配置切换到新配置可能是不安全的；由于不可能一次性原子化地切换所有的服务器，因此在(见图4.2)的过渡过程中，集群可能会分裂成两个独立的多数。</p> <p>​		大多数成员变更算法都引入了额外的机制来处理这类问题。这就是我们最初为Raft所做的工作，但后来我们发现了一种更简单的方法，即不允许成员资格的改变，而这种改变可能会导致不相交的多数。因此，Raft限制了允许的变化类型：每次只能从集群中添加或移除一个服务器。更复杂的成员关系变化是通过一系列单服务器的变化来实现的。本章的大部分介绍了单服务器方法，它比我们原来的方法更容易理解。为了完整起见，4.3节描述了原始方法，该方法需要额外的复杂度来处理任意的配置更改。在光盘之前，我们在LogCabin中实现了更复杂的方法；在本文写作时，它仍然使用了更为复杂的方法</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215125855631.png" alt="image-20231215125855631"></p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215125910380.png" alt="image-20231215125910380"></p> <p>​		集群配置使用复制日志中的特殊条目进行存储和通信。这利用了Raft中已有的机制来复制和持久化配置信息。它还允许集群在配置更改进行时继续服务客户机请求，通过在配置更改和客户机请求(同时允许两者在管道和/或批次中同时复制)之间施加排序。</p> <p>​		当领导者收到从其当前配置( Cold )中添加或删除服务器的请求时，它将新的配置( Cnew )作为条目添加到其日志中，并使用普通的Raft机制复制该条目。新的配置在每个服务器的日志中添加后立即生效：Cnew条目被复制到Cnew服务器中，并且大部分新配置用于确定Cnew条目的承诺。这意味着服务器并不等待配置条目提交，每个服务器始终使用其日志中发现的最新配置</p> <p>​		一旦提交Cnew条目，配置更改就完成了。此时，领导知道大部分Cnew服务器都采用了Cnew。它还知道，任何没有移动到Cnew的服务器都不能再形成集群的多数，没有Cnew的服务器也不能当选领导者。Cnew的承诺让三件事情得以延续：</p> <p>1、领导可以承认配置变更的顺利完成。</p> <p>2、如果配置更改后移除一个服务器，则该服务器可以关闭。</p> <p>3、可以开始进一步的配置更改。在这一点之前，重叠的配置变化可能退化为不安全的情况，如图4.2中的情况。</p> <p>如前所述，服务器总是在其日志中使用最新的配置，而不管该配置条目是否已经提交。这使得领导人可以很容易地避免重叠的配置变化(以上第三项)，直到前一个变化的进入已经承诺，才开始新的变化。只有当旧集群的大多数已经转移到Cnew的规则下运行时，才可以安全地启动另一个成员变更。如果服务器只有当他们知道Cnew是承诺的时候才采用Cnew，那么Raft领导者将很难知道当旧集群的大多数已经采用了Cnew。他们需要跟踪哪些服务器知道表项的承诺，并且服务器需要将他们的承诺索引持久化到磁盘上；这两种机制在Raft中都不需要。相反，每个服务器只要在其日志中存在该条目就采用Cnew，并且领导者知道一旦提交了Cnew条目，就可以放心地允许进一步的配置更改。不幸的是，这个决定确实意味着一个配置更改的日志条目可以被删除(如果领导力发生变化)；在这种情况下，服务器必须做好准备，以便在其日志中回落到先前的配置。</p> <p>在Raft中，它是用于达成共识的调用者配置，既用于投票，也用于日志复制：</p> <ul><li>服务器接受不属于服务器最新配置的领导者的AppendEntries请求。否则，无法在集群(它永远不会接受在添加服务器的配置项之前的任何日志项)中添加新的服务器。</li> <li>服务器还将其投票授予不属于服务器最新配置(如果候选者有一个足够最新的日志和一个当前项)的候选者。这种投票可能偶尔需要，以保持集群可用。例如，考虑在三服务器集群中增加第四台服务器。如果一个服务器失败，则需要新服务器的投票来形成多数并选举一个领导者。</li></ul> <p>因此，服务器进行RPC请求的处理，而不需要知道它们当前的配置。</p> <h3 id="_4-2、有效性"><a href="#_4-2、有效性" class="header-anchor">#</a> 4.2、有效性</h3> <p>集群成员关系的变化在保持集群的可用性方面引入了一些问题。4.2 . 1节讨论了在新服务器加入集群之前对其进行追赶，使其不至于拖延新日志项的承诺；第4.2 . 2节讨论了如何逐步淘汰现有的领导者，如果它被从集群中移除；和4.2 . 3节描述了如何防止被移除的服务器破坏新集群的领导者。最后，第4.2 . 4节结尾论证了为什么产生的成员变更算法足以在任何成员变更期间保持可用性。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215130235022.png" alt="image-20231215130235022"></p> <h4 id="_4-2-1、追赶新的服务器"><a href="#_4-2-1、追赶新的服务器" class="header-anchor">#</a> 4.2.1、追赶新的服务器</h4> <p>当一个服务器被添加到集群中时，它通常不会存储任何日志条目。如果以这种状态添加到集群中，其日志可能需要相当长的时间才能赶上领导者的日志，在此期间，集群更容易出现不可用的情况。例如，一个三服务器集群通常可以容忍一次故障而不损失可用性。然而，如果在同一个集群中添加了一个具有空日志的第四个服务器，并且原有的三个服务器中的一个发生故障，则该集群将暂时无法提交新的条目( (见图4 . 4 ( a) )。如果在一个集群中快速连续地增加许多新的服务器，其中需要新的服务器来构成集群的大部分( (见图4 . 4 ( b) )，则可能会出现另一个可用性问题。在这两种情况下，直到新服务器的日志记录为止</p> <p>​		为了避免可用性差距，Raft在配置更改之前引入了一个额外的阶段，其中一个新的服务器作为无投票权的成员加入集群。领导人向其复制日志条目，但出于投票或承诺的目的，领导人尚未计入多数。一旦新的服务器赶上了集群的其余部分，重新配置可以如上所述进行。(支持无投票权服务器的机制在其他情况下也是有用的；例如，它可以用于将状态复制到大量的服务器上，这些服务器可以以宽松的一致性服务只读请求）。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215130324267.png" alt="image-20231215130324267"></p> <p>​		领导者需要确定何时一个新的服务器足够被赶上，以继续进行配置更改。这就需要一些小心来保持可用性：如果服务器添加的太快，集群的可用性可能会受到威胁，如上所述。我们的目标是在选举超时的情况下保持任何暂时的不可用性，因为客户必须能够容忍偶尔的不可用期，其数量级为(在领导者失败的情况下)。此外，如果可能的话，我们希望通过使新服务器的日志更接近领导者的日志来进一步最小化不可用性。</p> <p>​		如果新的服务器不可用或速度太慢以至于永远赶不上，领导者也应该中止变更。这个检查很重要：兰波特的古代帕克森政府因为没有包括它而崩溃了。他们无意中改变了会员资格，只由溺水的船员组成，并不能取得更多的进步[ 48 ]。试图添加一个不可用或者速度较慢的服务器往往是一个错误。事实上，我们的第一个配置更改请求在网络端口号中包含了一个错别字；系统正确地中止了变更并返回了一个错误。</p> <p>​		我们建议以下算法来确定什么时候一个新的服务器足够被赶上来添加到集群中。条目到新服务器的复制被拆分为多轮，如图4.5所示。每一轮将轮开始时出现在领导日志中的所有日志条目复制到新服务器的日志中。虽然它在复制本轮的条目，但新的条目可能会到达领导者；它将在下一轮中复制这些。随着时间的推移，回合持续期在时间上逐渐缩短。算法等待固定轮数(如10)。如果最后一轮的持续时间小于选举超时，则领导者将新服务器添加到集群中，假设没有足够的未复制条目来造成显著的可用性差距。</p> <p>​		否则，领导者以错误中止配置更改。打电话者可能总是再试一次(它将更有可能在下一次取得成功,因为新服务器的日志将已经被部分赶上)。</p> <p>​		作为追赶新服务器的第一步，领导者必须发现新服务器的日志是空的。有了新的服务器，AppendEntries中的一致性检查会反复失败，直到领导者的nextIndex最终下降为1。这种往返可能是在集群(在此阶段之后,日志项可以通过批处理的方式传递给RPC数量较少的跟随者)中添加新服务器的性能的主要因素。各种方法可以使next Index更快地收敛到其正确值，包括第3章所述的方法。然而，解决添加新服务器这一特殊问题的最简单方法是让追随者在AppendEntries响应中返回其日志的长度；这使得领导者可以限制跟随者的下一个指数acc</p> <h4 id="_4-2-2、撤销现任领导者"><a href="#_4-2-2、撤销现任领导者" class="header-anchor">#</a> 4.2.2、撤销现任领导者</h4> <p>如果要求现有的领导者将自己从集群中移除，那么它必须在某个时刻下台。一种直接的方法是使用第3章中描述的领导权转移扩展：一个被要求移除自身的领导者将其领导权转移到另一个服务器，然后正常地进行成员变更。</p> <p>​		我们最初为Raft开发了一种不同的方法，在这种方法中，现有的领导者进行成员变更来移除自己，然后它下台。这使得拉夫特处于一种比较尴尬的运作模式，而领导人暂时管理着一个不属于其成员的配置。我们最初需要这种方法来进行任意配置更改(见4.3节)，其中旧配置和新配置可能没有任何共同的服务器，可以将领导权转移到这些服务器上。同样的方法对于不实施领导权转移的系统也是可行的。</p> <p>​		在这种方法中，一旦提交了Cnew条目，从配置中移除的领导者就会下台。如果领导人在这一点之前下台，仍然可能会拖延时间，重新成为领导人，拖延进展。在从双服务器集群中移除领导者的极端情况下，服务器甚至可能必须重新成为集群的领导者才能取得进展；见图4.6。因此，领导人等到Cnew承诺下台。这是第一点，当新的配置可以在没有被撤销的领导者参与的情况下运行时：Cnew的成员总是有可能从他们自己中选出一个新的领导者。被撤换的领导人下台后，Cnew中的服务器将超时并赢得选举。这种小的可用性差距应该是可以容忍的，因为当领导者失败时，也会出现类似的可用性差距。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215130557557.png" alt="image-20231215130557557"></p> <p>​		这种方法导致了两个关于决策的影响，这些影响不是特别有害，但可能是令人惊讶的。首先，当一个领导者能够管理一个不包含自身的集群时，会有一段时间(而正在进行Cnew)；它复制日志条目，但不计算大多数。其次，一个不属于自己最新配置的服务器仍然应该开始新的选举，因为在Cnew条目提交(如图4.6所示)之前可能仍然需要它。它在选举中不计算自己的选票，除非它是其最新配置的一部分。</p> <h4 id="_4-2-3、中断服务器"><a href="#_4-2-3、中断服务器" class="header-anchor">#</a> 4.2.3、中断服务器</h4> <p>​		在没有额外机制的情况下，不在Cnew中的服务器会破坏集群。一旦集群领导者创建了Cnew入口，不在Cnew中的服务器将不再收到心跳，因此它将超时并开始新的选举。此外，它不会收到Cnew条目，也不会得知该条目的承诺，因此它不会知道它已经从集群中移除。服务器将向RequestVote RPC发送新的项号，这将导致当前领导者恢复到跟随者状态。来自Cnew的新领导者最终会被选举出来，但是颠覆性的服务器会再次被淘汰，过程会重复，导致可用性差。如果从集群中删除了多个服务器，情况可能会进一步恶化。</p> <p>​		我们消除干扰的第一个想法是，如果一个服务器要开始选举，它将首先检查它不会浪费每个人的时间- -它有机会赢得选举。这就为选举引入了一个新的阶段，称为预投票阶段。候选人首先会询问其他服务器的日志是否更新到足以获得他们的投票。只有当候选人相信它可以从大多数集群中获得选票时，它才会增加其任期并开始正常的选举。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215130701908.png" alt="image-20231215130701908"></p> <p>​		遗憾的是，Pre - Vote阶段并没有解决颠覆性服务器的问题：存在颠覆性服务器的日志足够最新的情况，但启动选举仍将是颠覆性的。或许令人惊讶的是，这些甚至可以在配置变更完成之前发生。例如，图4.7显示了一个正在从集群中移除的服务器。一旦领导者创建了Cnew日志条目，被移除的服务器就可能是颠覆性的。在这种情况下，Pre - Vote检查无能为力，因为被移除的服务器有一个日志，它比任何一个集群中的大多数日志更新快。(尽管预投票阶段并没有解决干扰服务器的问题,但它确实是提高领导人选举鲁棒性的一个有用的想法。见第9章。)</p> <p>​		由于这种情况，我们现在认为，没有一个基于比较日志的解决方案，仅仅是(如&quot;投票前检查&quot;)就足以说明选举是否会产生破坏性。我们不能要求一个服务器在开始选举之前检查Cnew中每个服务器的日志，因为Raft必须始终能够容忍错误。我们也不希望假设一个领导者会可靠地复制足够快的条目，以快速通过图4.7所示的场景；这可能在实际中奏效，但这取决于我们更倾向于避免的更强的假设，即查找日志偏离的位置的性能和复制日志条目的性能。</p> <p>​		Raft的解决方案使用心跳来确定何时存在有效的领导者。在Raft中，如果一个领导者能够维持其追随者(否则,另一个服务器将启动选举)的心跳，则被认为是活跃的。因此，服务器不应该能够打乱集群正在接收心跳的领导者。我们对RequestVote RPC进行修改以实现这一点：如果服务器在当前领导人听证的最低选举超时时间内收到RequestVote请求，则不更新其任期或授予其投票权。它既可以拒绝请求，以投票否决的方式回复，也可以延迟请求；结果本质上是相同的。这并不影响正常的选举，每个服务器在开始选举之前至少等待一个最小的选举超时。然而，它有助于避免来自不在Cnew中的服务器的中断：当一个领导者能够获得其集群的心跳时，它不会被更大的术语数所取代。</p> <p>​		这一变化与第3章所述的领导权转移机制相冲突，在该机制中，服务器在不等待选举超时的情况下合法启动选举。在这种情况下，RequestVote消息应该被其他服务器处理，即使他们相信当前的集群领导者存在。那些RequestVote请求可以包含一个特殊的标志来表示这种行为( &quot;我有权破坏领导人- -它告诉我的! &quot;)。</p> <h4 id="_4-2-4、可用性论证"><a href="#_4-2-4、可用性论证" class="header-anchor">#</a> 4.2.4、可用性论证</h4> <p>本部分认为，上述解决方案足以在成员资格变更期间保持可用性。由于Raft的成员变更是基于领导者的，我们证明了该算法将能够在成员变更时维护和替换领导者，并且领导者将既服务客户端请求又完成配置变更。除此之外，我们假设大多数旧的配置是可用的(至少直到Cnew承诺)，而大多数新的配置是可用的。</p> <p>1 、在配置变更的所有步骤都可以选举出一名领导者：</p> <ul><li>如果在新集群中拥有最新日志的可用服务器拥有Cnew条目，它可以从大多数Cnew中收集选票，并成为领导者。</li> <li>否则，Cnew进入必须尚未承诺。在旧集群和新集群中拥有最新日志的可用服务器可以收集大多数Cold和大多数Cnew的投票，因此无论它使用哪种配置，它都可以成为领导者。</li></ul> <p>2 、领导者一旦当选就被维持，假设其心跳通过其配置，除非它故意下台，因为它不在Cnew但已承诺Cnew。</p> <ul><li>如果一个领导者能够可靠地将心跳发送到自己的配置中，那么它和它的追随者都不会采用更高的期限：他们不会抽出时间开始任何新的选举，他们会忽略来自其他服务器的任何期限更高的RequestVote消息。因此，领导人不会被迫下台。</li> <li>如果一个不在Cnew中的服务器提交了Cnew条目并下台，那么Raft将选举一个新的领导者。很可能这个新的领导者将是Cnew的一部分，允许配置更改来完成。然而，有一些(小的)风险，即下台的服务器可能再次成为领导者。如果再次当选，它将确认Cnew进入的承诺，并很快下台，而Cnew中的服务器再次有可能在下一次成功。</li></ul> <p>3、在整个配置更改过程中，领导者将为客户端请求提供服务。</p> <ul><li>在整个变更过程中，领导者可以继续将客户请求添加到日志中</li> <li>由于新的服务器在加入集群之前就被赶上了，领导者可以提前提交索引并及时回复给客户。</li></ul> <p>4、领导者通过提交Cnew，并在必要时下台，让Cnew中的一个服务器成为领导者，从而实现并完成配置更改。</p> <p>因此，在上述假设下，本部分所描述的机制足以在任何成员资格变更期间保持可用性。</p> <h3 id="_4-3、使用联合共识进行任意配置变化"><a href="#_4-3、使用联合共识进行任意配置变化" class="header-anchor">#</a> 4.3、使用联合共识进行任意配置变化</h3> <p>本节提出一种更复杂的集群成员变更方法，可以一次性处理对配置的任意更改。例如，在一个集群中可以同时增加两台服务器，或者在一个五台服务器集群中可以同时更换所有的服务器。这是我们提出的第一个成员变化的方法，它仅用于完整性的描述。既然我们已经知道了更简单的单服务器方法，那么我们建议采用单服务器方法，因为处理任意变化需要额外的复杂度。任意变化通常是文献中假设成员变化的操作方式，但我们认为在实际系统中不需要这种灵活性，在实际系统中，一系列单服务器变化可以将集群成员变化为任何想要的配置。在实际系统中，一系列单服务器变化可以将集群成员变化为任何想要的配置。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215131231731.png" alt="image-20231215131231731"></p> <p>为了确保在任意配置变化时的安全性，集群首先切换到一个过渡配置，我们称之为联合一致性；一旦达成了共同的共识，系统就会过渡到新的配置。联合共识结合了旧构型和新构型：</p> <ul><li>日志项在两种配置下都被复制到所有服务器。</li> <li>来自任一配置的任何服务器都可以充当领导者。</li> <li>(对于选举和参赛的承诺)协议要求从旧的和新的配置中分离出大多数。例如，当从3台服务器组成的集群变为9台服务器组成的集群时，协议要求旧配置中的3台服务器中的2台和新配置中的9台服务器中的5台。</li></ul> <p>联合共识允许单个服务器在不同时间在配置之间进行转换，而不会损害安全性。此外，联合共识允许集群在整个配置更改期间继续服务客户端请求。</p> <p>​		该方法扩展了单服务器成员变更算法，为联合配置提供了中间日志项；图4.8说明了这一过程。当领导者收到将配置从Cold更改为Cnew的请求时，它将联合共识的配置(冷,图中为新)存储为一个日志条目，并使用普通的Raft机制复制该条目。与单服务器配置更改算法一样，每台服务器在其日志中存储配置后，就开始使用新的配置。这意味着，领导者将使用Cold，new的规则来确定Cold，new的日志条目何时提交。如果领导人崩溃，根据获胜候选人是否获得了Cold，new，可以在Cold或Cold，new下选择新的领导人。无论如何，Cnew在此期间不能做出单方面的决定。</p> <p>​		一旦Cold，new已经提交，Cold和Cnew都不能在未经对方批准的情况下做出决策，并且Leader Completeness Property保证只有具有Cold，new日志项的服务器才能被选为Leader。现在，领导者创建一个描述Cnew的日志条目并将其复制到集群是安全的。再次，这种配置一经看到就会在每台服务器上生效。当Cnew日志项在Cnew的规则下已经提交时，旧的配置是不相关的，不在新配置中的服务器可以被关闭。如图4.8所示，不存在Cold和Cnew都可以进行单边决策的时刻；这就保证了安全性。</p> <p>​		联合一致性方法可以推广到允许配置更改开始时，而事先的更改仍在进行中。然而，这样做并没有太大的实际好处。相反，当配置更改已经在进行(当它的最新配置没有承诺或不是简单的多数时)时，领导者拒绝额外的配置更改。以这种方式被拒绝的变化可以简单地等待，稍后再试一次。</p> <p>​		这种联合一致性方法比单服务器的变化更复杂，因为它需要从中间配置过渡到中间配置。联合配置还要求改变所有投票和承诺决策的方式；而不是简单地计数服务器，领导者必须检查服务器是否形成了旧集群的大部分，同时也形成了新集群的大部分。在我们的Raft实现中，实现这一点需要发现和改变大约六个比较[ 86 ]。</p> <h3 id="_4-4、系统集成"><a href="#_4-4、系统集成" class="header-anchor">#</a> 4.4、系统集成</h3> <p>Raft实现可能会以不同的方式暴露本章所描述的集群成员变化机制。例如，图4.1中的AddServer和RemoveServer RPC可以由管理员直接调用，也可以由脚本调用，脚本使用一系列单服务器步骤以任意方式更改配置。为了响应服务器故障等事件，自动调用成员资格更改可能是可取的。然而，这只能根据合理的政策来完成。例如，集群自动移除失败的服务器可能是危险的，因为它可能会留下太少的副本来满足预定的耐久性和容错性要求。一种合理的方法是让系统管理员配置一个期望的集群大小，在这个约束范围内，可用的服务器可以自动替换失败的服务器。</p> <p>​		当进行需要多个单服务器步骤的簇成员身份变更时，最好在移除服务器之前添加服务器。例如，在三台服务器集群中更换一台服务器，增加一台服务器，然后移除另一台服务器，可以让系统在整个过程中随时处理一台服务器的故障。然而，如果一个服务器先被移除，另一个服务器再被添加，系统将暂时无法屏蔽任何故障(因为双服务器集群要求两台服务器都可用)。</p> <p>​		成员资格的变化激发了一种不同的方法来引导一个集群。在没有动态成员的情况下，每个服务器只有一个静态文件列出配置。随着动态成员关系的变化，不再需要静态配置文件，因为系统在Raft日志中管理配置；它也是潜在的易错的(例如,在哪种配置下应该初始化一个新的服务器?)。相反，我们建议在第一次创建集群时，将一个服务器初始化为一个配置条目，作为其日志中的第一个条目。这种配置只列出一个服务器；它单独形成它的大部分配置，因此它可以考虑这种配置承诺。从那时起，其他服务器应该用空日志初始化；它们被添加到集群中，并通过成员变化机制学习当前配置。</p> <p>成员关系的变化也需要一种动态的方法来帮助客户找到聚类；这在第六章中进行了讨论。</p> <h3 id="_4-5、总结"><a href="#_4-5、总结" class="header-anchor">#</a> 4.5、总结</h3> <p>本章描述了对Raft的扩展，用于自动处理集群成员关系的变化。这是一个完整的基于共识的系统的重要组成部分，因为容错需求可以随着时间的推移而改变，最终需要更换失败的服务器。</p> <p>​		由于新的配置会影响&quot;多数&quot;的含义，因此共识算法必须从根本上参与维护配置变化的安全性。本章提出了一种简单的方法，即一次添加或移除单个服务器。这些操作简单地保护了安全性，因为在变化期间至少有一个服务器重叠了任何大多数。多个单服务器的变化可能会组合在一起，以更大幅度地修改集群。Raft允许集群在成员关系发生变化时继续正常运行。</p> <p>​		在配置更改时保持可用性需要处理几个非平凡的问题。特别是，一个不在新配置中的服务器扰乱有效的集群领导者的问题出人意料地微妙；在解决基于心跳的工作方案之前，我们在基于日志比较的几个不充分的解决方案中挣扎。</p> <h2 id="第五章"><a href="#第五章" class="header-anchor">#</a> 第五章</h2> <h3 id="日志压缩"><a href="#日志压缩" class="header-anchor">#</a> 日志压缩</h3> <p>Raft的日志在正常运行期间增长，因为它包含了更多的客户端请求。随着它的变大，它占据了更多的空间，需要更多的时间来重播。如果没有某种方法来压缩日志，这将最终导致可用性问题：服务器要么会耗尽空间，要么启动时间过长。因此，对于任何实际系统，某种形式的日志压缩都是必要的。</p> <p>​		日志压缩的一般思想是日志中的大部分信息随着时间的推移而变得过时，可以被丢弃。例如，将x设置为2的操作，如果后面的操作将x设置为3，则该操作将过时。一旦日志条目被提交并应用到状态机中，用于到达当前状态的中间状态和操作就不再需要，它们可以被压缩。</p> <p>​		不同于核心的Raft算法和隶属度变化，不同的系统在涉及到日志压缩时会有不同的需求。由于种种原因，日志压缩没有一个放之四海而皆准的解决方案。首先，不同的系统可能会在不同程度上权衡简单性和性能。其次，状态机必须密切参与日志压缩，并且状态机在大小和是否基于磁盘或易失性内存方面存在很大差异</p> <p>​		本章的目标是讨论日志压缩的多种方法。在每种方法中，日志压缩的大部分责任都落在状态机上，状态机负责将状态写入磁盘，并对状态进行压缩。状态机可以通过不同的方式来实现这一点，这在整个章节中进行了描述，并在图5.1中进行了总结：</p> <ul><li>对于基于内存的状态机，快照是概念上最简单的方法。在快照中，整个当前系统状态被写入到一个稳定存储的快照中，然后丢弃到该点的整个日志。在Chubby [ 11、15]和ZooKeeper [ 38 ]中使用了快照技术，我们在LogCabin中实现了快照。快照是本章最深入的方法，见5.1节</li> <li>在基于磁盘的状态机中，作为正常运行的一部分，系统状态的最近副本被维护在磁盘上。因此，只要状态机向磁盘反映写操作，就可以丢弃Raft日志，只有在向其他服务器发送一致的磁盘映像时才使用快照( 5.2节)。</li> <li>增量式日志压缩方法，如日志清理和日志结构合并树，在5.3节中介绍。这些方法高效地写入磁盘，并随着时间的推移均衡地利用资源。</li> <li>最后，第5.4节讨论了一种日志压缩方法，该方法最大限度地减少了直接在日志中存储快照所需的机制。这种方法虽然更容易实现，但只适用于非常小的状态机。</li></ul> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215131907108.png" alt="image-20231215131907108"></p> <p>Log Cabin目前只实现了基于内存的快照方法(它嵌入了一个基于内存的状态机)。</p> <p>​		压缩的各种方法共享几个核心概念。首先，每个服务器独立地压缩其日志的承诺前缀，而不是将合并决策集中在领导者身上。这就避免了领导者将数据传输给已经拥有日志中数据的跟随者。它还有助于模块化：日志压缩的大部分复杂性包含在状态机中，并且与Raft本身没有太大的相互作用。这有助于将整个系统的复杂性降到最低：Raft的复杂性增加，而不是与日志压缩的复杂性相乘。在5.4 (而对于非常小的状态机,基于leader的方法可能更好)节中，进一步讨论了将压实责任集中在领导者身上的其他方法。</p> <p>​		其次，状态机和Raft之间的基本交互涉及将日志前缀的责任从Raft转移到状态机。状态机在应用条目后迟早会将这些条目反映到磁盘上，以恢复当前系统状态。一旦这样做，它就告诉Raft丢弃日志的相应前缀。在Raft放弃对日志前缀的责任之前，它必须保存自己描述日志前缀的一些状态。具体来说，Raft保留了其舍弃的最后一个条目的指数和期限；这将日志的其余部分锚定在状态机的状态之后，并允许AppendEntries一致性检查继续工作(它需要在lo中第一个条目之前的条目的索引和术语。Raft还从丢弃的日志前缀中保留最新的配置，以支持集群成员资格的更改。</p> <p>​		第三，一旦Raft丢弃了日志的一个前缀，状态机就承担了两个新的责任。如果服务器重新启动，则状态机需要从磁盘加载被丢弃的日志条目对应的状态，才能应用Raft日志中的任何条目。此外，状态机可能需要产生状态的一致映像，以便可以将其发送给慢跟随者(其日志远远落后于领导者的日志)。延迟合并是不可行的，直到日志条目被&quot;完全复制&quot;到集群中的每个成员，因为少数慢跟随者不能保持集群的完全可用性，并且可以随时向集群中添加新的服务器。因此，慢跟随者或新的服务器偶尔需要在网络上接收他们的初始状态。当AppendEntries中需要的下一个条目在领导者的日志中已经被丢弃时，Raft会检测到这一点。在这种情况下，状态机必须提供一个一致的状态映像，领导者然后发送给跟随者。</p> <h3 id="_5-1、基于内存的状态机快照"><a href="#_5-1、基于内存的状态机快照" class="header-anchor">#</a> 5.1、基于内存的状态机快照</h3> <p>第一种快照方法适用于状态机的数据结构保存在内存中的情况。这对于数据集在千兆字节或几十兆字节的状态机是一个合理的选择。它使操作能够快速完成，因为它们不需要从磁盘中获取数据；编程也很容易，因为可以使用丰富的数据结构，每次操作都可以运行到完成(无I / O阻塞)。</p> <p>​		图5.2展示了当状态机保存在内存中时，Raft中快照的基本思想。每个服务器独立地进行快照，只覆盖其日志中提交的条目。快照中的大部分工作都涉及到序列化状态机的当前状态，而这是针对特定的状态机实现的。例如，LogCabin的状态机使用树作为其主要的数据结构；它使用前序深度优先遍历(这样,在应用快照时,父节点先于子节点创建)对这棵树进行序列化。为了向客户端(见第6章)提供线性化能力，状态机还必须序列化它们所保存的信息。</p> <p>​		一旦状态机完成写快照，日志可以被截断。Raft首先存储重启所需的状态：快照中包含的最后一个条目的索引和项，以及该索引的最新配置。然后通过该索引丢弃其登录的前缀。任何以前的快照也可以被丢弃，因为它们不再有用。</p> <p>​		如前所述，领导者可能偶尔需要将其状态发送给慢速跟随者和正在加入集群的新服务器。在快照中，这个状态只是最新的快照，领导者使用一个名为InstallSnapshot的新RPC进行传输，如图5.3所示。当跟随者接收到这个RPC的快照时，它必须决定对其现有的日志条目做什么。通常快照会包含跟随者日志中尚未包含的新信息。在这种情况下，跟随者丢弃它的整个日志；它全部被快照所替代，并且可能存在与快照冲突的未提交项。相反，如果跟随者收到描述其日志(由于重传或误传)前缀的快照，则删除快照覆盖的日志条目，但快照后面的条目仍然有效，必须保留。</p> <p>​		本节余下部分将讨论基于内存的状态机快照的次要问题：</p> <ul><li>5.1 . 1节讨论了如何产生与正常操作并行的快照，以尽量减少它们对客户端的影响；</li> <li>5.1 . 2节讨论了何时进行快照，平衡了空间占用和快照开销</li> <li>第5.1 . 3节讨论了在实现快照时出现的问题。</li></ul> <h4 id="_5-1-1、并发快照"><a href="#_5-1-1、并发快照" class="header-anchor">#</a> 5.1.1、并发快照</h4> <p>创建快照可以花费很长的时间，无论是序列化状态还是写入磁盘。例如，在当今的服务器上复制10 GB的内存大约需要一秒钟，而将其序列化通常需要更长的时间：即使是固态硬盘也只能在一秒钟内写入约500 MB。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215132347776.png" alt="image-20231215132347776"></p> <p>因此，序列化快照和写入快照都必须与正常操作并发，以避免可用性缺口。</p> <p>幸运的是，写时复制技术允许在不影响正在写入的快照的情况下应用新的更新。对此，有两种途径：</p> <ul><li>状态机可以用不可变(函数)的数据结构来构建，以支持这一点。由于状态机命令不会对状态进行修改，因此快照任务可以保持对某个先验状态的引用，并将其一致地写入快照中。</li> <li>或者，操作系统的写时拷贝支持可以使用(在编程环境允许的地方)。以Linux为例，内存状态机可以使用fork复制服务器的整个地址空间。然后，子进程可以写出状态机的状态和退出，父进程继续服务请求。LogCabin的实现目前采用这种方法</li></ul> <p>服务器需要额外的内存来并发地进行快照，这需要对快照进行规划和管理。对于状态机来说，对快照文件有一个流式接口是必不可少的，这样快照在创建时就不必完全在内存中上演。尽管如此，复制-写需要额外的内存，这与快照过程中改变的状态机状态的比例成正比。此外，依赖操作系统进行写时拷贝通常会因为错误共享而占用更多的内存(例如,如果两个不相关的数据项恰好在同一个内存页上,那么即使只有第一个数据项发生了变化,第二个数据项也会被重复)。在快照期间内存容量耗尽的不幸事件中，服务器应该停止接受新的日志条目，直到它完成快照；这会暂时牺牲服务器的可用性(该团簇可能仍然存在)，但至少可以让服务器恢复。最好不要中止快照，稍后再重试，因为下一次尝试也可能面临同样的问题。( LogCabin使用了一个流式的磁盘接口,但它目前不能很好地处理内存耗尽问题。)</p> <h4 id="_5-1-2、何时进行快照"><a href="#_5-1-2、何时进行快照" class="header-anchor">#</a> 5.1.2、何时进行快照</h4> <p>服务器必须决定何时进行快照。如果服务器快照次数过多，就会浪费磁盘带宽和其他资源；如果它的快照过于频繁，它有耗尽其存储容量的风险，并且它增加了在重启期间重放日志所需的时间。</p> <p>​		一种简单的策略是当日志以字节为单位达到固定大小时进行快照。如果将该大小设置为显著大于快照的预期大小，则快照所需的磁盘带宽开销较小。然而，这会导致小型状态机产生不必要的大日志。</p> <p>​		一种更好的方法是将快照的大小与日志的大小进行比较。如果快照会比日志小很多倍，那么拍摄快照可能是值得的。然而，在快照被拍摄之前计算快照的大小可能是困难和繁重的，给状态机带来了巨大的记账负担，或者需要几乎与实际拍摄快照一样多的工作来动态计算快照的大小。压缩快照文件也会带来空间和带宽的节省，但是很难预测压缩后的输出会有多大。</p> <p>​		幸运的是，使用上一个快照的大小而不是下一个快照的大小可以得到合理的行为。服务器取一次快照，一旦日志的大小超过前一次快照的大小，则可配置扩展因子。扩展因子以磁盘带宽换取空间利用率。例如，扩展因子为4导致大约20 %的磁盘带宽被用于快照(对于每1字节的快照,将写入4字节的日志条目)，并且需要大约6倍的磁盘容量来存储状态(旧快照,一个日志比这个大4倍,而新快照正在写入)的单个副本。</p> <p>​		快照仍然会造成CPU和磁盘带宽的突发使用，这可能会影响客户端的性能。这可以通过增加额外的硬件来缓解；例如，可以使用第二个磁盘驱动器来提供额外的磁盘带宽。</p> <p>​		它也可能以客户端请求永远不会在正在快照的服务器上等待的方式来调度快照。在这种方法中，服务器将进行协调，以便在任何时候(可能的情况下)，集群中只有最多少数的服务器将被快照。由于Raft只需要大多数服务器提交日志记录，所以少数的快照服务器通常不会对客户端产生不利影响。当一个领导者希望快照时，它将首先下台，同时允许另一个服务器来管理集群。如果这种方法足够可靠，它还可以消除并发快照的需要；服务器在拍摄快照(尽管它们会依赖集群掩盖故障的能力)时可能无法使用。这对于未来的工作是一个令人兴奋的机会，因为它既可以提高系统的整体性能，又可以减少机制。</p> <h4 id="_5-1-3、实现关系"><a href="#_5-1-3、实现关系" class="header-anchor">#</a> 5.1.3、实现关系</h4> <p>该部分回顾了快照实现所需的主要组件，并讨论了实现这些组件的困难：</p> <ul><li>保存和加载快照：保存快照涉及到序列化状态机的状态并将数据写出到文件中，而加载则是相反的过程。我们发现这是相当直接的，尽管从它们的原生表示中序列化各种类型的数据对象有些繁琐。从状态机到磁盘上文件的流式接口可以避免在内存中缓冲整个状态机的状态；压缩流并对其进行校验和也可能是有益的。LogCabin首先将每个快照写入一个临时文件，然后在写完并被刷新到磁盘时重命名该文件；这保证了在启动时没有服务器加载部分写入的快照。</li> <li>迁移快照：迁移快照涉及实现InstallSnapshot RPC的领导者和跟随者端。这相当简单，并且可以通过保存快照和从磁盘加载快照来共享一些代码。这种传输的性能通常不是很重要的(一个需要这种状态的追随者一直没有参与到条目的承诺中,所以可能很快就不需要了;另一方面,如果集群遭受额外的故障,它可能需要追赶跟随者来恢复可用性)。</li> <li>消除不安全的日志访问和丢弃日志条目：我们最初设计的LogCabin没有担心日志压缩，因此代码假设如果日志中存在条目i，从i - 1到i - 1的条目也会存在。这在对数压缩情况下不再成立；例如，在Append Entries RPC中确定前一个条目的期限时，该条目可能已经被丢弃。在整个代码中去除这些假设需要仔细的推理和测试。如果编译器能够强制每个对日志的访问都能处理索引越界的情况，那么在更强大的类型系统的帮助下，这会更容易。一旦我们使所有的日志访问都是安全的，丢弃日志的前缀是很简单的。到此为止，我们只能孤立地测试快照的保存、加载和传输，但当日志条目可以被安全地丢弃时，这些都可以在系统级测试中开始执行。</li> <li>快照与写时拷贝并发：并发快照可能需要重写状态机或者利用操作系统的fork操作。Log Cabin目前使用的是fork，与线程和C + +析构函数的交互较差；要正确地进行这项工作提出了一些困难。但是，它的代码量很小，完全不需要修改状态机的数据结构，因此我们认为它是正确的方法。</li> <li>决定何时进行快照：我们建议在开发过程中应用每个日志条目后进行快照，因为这样可以帮助快速捕获bug。一旦实现完成，应该添加一个更有用的何时快照的策略(例如,使用关于Raft日志大小和最后一个快照大小的统计)。</li></ul> <p>我们发现分段开发和测试快照是具有挑战性的。在可能丢弃日志项之前，这些组件中的大部分必须就位，但只有这样，许多新的代码路径才会在全系统测试中使用。因此，实施者应该仔细考虑这些组件的实现和测试顺序。</p> <h3 id="_5-2、基于磁盘状态机的快照"><a href="#_5-2、基于磁盘状态机的快照" class="header-anchor">#</a> 5.2、基于磁盘状态机的快照</h3> <p>本节讨论了使用磁盘作为记录主要位置的大型状态机(在几十或几百千兆字节的量级上)的快照方法。这些状态机的不同之处在于，在发生崩溃的情况下，它们总是在磁盘上准备好状态的副本。应用Raft日志中的每个条目，会使磁盘状态发生变异，有效地到达一个新的快照。因此，一旦一个条目被应用，它就可以从Raft日志中被丢弃。(状态机还可以缓冲内存中的写操作,以期获得更好的磁盘效率;一旦它们被写入磁盘,相应的条目就可以从Raft日志中被丢弃。)</p> <p>​		基于磁盘的状态机的主要问题是磁盘上的状态突变会导致性能下降。在没有写缓冲的情况下，每个应用的命令都需要一个或多个随机的磁盘写操作，这会限制系统的整体写吞吐量(而写缓冲可能帮助不大)。第5.3节讨论了日志压缩的增量方法，这些方法通过大的、顺序的写操作更有效地写入磁盘。</p> <p>​		基于磁盘的状态机必须能够提供磁盘的一致快照，以便将其传输给慢速跟随者。虽然他们总是在磁盘上有一个快照，但是他们在不断地修改它。因此，它们仍然需要写时拷贝技术来保留足够长的时间来传输一致的快照。幸运的是，磁盘格式几乎总是被划分成逻辑块，因此在状态机中实现写时拷贝应该是直接的。基于磁盘的状态机也可以依赖操作系统对其快照的支持。例如，Linux上的LVM (逻辑卷管理)可用于创建整个磁盘分区的快照[ 70 ]，最近的一些文件系统允许对单个目录进行快照[ 19 ]。</p> <p>​		复制磁盘映像的快照会花费很长的时间，并且随着对磁盘的修改增加，保留快照所需的额外磁盘使用量也会增加。虽然我们还没有实现基于磁盘的快照，但是我们推测基于磁盘的状态机可以通过下面的算法传输它们的磁盘内容来避免大部分的开销：</p> <p>1、对于每个磁盘块，跟踪其上次被修改的时间。</p> <p>2、在继续正常运行的同时，将整个磁盘的内容逐块传输给一个跟随者。在这个过程中，领导者没有使用额外的磁盘空间。由于块同时被修改，这很可能导致在跟随者上的磁盘图像不一致。由于每个块都是从领导者那里转移过来的，记下它的最后一次修改时间。</p> <p>3、对磁盘内容进行写时拷贝快照。一旦采取这种措施，领导者对其磁盘内容具有一致的副本，但由于持续的客户操作而使用额外的磁盘空间作为对磁盘的修改。</p> <p>4、仅重传步骤2中首次传输时与步骤3中拍摄快照时之间被修改的磁盘块。</p> <p>希望在步骤3中创建时，一致性快照的大部分块已经被传输。如果是这种情况，第4步中的传输将快速进行：在第4步期间用于保留领导者上的快照的额外磁盘容量将较低，在第4步期间用于重传修改块的额外网络带宽也将较低。</p> <h3 id="_5-3、增量清除方法"><a href="#_5-3、增量清除方法" class="header-anchor">#</a> 5.3、增量清除方法</h3> <p>增量合并的方法，如日志清理[ 97、98 ]和日志结构合并树[ 84、17 ] ( LSM树)，也是可能的。虽然它们比快照更复杂，但增量方法有几个可取的特征：</p> <ul><li>它们一次只对一小部分数据进行操作，因此它们将压实的载荷随时间均匀地分布。</li> <li>它们在正常工作和压缩时都能高效地写入磁盘。在这两种情况下，它们都使用大的、顺序的写法。增量方法还选择性地压缩磁盘中具有最大可回收空间的部分，因此，与基于内存的状态机(它在每个快照上重写所有的磁盘)的快照相比，它们向磁盘写入的数据更少。</li> <li>它们可以相当容易地传输一致的状态快照，因为它们不会修改磁盘的区域。</li></ul> <p>第5.3 . 1节和第5.3 . 2节首先从总体上描述了日志清理和LSM树的基础知识。然后，第5.3 . 3节讨论了它们如何应用于Raft。</p> <h4 id="_5-3-1、日志清除的基础知识"><a href="#_5-3-1、日志清除的基础知识" class="header-anchor">#</a> 5.3.1、日志清除的基础知识</h4> <p>日志清理是在日志结构文件系统[ 97 ]的背景下引入的，最近被提出用于内存存储系统，如内存云[ 98 ]。原则上，日志清理可以用于任何类型的数据结构，尽管有些数据结构比其他数据结构更难有效地实现。</p> <p>​		日志清理维护日志作为系统状态的记录场所。版图被优化为顺序写入，并使读操作有效地随机访问。因此，需要索引结构来定位要读取的数据项。</p> <p>​		在日志清洗中，日志被分割成连续的区域，称为段。日志清理器的每一遍都使用三步算法对日志进行压缩：</p> <ul><li>它首先选择已经积累了大部分过时条目的片段进行清洗。</li> <li>然后，它将这些段的活表项(那些有助于当前系统状态的因素)拷贝到日志的头部。</li> <li>最后，它为片段释放了存储空间，使得该空间可用于新的片段。</li></ul> <p>为了尽量减少对正常运行的影响，这个过程可以同时进行[ 98 ]。</p> <p>​		由于将实时条目转发复制到日志头，条目会变得杂乱无章以备回放。条目可以包含额外的信息(例如,版本号)，以便在应用日志时重新创建正确的排序。</p> <p>​		选择哪个细分领域进行清理的政策对绩效有较大影响；先前的工作提出了一个成本效益政策，该政策不仅考虑了活动条目所使用的空间数量，而且还考虑了这些条目可能保持活[ 97、98 ]的时间。</p> <p>​		判断条目是否活着是国家机器的职责。例如，在语义相关商店中，如果密钥存在且当前设置为给定值，则设置某个特定值的密钥的日志项是活的。判断一个删除了密钥的日志条目是否为活的更微妙：只要在日志中存在任何设置该密钥的先前条目，都是活的。内存云根据需要保留删除命令(称为墓碑) [ 98 ]，但另一种方法是定期写出当前状态中存在的密钥的摘要，那么所有关于未列出密钥的日志条目都不会活着。Key - value商店就是一个非常简单的例子；其他的状态机是可能的，但不幸的是，每个状态机的活性判定是不同的。</p> <h4 id="_5-3-2、日志结构合并树的基础知识"><a href="#_5-3-2、日志结构合并树的基础知识" class="header-anchor">#</a> 5.3.2、日志结构合并树的基础知识</h4> <p>对数结构合并树( LSM树)最早由O ' Neil [ 84 ]描述，后来由大表[ 17 ]在分布式系统中推广。它们在Apache卡珊德拉[ 1 ]、HyperDex [ 27 ]等系统中使用，在LevelDB [ 62 ]及其forks (例如, RocksDB 和Hyper LevelDB )等库中可用。</p> <p>​		LSM树是存储有序键值对的树状数据结构。在较高的级别上，它们使用与日志清理方法类似的磁盘：它们以较大的顺序跨步写入，并且不修改磁盘上的数据。然而，LSM树不是维护日志中的所有状态，而是对状态进行重组，以便更好地进行随机访问</p> <p>​		一个典型的LSM树将最近写入的密钥保存在磁盘上的一个小日志中。当日志达到固定大小时，将其按键排序并写入文件中，称为按排序顺序的运行。游程从不被修改到位，而是一个压缩过程周期性地将多个游程合并在一起，产生新的游程并丢弃旧的游程。这种合并让人联想到合并排序；当一个密钥在多个输入游程中时，只保留最新的版本，因此产生的游程更加紧凑。LevelDB中使用的合并策略在图5.1中进行了总结；它按年龄对效率(类似于日志的清洗)进行分离。</p> <p>​		在正常运行时，状态机可以直接对这些数据进行操作。为了读取一个密钥，它首先检查该密钥是否在其日志中最近被修改，然后检查每个运行。为了避免在每次查找中检查每个键的运行，一些系统为每个运行(一种紧凑的数据结构,在某些情况下可以肯定地说,一个键在一个游程中不出现,尽管它有时可能需要搜索一个游程,即使键不出现)创建一个布隆过滤器。</p> <h4 id="_5-3-3、raft中的日志清理和日志结构合并树"><a href="#_5-3-3、raft中的日志清理和日志结构合并树" class="header-anchor">#</a> 5.3.3、Raft中的日志清理和日志结构合并树</h4> <p>我们没有尝试在Raft中实现日志清理或LSM树，但我们猜测两者都能很好地工作。将LSM树应用于Raft似乎相当简单。由于Raft日志已经将最近的表项持久地存储在磁盘上，因此LSM树可以将最近的数据以更方便的树格式保存在内存中。这将为查找服务提供快速，并且当Raft日志达到固定大小时，树将已经被排序以便写入磁盘作为新的运行。将状态从领导者转移到慢跟随者需要将所有的游程发送给跟随者(但不是内存树)；幸运的是，游程是一成不变的，因此不存在游程在转移过程中被修改的问题。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215133531601.png" alt="image-20231215133531601"></p> <p>​		将日志清理应用到Raft上效果不太明显。我们首先考虑了一种方法，该方法将Raft日志分为段并清洗(见图5.4 ( a )) )。不幸的是，清洗会在日志中留下许多空洞，其中段被释放，这将需要修改日志复制的方法。我们认为这种方法是可行的，但它给Raft及其与状态机的交互增加了很大的复杂性。此外，由于Raft日志中只有领导者可以追加，因此清洗需要基于领导者，这会浪费领导者的网络带宽(这在5.4节进一步讨论)。</p> <p>​		一个更好的方法是处理类似于LSM树的日志清理：Raft将为最近的变化保留一个连续的日志，状态机将保持自己的状态作为日志，但这些日志在逻辑上是不同的(见图5.4 ( b )) )。当Raft日志增长到固定大小时，它的新条目将被写入状态机日志中的新段，相应的Raft日志前缀将被丢弃。状态机中的线段将在每个服务器上独立清洗，Raft日志将保持完全不受此影响。我们更倾向于直接对Raft日志进行清理，因为日志清理的复杂度完全封装在状态机(状态机和Raft之间的接口仍然简单)中，服务器可以独立清理。</p> <p>​		正如所述，这种方法需要状态机将Raft的所有日志条目写入自己的日志(尽管它可以大批量地做到这一点)中。这种额外的副本可以通过直接从Raft的日志中移动一个由日志条目组成的文件，并将该文件合并到状态机的数据结构中进行优化。这可能是对性能关键系统的有益优化，但不幸的是，它将更紧密地耦合状态机和Raft模块，因为状态机需要了解Raft日志的磁盘表示法</p> <h3 id="_5-4、替代方案-基于领导者的方法"><a href="#_5-4、替代方案-基于领导者的方法" class="header-anchor">#</a> 5.4、替代方案：基于领导者的方法</h3> <p>本章提出的日志压缩方法背离了Raft的强领导者原则，因为服务器在没有领导者知识的情况下压缩日志。然而，我们认为这种背离是正当的。虽然有领导者有助于避免在达成共识时出现相互冲突的决策，但快照时已经达成共识，因此不存在决策冲突。数据仍然只从领导者流向追随者，但追随者现在可以独立地重新组织他们的数据。</p> <p>​		我们还考虑了基于Leader的日志压缩方法，但任何好处通常被性能考虑所抵消。当领导者能够独立地压缩自己的日志，然后将结果发送给跟随者时，这将是浪费的。将冗余状态发送给每个跟随者会浪费网络带宽，使压缩过程变慢。每个跟随者都已经拥有了压缩自身状态所需的信息，而领导者的出站网络带宽通常是Raft最珍贵的(瓶颈)资源。对于基于内存的快照，通常服务器从其本地状态产生快照比通过网络发送和接收快照要便宜得多。对于增量压缩算法，这更多地取决于硬件配置，但我们也希望独立压缩更便宜。</p> <h4 id="_5-4-1、在日志中存储快照"><a href="#_5-4-1、在日志中存储快照" class="header-anchor">#</a> 5.4.1、在日志中存储快照</h4> <p>基于领导者的方法的一个可能的好处是，如果所有的系统状态都可以存储在日志中，那么就不需要新的机制来复制和持久化状态。因此，我们考虑了一种基于领导者的快照方法，领导者创建一个快照，并将快照存储为Raft日志中的条目，如图5.5所示。然后，领导者将使用AppendEntries RPC将该快照发送给其每个跟随者。为了减少对正常操作的任何干扰，每个快照将被分割成许多条目，并与日志中的正常客户端命令交织在一起。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215133738912.png" alt="image-20231215133738912"></p> <p>​		然后，领导者将使用AppendEntries RPC将该快照发送给其每个跟随者。为了减少对正常操作的任何干扰，每个快照将被分割成许多条目，并与日志中的正常客户端命令交织在一起。这将比将快照存储在日志之外获得更好的机制经济性，因为服务器不需要单独的机制来传输快照或将其持久化为(他们将像其他日志条目一样被复制和持久化)。然而，除了浪费跟随者的网络带宽，跟随者也可以轻易地产生自己的快照外，这存在一个严重的问题。如果领导者在创建快照的中间失败，它会在服务器的日志中留下部分快照。原则上，这种情况可能反复发生并耗尽</p> <h4 id="_5-4-2、针对非常小的状态机的leader-based方法"><a href="#_5-4-2、针对非常小的状态机的leader-based方法" class="header-anchor">#</a> 5.4.2、针对非常小的状态机的Leader - based方法</h4> <p>对于非常小的状态机，将快照存储在日志中不仅变得可行，而且可以大大简化。如果快照足够小(高达约一兆字节)，它可以在单个日志项中舒适地拟合，而不会中断正常操作太久。为了以这种方式压缩服务器的日志，领导者会：</p> <p>1、停止接受新的客户端请求；</p> <p>2、等待其日志中的所有条目被提交，其状态机已应用其日志中的所有条目；</p> <p>3、拍摄快照(同步)；</p> <p>4、在其日志的末尾将快照添加到单个日志条目中；</p> <p>5、恢复接受新的客户端请求。</p> <p>一旦每个服务器了解到快照条目被提交，它就可以在其日志中的快照之前丢弃每个条目。这种方法在客户端请求被停止和快照条目被转移的情况下会造成较小的可用性差距，但对于非常小的状态机来说，它的影响是有限的。</p> <p>​		这种更简单的方法避免了在日志外部持久化快照、使用新的RPC传输快照和并发快照的实现工作。然而，成功的系统往往比他们最初的设计者预想的更多地被使用，并且这种方法对于较大的状态机并不能很好地工作。</p> <h3 id="_5-5、总结"><a href="#_5-5、总结" class="header-anchor">#</a> 5.5、总结</h3> <p>本章讨论了Raft中日志压缩的几种方法，这些方法总结在图5.1中。不同的方法适用于不同的系统，取决于状态机的大小，所需的性能水平和预算的复杂度。Raft支持各种各样的方法，这些方法共享一个共同的概念框架：</p> <ul><li>每个服务器独立地压缩其日志的承诺前缀。</li> <li>状态机和Raft之间的基本交互包括将日志前缀的责任从Raft转移到状态机。一旦状态机向磁盘施加了命令，它就指示Raft丢弃日志的相应前缀。Raft保留了它丢弃的最后一个条目的索引和项，以及该索引的最新配置。</li> <li>一旦Raft丢弃了日志的前缀，状态机就承担了两个新的职责：在重新启动时加载状态，并提供一个一致的映像传递给一个缓慢的跟随者。</li></ul> <p>基于内存状态机的快照技术已经在多个生产系统中得到了成功的应用，包括Chubby和ZooKeeper，我们已经在LogCabin中实现了这种方法。</p> <p>虽然在内存数据结构上的操作对于大多数操作来说是快速的，但在快照过程中的性能可能会受到很大的影响。同时快照有助于隐藏资源的使用，并且在未来，将整个集群的服务器调度到不同时间的快照可能会使快照不会影响所有的客户端。</p> <p>​		基于磁盘的状态机在位置上突变其状态在概念上是简单的。它们仍然需要在写时进行复制，以便将一致的磁盘映像传输到其他服务器，但这可能是磁盘的一个小负担，磁盘会自然地分成块。然而，正常运行时的随机磁盘写往往是缓慢的，因此这种方式会限制系统的写吞吐量。</p> <p>​		最终，增量方法可能是最有效的压实形式。通过一次对小块状态进行操作，可以限制资源使用量(并且它们还可以同时紧凑)中的突发。他们还可以避免将相同的数据重复写入磁盘；稳定的数据应该到达磁盘上经常没有被压缩的区域。虽然实现增量合并可能是复杂的，但这种复杂性可以卸载到诸如LevelDB的库中。此外，通过在内存中保存数据结构和在内存中缓存更多的磁盘，增量合并的客户端操作的性能可以接近基于内存的状态机的性能。</p> <h2 id="第六章"><a href="#第六章" class="header-anchor">#</a> 第六章</h2> <h3 id="客户端交互"><a href="#客户端交互" class="header-anchor">#</a> 客户端交互</h3> <p>本章描述了客户端如何与基于Raft的复制状态机进行交互的若干问题：</p> <ul><li>6.1节描述了客户如何找到集群，即使它的成员集合可以随时间变化；</li> <li>6.2节描述了客户请求如何被路由到集群领导进行处理；</li> <li>6.3节描述了Raft如何提供可线性化的一致性[ 34 ]；</li> <li>6.4节描述了Raft如何更有效地处理只读查询。</li></ul> <p>图6.1展示了客户端用于与复制状态机交互的RPC；在整个章节中讨论了这些RPC的元素。这些问题适用于所有基于共识的系统，而Raft的解决方案与其他系统类似。</p> <p>​		本章假设基于Raft的复制状态机作为网络服务直接暴露给客户端。Raft可以选择地直接集成到客户端应用程序中。在这种情况下，客户端交互中的一些问题可能会被推到一个嵌入应用的网络客户端的高度。例如，嵌入式应用的网络客户端在发现应用的集群时，会遇到和Raft网络服务的客户端在发现Raft集群时类似的问题。</p> <h3 id="_6-1、寻找集群"><a href="#_6-1、寻找集群" class="header-anchor">#</a> 6.1、寻找集群</h3> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215134332676.png" alt="image-20231215134332676"></p> <p>当Raft作为一个网络服务暴露时，客户端必须定位集群才能与复制的状态机进行交互。对于具有固定隶属度的聚类，这一点很直观；例如，服务器的网络地址可以静态地存储在配置文件中。然而，当集群的服务器集合可以随时间变化(如第四章所述)是一个更大的挑战。一般的做法有两种：</p> <p>1、客户端可以使用网络广播或多播的方式找到所有的集群服务器。然而，这只能在支持这些特征的特定环境中发挥作用。</p> <p>2、客户可以通过一个外部目录服务(如DNS )发现集群服务器，该服务可以在一个众所周知的位置访问。这个外部系统中的服务器列表不必是一致的，但它应该是包容的：客户端应该总是能够找到所有的集群服务器，但包括一些额外的服务器，这些服务器目前不是集群的成员，是无害的。因此，在簇成员变更时，应在成员变更前更新服务器的外部目录，以包括即将添加到簇中的任何服务器，然后在成员变更完成后再次更新，以删除不再属于簇的任何服务器。</p> <p>LogCabin客户端目前使用DNS来查找集群。LogCabin目前不会在会员变更(这留给了行政手稿)前后自动更新DNS记录。</p> <h3 id="_6-2、路由请求给领导者"><a href="#_6-2、路由请求给领导者" class="header-anchor">#</a> 6.2、路由请求给领导者</h3> <p>Raft中的客户请求是通过领导者处理的，因此客户需要一种方法来找到领导者。当客户端首先启动时，它连接到一个随机选择的服务器。如果客户端的第一选择不是领导者，则该服务器拒绝请求。在这种情况下，一个非常简单的方法是让客户端与另一个随机选择的服务器进行再次尝试，直到找到领导者。如果客户随机选择服务器而不更换，这种简单的方法可以在(n + 1) / 2次尝试后找到n个服务器集群的领导者，这对于小型集群来说可能足够快。</p> <p>​		通过简单的优化，也可以更快地向领导者发起路由请求。服务器通常知道当前集群领导者的地址，因为AppendEntries请求中包含领导者的身份。当非领导者的服务器收到来自客户端的请求时，它可以做两件事中的一件：</p> <p>1、第一种方案是服务器拒绝请求，如果知道，则将领导者的地址返回给客户机。这使得客户端可以直接与领导者重新连接，因此未来的请求可以全速进行。这也需要很少的额外代码来实现，因为在出现领导者故障时，客户端已经需要重新连接到不同的服务器。</p> <p>2、或者，服务器可以代理客户端对领导者的请求。这在某些情况下可能更为简单。例如，如果客户端连接到任何服务器以获取读请求(见6.4节)，那么代理客户端的写请求将使客户端不必管理与仅用于写的领导者的单独连接。</p> <p>​		Raft还必须防止陈旧的领导信息无限期地拖延客户请求。领导信息在整个系统中，在领导者、追随者和客户中都会变得陈旧：</p> <ul><li>领导者：一个服务器可能处于领导者状态，但如果不是当前的领导者，它可能会不必要地延迟客户端的请求。例如，假设一个领导者从集群的其余部分中分离出来，但它仍然可以与特定的客户机进行通信。如果没有额外的机制，它可能会永远延迟来自该客户端的请求，无法将日志条目复制到任何其他服务器。同时，可能会有一个新术语的另一个领导者，它能够与集群中的大多数进行通信，并且能够提交客户端的请求。因此，如果选举超时没有成功的一轮心跳到其集群的大多数，Raft中的领导者就会下台；这使得客户可以重新尝试他们的请求与另一个服务器。</li> <li>追随者：追随者跟踪领导者的身份，以便他们可以重定向或代理客户。他们必须在开始新的选举或任期发生变化时丢弃这些信息。否则，他们可能会不必要地延迟客户(例如,两个服务器之间可以相互重定向,将客户机放置在一个无限循环中)。</li> <li>客户端：如果客户端失去与领导者(或任何特定的服务器)的连接，它应该简单地与随机服务器重试。如果服务器出现故障，坚持能够联系到最后一个已知的领导者会造成不必要的延迟。</li></ul> <h3 id="_6-3、实现可线性化的语义"><a href="#_6-3、实现可线性化的语义" class="header-anchor">#</a> 6.3、实现可线性化的语义</h3> <p>正如目前所描述的那样，Raft为客户提供了至少一次的语义；复制的状态机可能多次应用一个命令。例如，假设客户机向领导提交命令，领导将命令追加到其日志中并提交日志条目，但在响应客户机之前就崩溃了。由于客户端没有收到确认，它将命令重新提交给新的领导者，而新的领导者又将命令作为新的条目附加在其日志中，并提交这个新的条目。虽然客户端希望命令执行一次，但会执行两次。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215134642363.png" alt="image-20231215134642363"></p> <p>如果网络可能重复客户端的请求，即使没有客户端的参与，命令也可以被多次应用。</p> <p>​		这个问题并不是Raft所独有的；它发生在大多数有状态的分布式系统中。然而，这些至少一次的语义特别不适合基于共识的系统，在这种系统中，客户通常需要更强的保证。来自重复命令的问题可以以微妙的方式表现出来，客户很难从这些问题中恢复。这些问题要么导致不正确的结果，要么导致不正确的状态，或者两者兼而有之。图6.2展示了一个错误结果的例子：一个状态机正在提供一个锁，而一个客户端发现它无法获得锁，因为它的原始请求- -它没有收到确认- -已经获得了锁。一个不正确状态的例子将是一个增量操作，其中客户希望一个值增加一个，而不是增加一个。</p> <p>​		我们在Raft中的目标是实现可线性化的语义[ 34 ]，从而避免这类问题。在可线性化中，每个操作似乎都是在其调用和响应之间的某一点上瞬时、准确地执行一次。这是一种很强的一致性形式，用户可以很容易地进行推理，并且不允许命令被多次处理。</p> <p>​		为了在Raft中实现线性化，服务器必须过滤掉重复的请求。其基本思想是服务器保存客户端操作的结果，并使用它们来多次跳过执行相同的请求。为了实现这一点，每个客户端被赋予一个唯一的标识符，并且客户端为每个命令分配唯一的序列号。每个服务器的状态机为每个客户端维护一个会话。会话跟踪为客户端处理的最新序列号，以及相关的响应。如果服务器收到一个序列号已经被执行的命令，它立即响应，而不需要重新执行请求。</p> <p>​		考虑到这种对重复请求的过滤，Raft提供了线性化的能力。Raft日志提供了一个在每个服务器上应用命令的串行命令。命令根据其在Raft日志中的首次出现而瞬时、准确地生效一次，因为任何后续出现都被如上所述的状态机过滤掉。</p> <p>​		这种方法也可以推广到允许单个客户端的并发请求。而不是客户端的会话跟踪仅仅是客户端的最新序列号和响应，它包括一组序列号和响应对。对于每个请求，客户端包含其尚未收到响应的最低序列号，然后状态机丢弃所有响应以获得较低的序列号。</p> <p>​		遗憾的是，会话不可能永远保持下去，因为空间是有限的。服务器最终必须决定客户端会话过期，但这就产生了两个问题：服务器如何约定客户端会话何时过期，以及如何处理会话不幸过期过快的活跃客户端?</p> <p>​		服务器必须就客户端会话何时到期达成一致；否则，服务器的状态机可能会彼此发散。例如，假设一个服务器对某个特定客户端的会话过期，然后重新应用该客户端的许多重复命令；同时，其他服务器保持会话处于活动状态，不应用副本。复制的状态机将变得不一致。为了避免这样的问题，会话过期必须是确定性的，就像正常的状态机操作一样。一种选择是设置会话数量的上限，并使用LRU (最近使用最少)策略删除条目。另一种选择是根据约定的时间来源来到期。在LogCabin中，领导者将其附加到Raft日志中的每个命令用当前时间进行扩展。服务器在这个时候达成一致，作为提交日志记录的一部分；然后，状态机确定性地使用这个时间输入来过期非活动会话。实时客户在不活动期间发出保持活动状态的请求，这些请求也被增加了领导者的时间戳，并提交给Raft日志，以维持他们的会话。</p> <p>​		第二个问题是如何处理会话过期后继续运行的客户端。我们期待这是个例外的情况；然而，它总是存在一定的风险，因为通常没有办法知道客户何时已经退出。一种选择是在客户端没有任何记录的情况下为客户端分配一个新的会话，但这会冒险重复执行在客户端上一个会话过期之前执行的命令。为了提供更严格的保证，服务器需要区分新客户端和会话已过期的客户端。当客户端首次启动时，它可以使用RegisterClient RPC向集群注册自己。这分配了新客户端的会话，并将客户端的标识符返回给客户端，客户端包括所有后续的命令。如果状态机遇到没有会话记录的命令，它不处理该命令，而是向客户端返回一个错误。LogCabin目前在这种情况下会崩溃客户端(大多数客户端可能不会优雅而正确地处理会话过期错误,但系统通常必须已经处理了客户端崩溃)。</p> <h3 id="_6-4、更高效地处理只读查询"><a href="#_6-4、更高效地处理只读查询" class="header-anchor">#</a> 6.4、更高效地处理只读查询</h3> <p>只读客户机命令只对复制的状态机进行查询；他们并没有改变它。因此，很自然地要问这些查询是否可以绕过Raft日志，其目的是以相同的顺序复制对服务器状态机的更改。绕过日志提供了一个有吸引力的性能优势：只读查询在许多应用程序中很常见，而将条目添加到日志中所需要的同步磁盘写是非常耗时的。</p> <p>​		然而，如果没有额外的预防措施，绕过日志可能会导致只读查询的陈旧性结果。例如，一个领导者可能被从集群的其余部分中分离出来，而集群的其余部分可能已经选出了一个新的领导者并向Raft日志提交了新的条目。如果被划分的领导者在没有咨询其他服务器的情况下响应只读查询，则会返回过时的结果，无法进行线性化处理。可线性化要求读出的结果在读出开始后的一段时间内反映系统的状态；每次读取至少要返回最近一次提交的结果写入。(一个允许陈旧读段的系统只会提供可串行化,这是一种较弱的一致性形式。)在两个第三方Raft实现中已经发现了由于读长过时引起的问题[ 45 ]，因此该问题值得关注。</p> <p>​		幸运的是，可以绕过Raft日志进行只读查询，并且仍然保持可线性化。为了做到这一点，领导者采取以下步骤：</p> <p>1、如果领导人尚未从其当前承诺的任期中标志入盟，则等待直到它这样做。领导者完备性属性保证领导者拥有所有承诺的条目，但在其任期开始时，它可能不知道这些条目是什么。要弄清楚，它需要从其任期开始提交一个条目。Raft通过让每个领导者在其任期开始时在日志中提交一个空白的no - op条目来处理这个问题。一旦提交了这个no - op条目，管理者的提交指数将至少与任期内任何其他服务器的提交指数一样大。</p> <p>2、领导者将当前提交索引保存在一个局部变量read Index中。这将作为查询操作所针对的状态的版本的下界。</p> <p>3、领导者需要确保它没有被一个新的领导者所取代，而这个新的领导者是不知道的。它发出新一轮的心跳，并等待大多数集群的确认。一旦收到这些承认，领导人就知道，在它发出心跳的那一刻，不可能有一个更长期的领导人。因此，当时read Index是集群中任何服务器所见过的最大提交索引。</p> <p>4、领导者等待其状态机至少向read Index推进；这足以满足可线性化。</p> <p>5、最后，领导者针对其状态机发出查询，并将结果回复给客户端</p> <p>​		这种方法比将只读查询作为日志中的新条目提交更有效，因为它避免了同步的磁盘写操作。为了进一步提高效率，领导者可以摊销确认其领导权的成本：它可以对其积累的任意数量的只读查询使用单轮心跳。</p> <p>​		跟随者还可以帮助卸载只读查询的处理。这会提高系统的读吞吐量，同时也会将负载从领导者处分流出去，使得领导者可以处理更多的读写请求。然而，这些reads也会在没有额外预防措施的情况下运行返回陈旧数据的风险。例如，一个被分割的跟随者可能在很长一段时间内没有从领导者那里收到任何新的日志条目，或者即使一个跟随者从领导者那里收到一条心跳，那个领导者本身也可能被废黜而还不知道它。为了安全地服务于读，跟随者可以向领导者发出请求，该领导者只需请求当前的读索引(领导者执行上述步骤1 ~ 3)；然后，跟随者可以在自己的状态机上对任意的numb执行步骤4和5</p> <p>​		LogCabin在leader上实现了上述算法，并在高负载下通过多个只读查询来分摊心跳开销。LogCabin中的跟随者目前并不服务于只读请求。</p> <h4 id="_6-4-1、使用时钟来减少只读查询的消息传递"><a href="#_6-4-1、使用时钟来减少只读查询的消息传递" class="header-anchor">#</a> 6.4.1、使用时钟来减少只读查询的消息传递</h4> <p>到目前为止，本文提出的只读查询方法已经在异步模型(其中,时钟、处理器和消息都可以以任意速度运行)中提供了可线性化性。这种安全级别需要通信来实现：它需要一轮心跳来为每批只读查询减半个集群，这增加了查询的延迟。本节的其余部分探索了一种替代方案，其中只读查询将完全依靠时钟来避免发送消息。LogCabin目前没有实现这种替代方案，我们不建议使用它，除非有必要满足性能要求。</p> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215135353989.png" alt="image-20231215135353989"></p> <p>​		为了使用时钟代替消息进行只读查询，正常的心跳机制将提供一种租赁的形式[ 33 ]。一旦领导者的心跳被大多数集群所承认，领导者将假定没有其他服务器会成为领导者，因为大约有一个选举超时，它可以相应地延长其租赁(见图6.3)。然后，领导者将在该期间内回复只读查询，而不需要任何额外的通信。(第3章提出的领导权让渡机制允许领导人提前更换;领导人在移交领导职务之前需要到期。)</p> <p>​		该租赁方法假设服务器(在给定的时间段内,没有一个服务器的时钟增加超过这个上界的任何其他时间)之间的时钟漂移有界。发现并维持这一边界可能会带来操作上的挑战(例如,由于调度和垃圾收集暂停、虚拟机迁移或时钟速率调整而进行的时间同步)。如果假设被违背，系统可以任意返回过时的信息。</p> <p>​		幸运的是，一个简单的扩展可以提高向客户机提供的保证，这样即使在异步假设(即使时钟被误动作了)下，每个客户机也会看到复制的状态机单调地进行(顺序一致性)。例如，一个客户机看不到日志索引为n的状态，然后换到另一个服务器，只看到日志索引为n - 1的状态。为了实现这种保证，服务器将包含与状态机状态相对应的索引，每次向客户端回复。客户会追踪他们所看到的结果所对应的最新索引，并在每次请求时将这些信息提供给服务器。如果一个服务器收到了一个客户端的请求，该客户端的索引大于该服务器上一次应用的日志索引，则该服务器不会为该请求提供服务(还没有)。</p> <h3 id="_6-5、总结"><a href="#_6-5、总结" class="header-anchor">#</a> 6.5、总结</h3> <p>本章讨论了客户如何与Raft互动的几个问题。在正确性方面，提供可线性化和优化只读查询的问题尤为微妙。不幸的是，当共识文献只解决集群服务器之间的通信时，它将这些重要问题抛之脑后。我们认为这是一个错误。一个完整的系统必须与客户端进行正确的交互，否则核心共识算法所提供的一致性水平将走向浪费。正如我们已经在真实的基于Raft的系统中看到的那样，客户端交互可能是Bug的主要来源，但我们希望更好地理解这些问题可以帮助防止未来的问题。</p> <h2 id="第七章"><a href="#第七章" class="header-anchor">#</a> 第七章</h2> <h3 id="raft用户研究"><a href="#raft用户研究" class="header-anchor">#</a> Raft用户研究</h3> <p>这是四个章节中的第一个章节，每个章节都对Raft的一个方面进行了评价：</p> <ul><li>本章对Raft的可理解性进行了评价。</li> <li>第八章讨论了Raft的正确性。</li> <li>第9章对Raft的领导人选举算法进行了评价</li> <li>第十章讨论了Raft的实现，并对其性能进行了评估。</li></ul> <p>基于我们的直觉和传闻证据，我们将Raft设计为可理解的，但我们想更客观地评价它的可理解性。尽管测量可理解性本质上是困难的，但这对我们很重要，原因有二。首先，如果没有评价，我们的中心论断&quot;Raft很容易理解&quot;将难以自圆其说。其次，我们的目标之一是提出可理解性作为计算机系统中的第一类特性，因此我们也承担了提出一种方法来评估它的负担。</p> <p>​		为了评估Raft的可理解性，我们进行了一项实验研究。本研究比较了学生在学习每种算法后，对Raft和Paxos问答题的解答能力。我们的参与者是斯坦福大学和加州大学伯克利分校的本科和研究生。我们录制了Raft和Paxos的视频讲座，并制作了相应的小测验。Raft讲座涵盖了基本的Raft算法(第3章)，并简要介绍了针对任意成员变化的联合共识方法(第4.3节)；Paxos讲座涵盖了足够的素材来创建等价的复制状态机，包括单令Paxos、多令Paxos、集群成员关系的变化，以及实践中需要的一些优化(如领导者选举)。讲座视频和幻灯片可在网上获得[ 88 ]。测试题测试了学生对算法的基本理解，并要求学生对角点情况进行推理。每个学生观看一个视频，进行相应的小测验，观看第二个视频，进行第二个小测验。大约一半的参与者先做了Paxos部分，另一半先做了Raft部分，以解释在第一部分研究中获得的表现和经验的个体差异。我们比较了参与者在两次测验中的得分，以确定参与者是否比Paxos对Raft有更好的理解。</p> <p>​		平均而言，被试在Raft测验上的得分比在Paxos测验(在可能的60分中, Raft评分平均为25.7分, Paxos评分平均为21.0分)上的得分高22.6 %。考虑到人们是先学习Paxos还是先学习Raft，线性回归模型预测没有Paxos经验的学生在Raft测验上的得分比在Paxos测验上的得分高12.5分。第7.4 . 1节详细分析了测验结果。</p> <p>​		我们还在测试后对参与者进行了调查，以了解他们认为哪种算法更容易实现或解释。绝大多数参与者认为Raft更容易实施和解释(每个问题41个中的33个)。然而，这些自我报告的感受可能比参与者的测验分数更不可靠。第7.4 . 2节对调查结果进行了详细分析。</p> <p>​		我们的研究对于系统研究来说是不寻常的，并且我们在设计和实施过程中吸取了许多教训。例如，在一项用户研究中，几乎所有的工作都必须在看到任何结果之前完成；这就给误差留下了较小的空间。两节讨论了我们的经验教训。第7.2节探讨了我们在开发我们的方法和材料时所考虑的众多设计决策。第7.5节探讨了实验如何有效地说服他人理解拉夫特的可理解性，是否值得我们投入时间和精力。</p> <h3 id="_7-1、研究问题与假设"><a href="#_7-1、研究问题与假设" class="header-anchor">#</a> 7.1、研究问题与假设</h3> <p>我们在研究中的首要目标是展示Raft的可理解性。一个开发人员应该能够很好地学习Raft算法，以产生一个正确的实现，而不会产生不必要的时间和精力的负担。遗憾的是，拉夫特的可理解性难以直接测量。对于可理解性没有既定的衡量标准，我们也无法判断Raft算法是否是最容易理解的算法。</p> <p>​		为了达成一个实验，我们需要制定我们可以测量的指标和我们可以检验的假设。我们首先需要一个代理来衡量一个人的可理解性。我们选择了测验参与者并测量了他们的测验成绩(第7.2 . 3节讨论了一种让参与者执行算法的替代方案)。其次，我们需要比较参与者在Raft和其他共识算法上的测验得分。我们选择将Raft与当今最流行的一致性算法Paxos进行比较。</p> <p>本研究拟探讨以下问题：</p> <ul><li>Raft是否比Paxos更容易理解?我们预测学生在Raft测验上的得分会高于在Paxos测验上的得分。</li> <li>Raft的哪些方面最难理解?我们对这个问题感兴趣，因为它可以帮助Raft的可理解性得到进一步的改进。我们认为，学生最有可能与Raft中的承诺和成员变化进行斗争。我们觉得这些是Raft解释中最复杂和最困难的地方，所以学生在理解他们的(这比Raft更简单的单服务器隶属度变化算法更早)时最容易出现困难。我们也觉得Paxos的α -基于成员资格的方法对(虽然它遗留下来的次要问题是重大的)的解释更简单。</li> <li>知道Paxos如何影响学习Raft，反之亦然?我们预测，学生在第二次测验中的得分一般会更高。我们有两个原因。首先，共识算法共享基本概念，学生在第二次看到一个概念时应该能够更容易地掌握。第二，由于讲座和测验遵循相同的形式，我们认为学生在第一次讲座和测验中会获得有用的经验。</li> <li>人们是否更喜欢使用Raft而不是替代方案?我们预测Raft的可理解性会导致对Raft实施和解释的偏好。</li></ul> <h3 id="_7-2、关于方法的讨论"><a href="#_7-2、关于方法的讨论" class="header-anchor">#</a> 7.2、关于方法的讨论</h3> <p>由于在计算机系统文献中很少有这种实验的先例，我们从第一性原理出发，通过大量的实验设计决策进行了推理。在这个过程中，我们特别感谢斯科特·克莱默的宝贵帮助。本部分通过描述我们为每个决策所考虑的备选方案来解释为什么我们会得出我们的方法，包括：</p> <ul><li>我们对参与者的选择以及如何激励他们的参与( 7.2 . 1节)，</li> <li>如何将算法教给参与者(第7.2 . 2节)。</li> <li>如何检验他们的理解( 7.2 . 3节)，</li> <li>如何评价其绩效( 7.2.4节)，</li> <li>在调查中提出哪些问题(第7.2 . 5节)，</li> <li>如何在研究开始前发现并解决研究中的问题(第7.2 . 6节)。</li></ul> <p>我们最终决定使用的方法将在第7.3节以更正式的APA (美国心理学会)风格呈现。</p> <p>​		我们采用的一个共同原则是在算法的学习曲线开始时对被试进行测试。我们想看看他们能多么容易地从没有知识走向一个适度的理解水平。虽然我们希望我们的参与者至少对这两种算法有一个基本的了解，但我们并不想过度准备它们。给定无限时间，大多数参与者最终都会理解任何共识算法。因此，为了衡量算法之间的差异，我们必须在学习曲线开始时对参与者进行测试。例如，这意味着我们在激励参与者方面面临着紧张，正如在下一节中讨论的那样：我们希望他们尝试，但我们不希望他们广泛地研究算法。</p> <h4 id="_7-2-1、参加者"><a href="#_7-2-1、参加者" class="header-anchor">#</a> 7.2.1、参加者</h4> <p>我们邀请了来自斯坦福大学和伯克利大学的学生参与我们的研究。这既增加了我们的样本量，也拓宽了我们结果的一般性。我们选择在两所学校使用相同的材料和程序，以便比较参与者在不同学校的表现。</p> <p>我们考虑了利用课程成绩来激励学生参与学习的各种方法。我们希望学生在学习每一个算法时都付出同等的努力，并且我们只想让他们观看为(不利用外界信息或过度学习)做准备的讲座。不幸的是，我们对我们认为能够激励学生的每一种方法都有很大的顾虑：</p> <ul><li>如果学生的参与影响了他们的课程成绩，但他们为甚至错误的答案赢得了学分，我们担心学生可能不会关注这些讲座。例如，一个学生跳过了讲座，但在测验中填写了任何想到的答案，他/她的课程成绩仍将获得全额学分。</li> <li>如果学生的测验成绩影响了他们的课程成绩，我们担心学生可能会花费太多的时间来准备测验，或者为了获得相同的成绩，他们可能会在更难理解的算法上更加努力。我们希望在学习曲线开始时对参与者进行测试；我们不希望学生对算法的理解太好，以至于我们的问题无法衡量算法之间的理解差异。我们也希望他们在每个算法上花费同等的精力。</li> <li>我们希望在学习曲线开始时对参与者进行测试；我们不希望学生对算法的理解太好，以至于我们的问题无法衡量算法之间的理解差异。我们也希望他们在每个算法上花费同等的精力。如果学生被授予额外的课程学分以参与或获得良好的测验成绩，我们担心成绩较差或压力较大的学生可能在我们的参与者中占多数。</li> <li>我们考虑的另一个想法是，给学生所有的课程学分，让他们在任何一次测验中得分至少50 %。我们对这种方法的担忧是，它会为测验成绩留下太多可能的解释。例如，如果学生认为他们做得足够好，他们是否会在第一个算法之后停止学习?学生是否会选择提前尝试在Raft上做得好，不用担心Paxos小测验(反之亦然)?</li></ul> <p><img src="https://raw.githubusercontent.com/zhaoyb-coder/pic-repo/main/image-20231215162158708.png" alt="image-20231215162158708"></p> <p>​		对于斯坦福大学的学生，我们最终决定给予全课程学分( 5 %的课程总成绩)，以便合理参与研究。我们有意地让这个定义变得模糊，但如果一个学生似乎在学习中投入了一些精力，我们就授予了他们完整的课程学分。学生还被告知该材料可能会在课程的期末考试中再次出现。斯坦福大学班级几乎每个学生都参加了(见表7.1)。</p> <p>​		然而，伯克利参与者的唯一激励是学习材料的机会。伯克利班的指导老师选择不将学习参与度纳入课程成绩，且该班没有考试。即使没有额外的激励，伯克利班级中至少有三分之一的学生参与了(见表7.1)。</p> <h4 id="_7-2-2、教学"><a href="#_7-2-2、教学" class="header-anchor">#</a> 7.2.2、教学</h4> <p>我们在如何向参与者传授算法方面有许多选择。不仅一般的教学方法很多，特别是帕克斯的教学方法更是多种多样。我们在研究中的目标是比较算法，而不是比较它们的传播方式。因此，教学方法和教学风格的一致性非常重要。我们希望以类似的方式传达算法，并希望覆盖等价的内容。我们还希望参与者每次算法花费的时间不超过几个小时。我们认为对我们的参与者进行询问是合理的，然后我们就可以在每个算法的学习曲线开始时对他们进行测试。</p> <p>​		我们考虑使用试卷来教授我们的参与者，但这有两个问题。首先，我们找不到合适的帕克斯纸。这篇论文本来就必须了：</p> <ul><li>涵盖Paxos ( Paxos算法没有一个统一的说法,但有些算法比另一些算法更容易理解)的一个相对容易理解的变体；</li> <li>将其描述得足够完整，以构建可复制的状态机；</li> <li>对于题目中没有背景的学生来说，不需要事先了解相关工作；</li> <li>具有与Raft论文相似的质量、风格和长度。</li></ul> <p>我们本可以写这样一篇论文，但要花几个月的时间。第二个问题是，论文阅读需要很多小时，我们希望参与者能够在更短的时间内学习算法。</p> <p>​		取而代之的是，我们决定通过讲座的方式对参与者进行授课。我们估计，在一个小时的讲座中，我们可以为每个算法覆盖足够的材料。这足够短，以至于它没有给我们的参与者造成过重的负担，但它足够长，以舒适的速度覆盖大量的材料。它还足够短，以至于我们仍然可以在算法的学习曲线开始时测试参与者。</p> <p>​		我们选择让约翰·奥斯特豪特( John Ousterhout )为这两种算法做讲座，而不是为帕克斯( Paxos )使用不同的讲师。在试图最大化算法之间的一致性时，我们在决策中考虑了以下因素：</p> <ul><li>专业知识：我们希望每个算法都有同等水平的专业知识，在研究之前我们没有考虑自己在Paxos上的专家。我们本来可以请一位帕克索斯专家来做帕克索斯讲座。相反，Ousterhout将他的幻灯片建立在专家的幻灯片基础上，在准备帕克斯讲座时，我们相信我们学得很好，足以认为自己在帕克斯讲座上有足够的知识。</li> <li>教学风格和能力：奥斯特霍特能够在他的两次演讲中保持这种一致性，而如果一个单独的演讲者给帕克斯演讲，我们可能会在不同的教学风格和能力之间挣扎。</li> <li>讲座质量：奥斯特霍夫没有同时进行这两场讲座，这引起了他的担忧，他可能没有付出努力来制作一篇同样优秀的帕克斯讲座。然而，他试图制作等效的讲座，并通过将他的帕克索斯幻灯片与专家的幻灯片分开来缓解这种情况。(此外,拉夫特讲座在研究过程中也存在一些不足:我们做了一些最后一分钟的修改,以修复其中的一个错误,如果我们有更多的时间,这个错误本来可以更清楚。此外,它还提出了更复杂的成员变更形式,因为它比较简单的单服务器变更算法更简单。) Balancing讲座的质量可能会因为另一位帕克斯讲师的不同而变得更加困难，因为第二位讲师可能没有那么专注于这项研究。</li></ul> <p>我们想教一个相对容易理解和完整的帕克斯变体，同时忠实于帕克斯的基本原理。遗憾的是，关于Paxos的变体还没有达成一致的意见；不同的教师对采用哪种变式进行教学持不同意见。我们最终解决了David Mazi ' eres [ 78 ]的一个变体，这个变体不仅高效而且相对容易理解。然而，我们使用莱斯利·兰伯特的α方法[ 49 ]进行重新配置，而不是Mazi的方法。虽然兰波特的方法有限制Paxos在正常运行时的并发性的不可取之处，但我们认为(包括马兹埃尔斯)的基本思想比Mazi ' es和其他方法更容易理解。</p> <p>​		我们将这两场讲座录制在视频上，而不是让约翰·奥斯特豪特亲自到场。记录它们有几个好处：</p> <ul><li>在相同的时间内，我们可以拟合更多的材料，因为当我们犯错时，我们可以重新记录片段。</li> <li>在我们为每个算法(见第7.2 . 6节)运行的两个试点研究中，我们能够通过我们的讲座调试问题。有了它们的记录，我们就可以捕捉到问题，并可靠地修复它们。</li> <li>参与者可以以不同的顺序观看演讲，并且仍然可以看到相同的确切材料。</li> <li>学生可以按照自己的节奏和时间安排观看讲座。他们可以重新观看视频片段，或者按照自己的意愿对视频进行加速和减速。我们没有对授课时间进行限制，因此学生可以按照自己的节奏观看。</li> <li>视频讲座仍作为研究的文件，可用于重复研究。研究之外的其他人也在自己的(我们的Raft讲座截至2014年8月在YouTube上的浏览量为14 480次,我们的Paxos讲座浏览量为9 200次)上使用视频进行算法的学习。</li></ul> <p>视频讲座仍作为研究的文件，可用于重复研究。研究之外的其他人也在自己的(我们的Raft讲座截至2014年8月在YouTube上的浏览量为14 480次,我们的Paxos讲座浏览量为9 200次)上使用视频进行算法的学习。一个可能的缺点是学生在听课时不能提问。另一方面，提问会破坏录音讲座的一致性好处。例如，问题可以导致在一个讲座中呈现比另一个讲座更多的材料，并且可以在斯坦福和伯克利小组之间引入额外的差异。我们也不知道录制的讲座是如何影响学习参与的；虽然我们斯坦福的参与度很高，但这是有可能的</p> <p>​		我们试图使视频讲座保持相对客观，以减少偏见。例如，视频部分只展示了讲座幻灯片，而没有展示约翰·奥斯特霍夫本人。然而，即便是奥斯特豪特的画外音也可能已经微妙地偏向了(尽管他试图不是这样)。关注的读者应该回顾演讲视频，以决定自己的演讲；我们不知道有什么正式的技术来测量或减少这种偏见。</p> <p>​		除了视频讲座之外，我们还为被试准备(讲座笔记和算法总结)提供了额外的辅助材料。我们不鼓励参与者在自己的(例如,通过阅读论文)上学习算法，但我们觉得一些额外的材料在测验前回顾和测验期间参考会对参与者有帮助。我们提供了演讲幻灯片的副本，以便于参考，并以(浓缩)一页的Raft摘要和(稀疏) 3.5页的Paxos摘要的形式向参与者提供了算法摘要。这些内容见附录A.4。</p> <h4 id="_7-2-3、测试理解"><a href="#_7-2-3、测试理解" class="header-anchor">#</a> 7.2.3、测试理解</h4> <p>本研究的一个关键挑战是如何测量参与者对算法的理解。我们考虑让参与者实现算法，这将使我们能够更直接地衡量他们构建工作系统的能力。如果可行的话，这种方法会比测验更好。然而，由于众多的挑战，我们选择不这样做。首先，我们估计，实施Raft或Paxos的大部分工作将需要大多数专家周。如果我们询问我们的参与者，我们肯定不会有这么多，并且我们可能无法得出具有统计学意义的结论。而且，人们开发系统的能力差异很大，因此要得出具有统计学意义的结论，这样的研究需要大样本量或意愿。这两种选择在实践中都会因为需要参与者的时间承诺而变得困难。即使解决了参与问题，衡量彼此的实施仍然具有挑战性。彻底的处理需要包括正确性、代码复杂性和成本的度量，所有这些都是具有挑战性的。</p> <p>​		相反，我们选择测验参与者来测量他们的理解。这对被试的时间要求较低。因此，我们能够让每个参与者都学习这两种算法，从而更容易地排除学习和应试能力的个体差异。此外，根据被试的数字测验成绩可以很容易地比较被试的表现。</p> <p>​		我们在开发试题时遇到的最困难的挑战是如何使试题公平。我们首先考虑使用同样适用于两种算法的问题，但是对于其中一种算法来说，这样的问题往往过于明显，因为它更直接地覆盖了主题。相反，如果难度也相似，我们只使用相似的问题。</p> <p>​		我们使用了以下策略来使测验公平。首先，我们对每个问题按难度进行了分类：</p> <ul><li>简单的问题本质上是回忆：在讲座中可以找到答案，很少或没有推论。我们期望学生能够正确回答几乎所有的这些问题。</li></ul></div></div>  <div class="page-edit"><!----> <div class="tags"><a href="/tags/?tag=Raft" title="标签">#Raft</a></div> <!----></div> <div class="page-nav-wapper"><div class="page-nav-centre-wrap"><a href="/more/251dfe/" class="page-nav-centre page-nav-centre-prev"><div class="tooltip">分享一次项目压测导致的并发问题</div></a> <!----></div> <div class="page-nav"><p class="inner"><span class="prev">
        ←
        <a href="/more/251dfe/" class="prev">分享一次项目压测导致的并发问题</a></span> <!----></p></div></div></div> <div class="article-list"><div class="article-title"><a href="/archives/" class="iconfont icon-bi">最近更新</a></div> <div class="article-wrapper"><dl><dd>01</dd> <dt><a href="/data/2f28ce/"><div>
            Mysql-日志详解
            <!----></div></a> <span class="date">12-11</span></dt></dl><dl><dd>02</dd> <dt><a href="/be/935152/"><div>
            Mybatis源码
            <!----></div></a> <span class="date">12-10</span></dt></dl><dl><dd>03</dd> <dt><a href="/be/935100/"><div>
            JDK源码中有趣的位运算
            <!----></div></a> <span class="date">12-08</span></dt></dl> <dl><dd></dd> <dt><a href="/archives/" class="more">更多文章&gt;</a></dt></dl></div></div></main></div> <div class="footer"><!----> 
  Theme by
  <a href="https://github.com/xugaoyi/vuepress-theme-vdoing" target="_blank" title="本站主题">Vdoing</a> 
    | Copyright © 2022-2023
    <span>赵宇博 | <a href="https://github.com/zhaoyb-coder/" target="_blank">MIT License</a></span></div> <div class="buttons"><div title="返回顶部" class="button blur go-to-top iconfont icon-fanhuidingbu" style="display:none;"></div> <div title="去评论" class="button blur go-to-comment iconfont icon-pinglun" style="display:none;"></div> <div title="主题模式" class="button blur theme-mode-but iconfont icon-zhuti"><ul class="select-box" style="display:none;"><li class="iconfont icon-zidong">
          跟随系统
        </li><li class="iconfont icon-rijianmoshi">
          浅色模式
        </li><li class="iconfont icon-yejianmoshi">
          深色模式
        </li><li class="iconfont icon-yuedu">
          阅读模式
        </li></ul></div></div> <!----> <!----> <!----></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.e85e8bd5.js" defer></script><script src="/assets/js/2.75aeda74.js" defer></script><script src="/assets/js/27.009e71e1.js" defer></script>
  </body>
</html>
