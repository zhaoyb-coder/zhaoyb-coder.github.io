---
title: Redis
date: 2022-08-17 18:59:30
permalink: /pages/Redis/
categories:
  - 后端
  - redis
tags:
  - redis
author: 
  name: Coder
  link: https://github.com/zyb-github
---
# Redis

## 1、Redis 集群配置

> Redis集群是一个由多个节点组成的分布式服务器集群，具有复制、高可用、分片特性
>
> Redis集群没有中心节点，并且带有复制和故障转移特性，这可以避免单个节点成为性能瓶颈，或者因为某个节点下线导致整个集群下线
>
> 集群中的主节点负责处理存储数据，从节点是主节点的复制品
>
> 复制原理：
>
> Slave从机启动成功连接到Master主机后，会向Master发送一个sync同步命令
>
> Master接收到命令后，启动后台的存盘进程， 同时收集所有接受到的用于修改数据集指令 ，在后台进程执行完毕之后，Master将传送整个数据文件（全量复制）到Slave，完成一次性同步
>
> + 全量复制：Slave服务在接收数据文件后，将其存盘并加载到内存中
> + 增量复制：Master继续将新的所有修改命令一次传给Slave，完成同步
>
> 
>
> 
>
> 哨兵模式
>
> 哨兵是一个单独的进程，作为进程会独立运行
> 原理：哨兵通过发送命令，等待redis服务器响应，从而监控运行的多个redis实例，当哨兵检测到Master宕机，会自动将Slave切换到Master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，切换到主机

```shell
#一主多从 
#准备工作：准备4台redis，端口分别是6380、6381、6382、6383
#分别启动四台redis
redis-server redis.conf

#四台机器分别进行连接：
redis-cli -p xxxx -h xxxxxx
# info replication 查看redis信息，可以看到 当前节点时主节点开始从节点，还有当前连接的从节点的个数等信息

#6381节点使用slaveof命令找寻主节点6380
slaveof 127.0.0.1 6380
#设置为从节点之后是不能再写入数据的，会提示READONLY

#如果停止主节点6380，则需要把其中一个redis替换为主服务器
#6381 停止复制，并把自己改为主服务器
salveof no one
#6382 和 6383 更改主服务器
salveof 127.0.0.1 6381

#哨兵模式 自动更改主服务器
#1、新建哨兵的配置文件 sentinel.conf  
sentinel monitor redis6380 127.0.0.1 6382 1
sentinel monitor <master-group-name> <ip> <port> <quorum>
#当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了
#为了正常选举，哨兵数量应该是基数，并且最少启动三个
#启动哨兵的命令  默认端口26379
redis-sentinel sentinel.conf
```

![image-20220817112500871](https://s2.loli.net/2022/08/17/q4vMwR5PS9ZxHKB.png)

> 集群
>
> 四个节点，主从节点会自动分配
>
> 主节点故障后，从节点会自动替换主节点
>
> 步骤：
>
> 1、修改配置文件，增加集群配置
>
> cluster-enabled yes
> cluster-config-file node-6380.conf  #启动会自动生成的文件
>
> 2、启动各个节点
>
> 3、客户端创建集群
>
> ```shell
> redis-cli --cluster create 117.50.182.147:6380  117.182.147:6381  117.50.182.147:6382  117.50.182.147:6383  117.50.182.147:6384  117.50.182.147:6385 --cluster-replicas 1
> ```
>
> 4、连接集群
>
> redis-cli -c -p 6380 -h 127.0.0.1  主要是加-c的参数
>
> 注意：创建集群的redis不能含有数据，否则会报错[ERR] Node xxx is not empty.
>
> 注意：如果集群启动之后，查询状态为fail或者无法set数据，插槽报错，需要重新分配插槽，命令如下
>
>  redis-cli --cluster fix ip:port
>
> 集群的常用命令
>
> ```shell
> cluster info 
> cluster node
> ```
>
> 

## 2、Redis 过期键删除策略

> 常见的有三种删除策略
>
> 1、定时删除：在创建带有过期时间的key时，同时创建一个定时器，定时器到时间之后直接删除已经过期的key
>
> 2、惰性删除：key过期之后并不会在内存中删除，而是改变这个key或者使用这个key时才进行删除
>
> 3、定期删除：每隔一段时间从内存中取出部分key，判断是否过期，如果过期则删除

**Redis使用的是惰性删除+定期删除的策略**

> **惰性删除的实现**：由expireIfNeeded函数实现，所有读写数据库的Redis命令在执行之前都会调用expireIfNeeded函数对输入键进行检查，如果键过期，则删除并返回空，如果键不过期，则不操作
>
> **定期删除的实现**：由activeExpireCycle函数实现，被调用时，它在规定的时间内，分多次遍历服务器的各个数据库，从数据库的expires字典表中随机检查一部分键的过期时间，并删除其中的过期键。
>
> + 函数每次运行时，都是从一定数量的数据库键中随机取一定数量的键进行检查，并删除其中的过期键
> + 有一个全局变量current_db会记录当前activeExpireCycle函数检查的进度，并在下一次函数执行时，接着上一次的进度进行处理。如：当前activeExpireCycle函数执行到了10，将current_db=10；下一次执行函数时，从10开始继续执行。
> + 当所有数据库的键都被检查完时，current_db置为0
>
> **定期删除的具体代码实现**：
>
> + Redis读取配置文件hz的值，也就是每10s执行一次搜索，**serverCron()->databaseCron()->activeExpireCycle()**
>
> + ![image-20220819162752973](https://s2.loli.net/2022/08/23/FGyWUYqm6klO9aK.png)
>
> + activeExpireCycle方法对每个expire[*]进行检查，每次检查时间为250ms/hz  (默认25ms)
>
> + 对某个expire[*]进行检查时，随机挑选出**W**个key检查，W取值ACTIVE_EXPIRE_CYCLE_LOOKUPS_PRE_LOOP默认值为20
>
> + 检查时，如果key过期则删除，如果删除的个数 25%,则循环该过程，如果删除的小与25%，则检查下一个expire[*],0-15循环，直到本次检查时间超过25ms（默认） 
>
>   

**AOF、RDB、复制功能对过期键的处理**

+ AOF

  + 写入：当服务器开启AOF模式运行时，如果某个键过期了，但没有被惰性删除或者定期删除，那么AOF不会理会这个key，如果被惰性删除或者定期删除了，则会在AOF文件末尾追加一个DEL语句
  + 重写：当AOF重写时，过期的键不会被载入到redis内存中

+ RDB

  + 生成RDB：过期的键不会载入到RDB文件中
  + 加载RDB：如果服务器是主服务器，加载RDB时，过期的键会被过滤掉，不会被载入内存中；如果是从服务器运行，任何数据都会被载入内存，但是由于服务器会进行主从同步，所以同步时过期键会被清空。

+ 复制：在复制模式下，删除过期键的操作都是主服务器完成的

  + 主服务器在删除一个过期键后，会向所有从服务器发送一个DEL命令，告知从服务器删除这个过期键
  + 从服务器在执行客户端发送的命令时，即使碰到过期的键也不会删除，而是正常的继续操作
  + 从服务器只有在接到主服务器发来的DEL命令之后，才会删除过期键

  > Q&A :从服务器不会主动删除过期键，那如果查询从服务器的过期键怎么办？
  >
  > 大致操作：从节点使用逻辑时钟记录一下本该过期的Key，等待着master的del命令，被缓存的本该过期的key即使被查询也不会返回。

## 3、Redis内存淘汰策略

+ noeviction( **Redis 的默认策略**)

  > 不会淘汰任何数据，当使用的内存空间超过 `maxmemory` 值时，返回错误；

+ volatile-ttl

  > 筛选设置了过期时间的键值对，越早过期的越先被删除；

+ volatile-random

  > 筛选设置了过期时间的键值对，随机删除；

+ volatile-lru

  > 使用 `LRU` 算法筛选设置了过期时间的键值对;
  >
  > `LRU` 算法全称 `Least Recently Used`，一种常见的页面置换算法。按照「**最近最少使用**」的原则来筛选数据，筛选出最不常用的数据，而最近频繁使用的数据会留在缓存中
  >
  > **LRU算法思想：基于链表实现**
  >
  > 把所有数据组织为一个链表，链表的表头（MRU）和表尾（LRU），代表【最近常用】和【最近不常用】
  >
  > 新加入的数据和被访问的数据都移动到表头（MRU）端，如果新加入数据时，内存空间不够，则把表尾的数据删除，并把新加入的数据放入表头
  >
  > **Redis对于LRU的实现**：
  >
  > redis会记录每个数据的最近一次访问的时间戳，(由键值对数据结构RedisObject中的lru字段记录)
  >
  > 然后redis在决定淘汰数据的时候，第一次随机选出N个数据，把它们作为一个候选合集，接下来，redis在比较N个数据的lru字段，把lru字段值最小的数据从缓存中淘汰出去
  >
  > redis有一个配置参数`maxmemory-samples`就是备选数据个数
  >
  > 当再次需要淘汰数据时，redis需要挑选数据进入【第一次淘汰时创建的候选集合】
  >
  > 挑选的标准是：`能进入候选集合的数据的lru字段值必须小于候选集合中的最小lru值`

+ volatile-lfu

  > 使用 `LFU` 算法选择设置了过期时间的键值对；
  >
  > LFU缓存策略是在LRU的基础上，为每个数据增加一个计时器，来统计这个数据被访问的次数。
  >
  > 筛选规则：
  >
  > + 首先根据数据的访问次数进行筛选，把访问次数最低的淘汰出内存
  > + 再比较数据的访问时效性（LRU），把距离上一次访问时间更久的数据淘汰出内存
  >
  > LFU的具体实现：
  >
  > + redis在RedisObject结构中设置了lru字段，记录数据访问的时间戳
  > + LFU把原先的24bit的lru字段分成了两部分，ldt（16bit）表示访问的时间戳和counter（8bit）表示数据的访问次数
  >
  > 举例：假设数据A的累计访问次数是256，访问的时间戳是202208201104，count是255
  >
  > `8bit的数据记录访问次数，所以最大值只能是255`
  >
  > 由于最大值的限制，所以redis在这一方面进行了优化：
  >
  > 并不是在访问一次的时候就直接counter加1，而是采用了一个配置项的规则：
  >
  > + 每当数据被访问时，先用【计数器当时的值】乘以【配置项】(`lfu_log_factor`)，再加1，取其倒数，得到一个P值，
  > + 然后把P和一个取值范围再(0，1)之间的随机数r比大小，只有P大于1时，计数器才加1
  >
  > redis的部分源码
  >
  > ```java
  > double r = (double)rand()/RAND_MAX;
  > ...
  > double p = 1.0/(baseval*server.lfu_log_factor+1);
  > if(r<p) counter++;
  > ```
  >
  > 其中，baseval是计数器当时的值，（`计数器初始值为5，而不是0，这样可以避免数据刚被写入缓存就因为访问次数少而被立即淘汰`）
  >
  > 使用了这种规则后，可以设置不同的lfu_log_factor值，来避免counter很快的到达255
  >
  > redis官网提供了一张表，来展示lfu_log_factor再不同值时，countor到达255的时间
  >
  > ![image-20220820111419346](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220820111419346.png)
  >
  > 从刚才的表中，我们可以看到，当 `lfu_log_factor` 取值为 10 时，百、千、十万级别的访问次数对应的 counter 值已经有明显的区分了。所以，我们在应用 `LFU` 策略时，一般可以将 `lfu_log_factor` 取值为 10。
  >
  > 但是还有很多的业务场景：有些数据再短时间内被大量访问后，就不会再被访问了，这种如果再次按照访问次数来筛选的话，这些数据就会被留在缓存中，但是不会提高缓存命中率，为此：LFU还设计了一个`counter的衰减机制`
  >
  > LFU使用衰减因子配置项【lfu_decay_time】来控制访问次数的衰减
  >
  > + LFU策略会计算`当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位`
  > + LFU策略再把这个差值除以`lfu_decay_time`值，所得的结果就是counter衰减的值
  >
  > 举例：lfu_decay_time设置为1，如果数据A在N分钟内没有被访问，那么A的访问次数就要被减少N，如果lfu_decay_time的值设置的更大，那么相应的衰减值就会被减少，衰减效果减弱，所以如果业务中有短时高频访问的数据，建议把lfu_decay_time设置为1.

+ allkeys-random

  > 在所有键值对中，随机选择并删除数据；

+ allkeys-lru

  > 使用 `LRU` 算法在所有数据中进行筛选；

+ allkeys-lfu

  > 使用 `LFU` 算法在所有数据中进行筛选。

## 4、Redis持久化策略

+ RDB

  > Redis DataBase
  >
  > + 如何备份？
  >
  >   > 1、redis会单独创建一个子进程（fork主进程）进行持久化，会先将数据临时写道临时文件中，待持久化过程都结束了，再用这个临时文件替换上次持久化的文件。整个过程中，主进程不进行任何的IO操作，确保了极高的性能
  >   >
  >   > ![image-20220820141428434](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220820141428434.png)
  >
  > + 触发方式
  >
  >   > 1、自动触发
  >   >
  >   > ```shell
  >   > #save 负责触发redis的rdb持久化条件，表示20秒内数据集存在3次修改，自动触发bgsave指令
  >   > #save "" 表示不使用rdb持久化
  >   > save 20 3
  >   > 
  >   > #默认值为yes，表示：当启动了RDB之后且最后一次后台保存数据失败，redis是否停止接收数据，这会让用户意识到数据没有正确持久化到磁盘上，否则没人意识到这个情况。如果redis重启了，那么又可以重新开始接收数据了
  >   > stop-writes-on-bgsave-error:yes
  >   > 
  >   > #默认值为yes，表示：对于存储到磁盘中的快照，可以设置是否进行压缩存储，如果是，则会采用LZF算法进行压缩（会消耗CPU资源），否则不进行压缩，磁盘文件会比较大
  >   > rdbcompression:yes
  >   > 
  >   > #默认值yes，从RDB快照功能的version 5 版本开始，一个64位的CRC冗余校验编码会被放置在RDB文件的末尾，以便对整个RDB文件的完整性进行验证。这个功能大概会多损失10%左右的性能，但获得了更高的数据可靠性。所以如果您的Redis服务需要追求极致的性能，就可以将这个选项设置为no
  >   > rdbchecksum：yes
  >   > 
  >   > #快照的文件名，默认dump.rdb
  >   > dbfilename：dump.rdb
  >   > 
  >   > #快照的存放路径，这个配置项一定是一个目录，默认设置为“./”，也就是Redis服务的主目录。
  >   > dir：
  >   > ```
  >   >
  >   > 
  >   > 2、手动触发
  >   >
  >   > + save
  >   >
  >   >   > 会阻塞当前的redis服务器，执行save命令期间，redis不能执行别的命令，直到rdb过程完成为止
  >   >
  >   > + bgsave
  >   >
  >   >   > 执行bgsave，redis会在后台异步进行快照操作，快照同时还可以响应客户端请求。具体操作是redis进程执行fork操作创建子进程，rdb持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短。
  >
  > + 数据恢复
  >
  >   > 将备份文件dump.rdb移动到redis的安装目录，并启动服务即可，redis会自动加载文件数据到内存，在加载rdb文件过程中，redis服务会一直处于阻塞状态，直到载入工作完成为止
  >
  > + 优缺点
  >
  >   > 优点：
  >   > 1、RDB生成的文件是一个非常紧凑的文件，保存了redis某个时间点上的数据集，这种文件非常试合进行备份和灾难恢复
  >   >
  >   > 2、RDB的持久化过程是fork子进程的方式进行，主进程不需要IO操作
  >   >
  >   > 3、RDB恢复大数据集时的速度高于AOF
  >   >
  >   > 缺点：
  >   >
  >   > 1、RDB无法做到实时持久化，在一定间隔进行备份的话，有可能会丢失间隔时间内的数据
  >   >
  >   > 2、RDB文件使用特定的二进制格式保存，Redis版本演进过程中会有多个格式的RDB版本，存在老版本的RDB文件无法兼容新版本的RDB格式问题
  >
  > + 深入理解
  >
  >   > RDB中的核心思路是Copy-on-Write，来保证在进行快照操作的这段时间，需要压缩写入磁盘上的数据在内存中不会发生变化。在正常的快照操作中，一方面Redis主进程会fork一个新的快照进程专门来做这个事情，这样保证了Redis服务不会停止对客户端包括写请求在内的任何响应。另一方面这段时间发生的数据变化会以副本的方式存放在另一个新的内存区域，待快照操作结束后才会同步到原来的内存区域。
  >   > 

+ AOF

  > Append of File
  >
  > + 如何备份？
  >
  >   > 以日志的形式来记录每个写操作（增量操作），将Redis执行过的所有写指令保存下来，只追加文件，不改写文件。redis启动之初会读取该文件重新构造数据。
  >   >
  >   > 同步策略：
  >   >
  >   > `为了提高文件写入效率，在现代操作系统中，当用户调用write函数，将一些数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区的空间被填满或超过了指定时限后，才真正将缓冲区的数据写入到磁盘里。`
  >   >
  >   > `这样的操作虽然提高了效率，但也为数据写入带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失。为此，系统提供了fsync、fdatasync同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保写入数据的安全性。`
  >
  > + 持久化过程
  >   ![image-20220820150446431](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\image-20220820150446431.png)
  >
  >   > 1、客户端的请求写命令会被append追加到AOF缓冲区内
  >   >
  >   > 2、AOF缓冲区根据AOF持久化策略[always、everysec、no]将操作sync同步到磁盘的AOF文件中
  >   >
  >   > 3、AOF文件大小超过重写策略或者手动重写时，会对AOF文件rewrite重写，压缩AOF文件容量
  >   >
  >   > 4、Redis服务重启时，会重新load加载AOF文件中的写操作达到数据恢复的目的
  >
  > + 相关命令
  >
  >   > #AOF默认不开启
  >   >
  >   > appendonly yes
  >   >
  >   > 
  >   >
  >   > #AOF文件名 \aof文件的保存路径同RDB路径一致
  >   >
  >   > appendfilename "appendonly.aof"
  >   >
  >   > 
  >   >
  >   > #RDB和AOF同时开启，系统默认获取AOF文件的内容
  >   >
  >   > #AOF同步频率 always 每次的写入都会立即写入日志 | everysec 每秒同步一次  | no redis不主动同步,只是先把日志写到AOF文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘
  >   > appendfsync  everysec 
  >   >
  >   > 
  >   >
  >   > #aof重写期间是否同步
  >   >
  >   > no-appendfsync-on-rewrite no
  >   >
  >   >
  >   > #重写触发配置
  >   >
  >   > auto-aof-rewrite-percentage 100
  >   > auto-aof-rewrite-min-size 64mb
  >   >
  >   > #加载aof出错如何处理
  >   >
  >   > aof-load-truncated yes
  >   >
  >   > #文件重写策略
  >   >
  >   > aof-rewrite-incremental-fsync yes
  >
  > + AOF启动、恢复、修复
  >
  >   > 1、启动：启动系统加载AOF文件
  >   >
  >   > 2、异常恢复：如果遇到AOF文件损坏，通过/usr/lcoal/bin/redis-check-aof-fix appendonly.aof进行恢复，然后备份被写坏的AOF文件，重启redis进行加载数据