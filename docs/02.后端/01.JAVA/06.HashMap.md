---
title: HashMap
date: 2022-08-07 17:27:04
permalink: /pages/hashmap
categories:
  - 后端
  - JAVA
tags:
  - HashMap
author: 
  name: Coder
  link: https://github.com/zyb-github
---

# HashMap

## 1、 HashMap的数据结构

![image-20220807173233731](https://s2.loli.net/2022/08/07/7xiP923X8enwBrD.png)

## 2、Hash简介

> 哈希表（hash table，也叫散列表），能够根据key直接访问相应的值，查找算法分为两步：
>
> 1、用哈希函数将被查找的key转化为数组的一个索引，理想情况下，不同的key都会转化为不同的索引值，但是现实情况下不同的key也会转化为相同的索引值，这个就叫做碰撞冲突。可以通过拉链法或者线性探测法解决冲突
>
> 2、通过生成的索引值直接访问数据

> 哈希表是算法在时间和空间上做出权衡的经典案例，如果没有内存限制，我们可以直接将key作为数组的索引，那么所有的查找只需要访问内存一次；如果没有时间限制，我们可以使用无序数组并进行顺序查找，这样只需要很少的内存，但是话费的时间太长了，而哈希表则是在这两个极端中找到了一个平衡

### 1、哈希函数

> 假设有一个能够保存M个键值对的数组，那么我们就需要一个能够将任意key转化为该数组范围（0，M-1）内的索引的哈希函数，起码这个函数还需要满足下面的要求：
>
> 1、容易计算，并且速度快
>
> 2、计算出来的索引值最好能够均匀的分布在所有的键，避免产生太多的冲突
>
> 3、由于key的类型可能是数字、字符串，所以我们需要设计不同的哈希函数来对应不同的键，

### 2、冲突解决

> 当出现两个或者多个key哈希值相同的情况下，可以通过拉链法或者线性探测法来解决，hashMap的底层实现是基于拉链法：
>
> 大致思路：将大小为M的数组中的每个元素指向一个链表，链表中的每个节点都存储了哈希值为该元素的索引的键值对，当要查找某个元素时，首先根据哈希值找到对应的链表，然后沿着链表的顺序查找对应的key，并返回value

![image-20220807183401384](https://s2.loli.net/2022/08/07/YtDrdMwoWuBP8iq.png)

## 3、位运算

![image-20220807183706604](https://s2.loli.net/2022/08/07/8YB14KqGuvew3xL.png)

><< 左移，空位补0，被移除的高位丢弃，空缺位补0；
>
>\>> 右移，被移位的二进制最高位是0，右移后，空缺位补0；最高位是1，空缺位补1；
>
>\>>> 无符号右移，被移位的二进制最高位无论是0或者1，空缺位都用0补
>
>& 与运算，二进制位进行&运算，只有1&1是1，其余全是0
>
>｜ 或运算，二进制位进行｜运算，只有0｜0是0，其余全是1
>
>^ 异或运算，相同二进制位进行^运算，结果是0；1^1 =0;0^0=0;不相同的二进制位进行^,结果是1，1^0=1
>
>~ 取反运算，正数取反，各二进制码按补码各位取反； 负数取反，各二进制码按补码各位取反

## 4、HashMap简介

> HashMap基于哈希表的Map接口实现，以key-value的形式存储，HashMap的实现不是同步的，也就是非线程安全。 key和value都可以为null。HashMap中的映射不是有序的。
>
> JDK1.8之后，解决哈希冲突有了变化，**当链表长度大于阈值（默认为8），并且当前数组长度大于64时，此时此索引位置上的所有数据改为红黑树存储**
>
> 如果是链表长度大于阈值，但是数组长度没有大于64，此时并不会转变为红黑树，而是进行扩容，这样做的目的是因为数组比较小，尽量避开红黑树结构，这种情况下红黑树的效率比较慢，因为红黑树需要进行左旋、右旋、变色这些操作来保持平衡。同时数组长度小于64时，搜索时间相对快些。

## 5、重要的成员变量

### 1、DEFAULT_INITIAL_CAPACITY

> 默认集合初始容量：16
>
> 初始容量必须时2的n次方，根据hash表的原理，我们可以知道当向hashMap中添加一个元素时，需要根据key的哈希值去确定其在数组中的具体位置，HashMap为例存取高效，要尽量减少冲突碰撞，key的哈希值有可能是个很大的值，超过散列表的范围，因此要把它缩小到适合索引的范围，假设索引的范围处于0到n-1之间，将一个整数缩小到0到n-1之间到最常用的方法就是取模hash%n，其中n为大于2的素数。
>
> 比如hashtable初始化桶大小为11，理想情况下应该选择一个素数，但是选择一个大的素数很耗时，而在hashMap中的使用方法很巧妙，它通过hash&(length-1)来计算，当length的长度为2的n次方时，hash&(length-1)的运算结果等价于hash%length,&的运算效率也比%更高
>
> 在创建HashMap对象的时候，可以传入initialCapacity初始大小值，如果输入的大小不是2的n次方，那么底层会通过位运算得到一个离传入数字最近的一个2的幂次数
>
> 源码如下：如果cap=10
>
> ![image-20220807195211918](https://s2.loli.net/2022/08/07/xLf7SvdBjKkyElJ.png)
>
> 为什么要对cap做-1的操作？
> 	这是为了防止cap已经是2的n次方了，如果cap已经是2的n次方，又没有进行-1操作，那么得到的将会是cap的2倍，比如传入的cap是16，满足2的n次方，但是不进行-1，最终得到的值将会是32
>
> 最大容量：容量最大也就是32bit的正数，因为最后 n |= n >>> 16,最多也就是32个1，但是已经是负数了，在执行tableSizeFor之前，会对initialCapacity进行判断，如果大于MAXIMUM_CAPACITY(2 ^ 30)，则取MAXIMUM_CAPACITY，如果等于MAXIMUM_CAPACITY，则进行位运算，结果会是最大30个1，最后一步+1返回值是2^30

### 2、DEFAULT_LOAD_FACTOR

> 默认的装载因子：0.75f
>
> 用于衡量HashMap满的程度，计算HashMap实时装载因子loadFactor的方法是size/capacity, size是当前HashMap中存放键值对的数量，capacity是桶的数量，默认值是0.75f，
>
> loadFactor太大导致查找元素效率低，太小会导致数组的利用率低，存放的数据会很分散，这是空间和时间的一个平衡选择

### 3、TREEIFY_THRESHOLD

> 当桶（bucket）上的节点数大于这个值时会转化为红黑树
>
> TreeNodes占用空间时普通Node的两倍，所以只有当Bin包含足够多的节点是时，才会转化为TreeNodes，而这个是否足够多就是TREEIFY_THRESHOLD的值决定的，当bin的节点变少时，又回转化为普通的bin
>
> 数组长度大于64并且链表长度大于8就会转化为红黑树，当长度将为6就转化为普通的bin
>
> 为什么选择8这个数字？
>
> 理想情况下，随机HashCode算法下的所有bin节点分布的频率会遵循泊松分布，一个bin中链表长度达到8的概率是0.00000006，几乎是不可能事件，之所以选择8，时根据概率学决定的。

### 4、table

> 存储元素的数组 Node<K,V>[] table;

### 5、threshold

> 临界值，当实际大小（容量*负载因子）超过临界值，就会进行扩容，扩容后的容量是之前容量的两倍

## 6、put

![image-20220807202604018](https://s2.loli.net/2022/08/07/BmhvAHFwTVYxuLs.png)

> 大致流程：
>
> 1、先计算hash值判断key放在哪个桶
>
> 2、如果桶上没有碰撞冲突，则直接放入
>
> 3、如果出现冲突，则处理
>
> 4、如果桶上的数据使用的链表存储数据，调用链表的插入数据方法，然后判断是否需要转为红黑树，调用转为红黑树的方法
>
> 5、如果桶上的数据是红黑树存储，则直接调用红黑树的插入数据方法
>
> 6、如果桶中有重复的键，则替换value值
>
> 7、如果size大于阈值theshold，则进行扩容

## 7、hash算法

> 符号右移16位后的二进制进行按位异或得到最后的hash值
>
> ```java
> return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
> ```
>
> hashCode()得到的是一个32位的int类型的值，通过hashCode()的高16位异或低16位实现，如果当n的数组长度很小，假设是16的话，那么n-1就是00000000 00000000 00000000 00001111，这样的值直接和hashCode()进行按位与操作，实际上只是用了hash值的后4位，**如果hash值的高位变化很大，低位变化很小，这样就很容易造成哈希冲突**，所以这里把高低位都利用起来，从而解决了这个问题，
>
> 例如下面这个例子，hashCode的红色部分再怎么变化都没有用，从而造成哈希冲突
>
> ![image-20220807203750750](https://s2.loli.net/2022/08/07/AFrLtRglwHf975p.png)

## 8、treeifyBin

> 节点添加完成之后判断此时的节点个数是否大于`TREEIFY_THRESHOLD`临界值8，如果大于临界值并且数组大雨64，则执行转换为红黑树的代码treeifyBin
>
> ```java
>   /** 
>   * Replaces all linked nodes in bin at index for given hash unless 
>   * table is too small, in which case resizes instead. 
>   	替换指定哈希表的索引处桶中的所有链接节点，除非表太小，否则将修改大小。 
>   	Node<K,V>[] tab = tab 数组名 
>   	int hash = hash表示哈希值 
>   */    
> final void treeifyBin(Node<K,V>[] tab, int hash) {         
>   int n, index; Node<K,V> e;        
>   /* 如果当前数组为空或者数组的长度小于进行树形化的阈值(MIN_TREEIFY_CAPACITY = 64), 
>   就去扩容。而不是将节点变为红黑树。 目的：如果数组很小，那么转换红黑树，然后遍历效率要低一些。
>   这时进行扩容，那么重新计算哈希值 ，链表长度有可能就变短了，数据会放到数组中，
>   这样相对来说效率高一些。 
>   */        
>   if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY) 
>   //扩容方法            
>     resize();        
>   else if ((e = tab[index = (n - 1) & hash]) != null) { 
>     /* 
>     1）执行到这里说明哈希表中的数组长度大于阈值64，开始进行树形化 
>     2）e = tab[index = (n - 1) & hash]表示将数组中的元素取出赋值给e,
>     e是哈希表中指定位置桶里的链表节点，从第一个开始 
>     */            
>     //hd：红黑树的头结点 tl :红黑树的尾结点            
>     TreeNode<K,V> hd = null, tl = null;            
>     do {                 
>       //新创建一个树的节点，内容和当前链表节点e一致                
>       TreeNode<K,V> p = replacementTreeNode(e, null);                
>       if (tl == null)                    
>       //将新创键的p节点赋值给红黑树的头结点                    
>         hd = p;                
>       else {                     
>       /* 
>       p.prev = tl：将上一个节点p赋值给现在的p的前一个节点 tl.next = p;
>       将现在节点p作为树的尾结点的下一个节点 
>       */                    
>         p.prev = tl;                    
>         tl.next = p;                
>       }                
>       tl = p;                
>       /* 
>       e = e.next 将当前节点的下一个节点赋值给e,如果下一个节点不等于null 
>       则回到上面继续取出链表中节点转换为红黑树 
>       */            
>     } 
>     while ((e = e.next) != null);            
>     /* 
>     让桶中的第一个元素即数组中的元素指向新建的红黑树的节点，
>     以后这个桶里的元素就是红黑树 而不是链表数据结构了 
>     */            
>     if ((tab[index] = hd) != null)                
>       hd.treeify(tab);        
>   }    
> }
> ```

## 9、扩容机制

> 流程：当HashMap中的元素个数超过`capacity(数组长度默认16) * loadFactor(负载因子默认0.75`时，就会进行数组扩容，loadFactor的默认值(DEFAULT_LOAD_FACTOR)是0.75,这是一个折中的取值
>
> 也就是说默认情况下 16\*0.75 = 12，如果元素个数超过12，就会进行扩容，把数组大小扩大两倍就是16\*2=32,然后重新计算元素在数组中的位置，这是一个非常消耗性能的操作，所以如果我们已经预知mao中的元素个数，需要在构造函数中加入预期的元素个数
>
> 扩容：因为每次扩容都是翻倍，与原来计算的（n-1）&hash的结果相比，只是多了一个bit位，所以节点要么在原来的位置上，要么就被分配到**原位置+旧位置**的位置，例如 从16扩容到32的过程，具体变化如下所示
>
> ![image-20220807204940161](https://s2.loli.net/2022/08/07/QpgLIXZ95JGuUK8.png)
>
> ![](https://s2.loli.net/2022/08/07/GemxiSKWzJ8I1cC.png)
>
> 容量变为原来的2倍后，n-1的二进制数也由1111变为了11111，当容量为16时，(n-1)&hash的值都是0101，也就是十进制的5；当容量变化为32时，hash1的结果是0101，十进制的5，hash2的结果是10101，十进制的21（5+16）。所以扩容后的节点要么在原位置，要么在**原位置+旧位置**。因此，在扩充hashMap的时候，不需要重新计算hash，只需要看一下原来的hash值新增的bit是0还是1，如果是0代表索引没变，如果是1就变成了**原索引+oldCap（原位置+旧容量）**，源码中通过e.hash & oldCap进行判断。
>
> oldCap就是扩容之前的容量，在上面的例子中就是16，hash1的结果为0，表示在原位置，hash2的结果为1，表示在5+16 =21的位置
>
> 可以看一下16扩容到32点resize示意图
>
> ![image-20220807205804617](https://s2.loli.net/2022/08/07/54KUxotLY7JQnVW.png)
>
> 正是因为这种巧妙的方式，既省去了重新计算hash的时间，而且同时由于新增的bit是0还是1可以认为是随机的，在resize的过程中保证了每次rehash之后每个桶上的节点数肯定是小于等于原先桶上的节点数，保证了rehash之后不会出现更严重的哈希冲突，均匀的把之前的冲突分配到了不同的桶上
>
> ```java
> final Node<K,V>[] resize() {     
> 	//得到当前数组    
>   Node<K,V>[] oldTab = table;    
> 	//如果当前数组等于null长度返回0，否则返回当前数组的长度    
>   int oldCap = (oldTab == null) ? 0 : oldTab.length;    
> 	//当前阈值点 默认是12(16*0.75)    
>   int oldThr = threshold;    
>   int newCap, newThr = 0;    
> 	//如果老的数组长度大于0    
>   //开始计算扩容后的大小    
>   if (oldCap > 0) {         
>     // 超过最大值就不再扩充了，就只好随你碰撞去吧        
>     if (oldCap >= MAXIMUM_CAPACITY) {             
>       //修改阈值为int的最大值            
>       threshold = Integer.MAX_VALUE;            
>       return oldTab;        
>     }        
>     /* 
>     没超过最大值，就扩充为原来的2倍 1)(newCap = oldCap << 1) < MAXIMUM_CAPACITY 
>     扩大到2倍之后容量要小于最大容量 2）oldCap >= DEFAULT_INITIAL_CAPACITY 
>     原数组长度大于等于数组初始化长度16 
>     */        
>     else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY 
>              && oldCap >= DEFAULT_INITIAL_CAPACITY)            
>       //阈值扩大一倍            
>       newThr = oldThr << 1; 
>     // double threshold    
>   }    
>   //老阈值点大于0 直接赋值    
>   else if (oldThr > 0) 
>     // 老阈值赋值给新的数组长度        
>     newCap = oldThr;    
>   else { 
>     // 直接使用默认值        
>     newCap = DEFAULT_INITIAL_CAPACITY;
>     //16        
>     newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);    
>   }    
>   // 计算新的resize最大上限    
>   if (newThr == 0) {         
>     float ft = (float)newCap * loadFactor;        
>     newThr = (newCap < MAXIMUM_CAPACITY 
>               && ft < (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);    
>   }    
>   //新的阈值 默认原来是12 乘以2之后变为24    
>   threshold = newThr;    
>   //创建新的哈希表    
>   @SuppressWarnings({ "rawtypes","unchecked"})    
>   //newCap是新的数组长度32    
>   Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];    
>   table = newTab;    
>   //判断旧数组是否等于空    
>   if (oldTab != null) {         
>     // 把每个bucket都移动到新的buckets中        
>     //遍历旧的哈希表的每个桶，重新计算桶里元素的新位置        
>     for (int j = 0; j < oldCap; ++j) {             
>       Node<K,V> e;            
>       if ((e = oldTab[j]) != null) {                 
>         //原来的数据赋值为null 便于GC回收                
>         oldTab[j] = null;                
>         //判断数组是否有下一个引用                
>         if (e.next == null)                    
>           //没有下一个引用，说明不是链表，当前桶上只有一个键值对，直接插入
>           newTab[e.hash & (newCap - 1)] = e;                
>         //判断是否是红黑树                
>         else if (e instanceof TreeNode)                    
>           //说明是红黑树来处理冲突的，则调用相关方法把树分开
>           ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);                
>         else {  
>           // 采用链表处理冲突                    
>           Node<K,V> loHead = null, loTail = null;                    
>           Node<K,V> hiHead = null, hiTail = null;                    
>           Node<K,V> next;                    
>           //通过上述讲解的原理来计算节点的新位置                    
>           do {                         
>             // 原索引                        
>             next = e.next;                     	
>             //这里来判断如果等于true e这个节点在resize之后不需要移动位置 
>             if ((e.hash & oldCap) == 0) {                             
>               if (loTail == null)                                
>                 loHead = e;                            
>               else                                
>                 loTail.next = e;                            
>               loTail = e;                        
>             }                        
>             // 原索引+oldCap                        
>             else {                             
>               if (hiTail == null)                                
>                 hiHead = e;                            
>               else                                
>                 hiTail.next = e;                            
>               hiTail = e;                        
>             }                    
>           } 
>           while ((e = next) != null);                    
>           // 原索引放到bucket里                    
>           if (loTail != null) {                         
>             loTail.next = null;                        
>             newTab[j] = loHead;                   
>           }                    
>           // 原索引+oldCap放到bucket里                    
>           if (hiTail != null) {                         
>             hiTail.next = null;                        
>             newTab[j + oldCap] = hiHead;                    
>           }                
>         }            
>       }        
>     }    
>   }    
>   return newTab;
> }
> ```

## 10、线程不安全

> 1.7 头插法导致死循环、数据丢失、数据覆盖问题
>
> 1.8 导致数据覆盖，多线程同时扩容等问题
