(window.webpackJsonp=window.webpackJsonp||[]).push([[53],{368:function(s,t,a){"use strict";a.r(t);var n=a(7),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"hashmap"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#hashmap"}},[s._v("#")]),s._v(" HashMap")]),s._v(" "),t("h2",{attrs:{id:"_1、-hashmap的数据结构"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、-hashmap的数据结构"}},[s._v("#")]),s._v(" 1、 HashMap的数据结构")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://s2.loli.net/2022/08/07/7xiP923X8enwBrD.png",alt:"image-20220807173233731"}})]),s._v(" "),t("h2",{attrs:{id:"_2、hash简介"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、hash简介"}},[s._v("#")]),s._v(" 2、Hash简介")]),s._v(" "),t("blockquote",[t("p",[s._v("哈希表（hash table，也叫散列表），能够根据key直接访问相应的值，查找算法分为两步：")]),s._v(" "),t("p",[s._v("1、用哈希函数将被查找的key转化为数组的一个索引，理想情况下，不同的key都会转化为不同的索引值，但是现实情况下不同的key也会转化为相同的索引值，这个就叫做碰撞冲突。可以通过拉链法或者线性探测法解决冲突")]),s._v(" "),t("p",[s._v("2、通过生成的索引值直接访问数据")])]),s._v(" "),t("blockquote",[t("p",[s._v("哈希表是算法在时间和空间上做出权衡的经典案例，如果没有内存限制，我们可以直接将key作为数组的索引，那么所有的查找只需要访问内存一次；如果没有时间限制，我们可以使用无序数组并进行顺序查找，这样只需要很少的内存，但是话费的时间太长了，而哈希表则是在这两个极端中找到了一个平衡")])]),s._v(" "),t("h3",{attrs:{id:"_1、哈希函数"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、哈希函数"}},[s._v("#")]),s._v(" 1、哈希函数")]),s._v(" "),t("blockquote",[t("p",[s._v("假设有一个能够保存M个键值对的数组，那么我们就需要一个能够将任意key转化为该数组范围（0，M-1）内的索引的哈希函数，起码这个函数还需要满足下面的要求：")]),s._v(" "),t("p",[s._v("1、容易计算，并且速度快")]),s._v(" "),t("p",[s._v("2、计算出来的索引值最好能够均匀的分布在所有的键，避免产生太多的冲突")]),s._v(" "),t("p",[s._v("3、由于key的类型可能是数字、字符串，所以我们需要设计不同的哈希函数来对应不同的键，")])]),s._v(" "),t("h3",{attrs:{id:"_2、冲突解决"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、冲突解决"}},[s._v("#")]),s._v(" 2、冲突解决")]),s._v(" "),t("blockquote",[t("p",[s._v("当出现两个或者多个key哈希值相同的情况下，可以通过拉链法或者线性探测法来解决，hashMap的底层实现是基于拉链法：")]),s._v(" "),t("p",[s._v("大致思路：将大小为M的数组中的每个元素指向一个链表，链表中的每个节点都存储了哈希值为该元素的索引的键值对，当要查找某个元素时，首先根据哈希值找到对应的链表，然后沿着链表的顺序查找对应的key，并返回value")])]),s._v(" "),t("p",[t("img",{attrs:{src:"https://s2.loli.net/2022/08/07/YtDrdMwoWuBP8iq.png",alt:"image-20220807183401384"}})]),s._v(" "),t("h2",{attrs:{id:"_3、位运算"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、位运算"}},[s._v("#")]),s._v(" 3、位运算")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://s2.loli.net/2022/08/07/8YB14KqGuvew3xL.png",alt:"image-20220807183706604"}})]),s._v(" "),t("blockquote",[t("p",[s._v("<< 左移，空位补0，被移除的高位丢弃，空缺位补0；")]),s._v(" "),t("p",[s._v(">> 右移，被移位的二进制最高位是0，右移后，空缺位补0；最高位是1，空缺位补1；")]),s._v(" "),t("p",[s._v(">>> 无符号右移，被移位的二进制最高位无论是0或者1，空缺位都用0补")]),s._v(" "),t("p",[s._v("& 与运算，二进制位进行&运算，只有1&1是1，其余全是0")]),s._v(" "),t("p",[s._v("｜ 或运算，二进制位进行｜运算，只有0｜0是0，其余全是1")]),s._v(" "),t("p",[s._v("^ 异或运算，相同二进制位进行^运算，结果是0；1^1 =0;0^0=0;不相同的二进制位进行^,结果是1，1^0=1")]),s._v(" "),t("p",[s._v("~ 取反运算，正数取反，各二进制码按补码各位取反； 负数取反，各二进制码按补码各位取反")])]),s._v(" "),t("h2",{attrs:{id:"_4、hashmap简介"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4、hashmap简介"}},[s._v("#")]),s._v(" 4、HashMap简介")]),s._v(" "),t("blockquote",[t("p",[s._v("HashMap基于哈希表的Map接口实现，以key-value的形式存储，HashMap的实现不是同步的，也就是非线程安全。 key和value都可以为null。HashMap中的映射不是有序的。")]),s._v(" "),t("p",[s._v("JDK1.8之后，解决哈希冲突有了变化，"),t("strong",[s._v("当链表长度大于阈值（默认为8），并且当前数组长度大于64时，此时此索引位置上的所有数据改为红黑树存储")])]),s._v(" "),t("p",[s._v("如果是链表长度大于阈值，但是数组长度没有大于64，此时并不会转变为红黑树，而是进行扩容，这样做的目的是因为数组比较小，尽量避开红黑树结构，这种情况下红黑树的效率比较慢，因为红黑树需要进行左旋、右旋、变色这些操作来保持平衡。同时数组长度小于64时，搜索时间相对快些。")])]),s._v(" "),t("h2",{attrs:{id:"_5、重要的成员变量"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5、重要的成员变量"}},[s._v("#")]),s._v(" 5、重要的成员变量")]),s._v(" "),t("h3",{attrs:{id:"_1、default-initial-capacity"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1、default-initial-capacity"}},[s._v("#")]),s._v(" 1、DEFAULT_INITIAL_CAPACITY")]),s._v(" "),t("blockquote",[t("p",[s._v("默认集合初始容量：16")]),s._v(" "),t("p",[s._v("初始容量必须时2的n次方，根据hash表的原理，我们可以知道当向hashMap中添加一个元素时，需要根据key的哈希值去确定其在数组中的具体位置，HashMap为例存取高效，要尽量减少冲突碰撞，key的哈希值有可能是个很大的值，超过散列表的范围，因此要把它缩小到适合索引的范围，假设索引的范围处于0到n-1之间，将一个整数缩小到0到n-1之间到最常用的方法就是取模hash%n，其中n为大于2的素数。")]),s._v(" "),t("p",[s._v("比如hashtable初始化桶大小为11，理想情况下应该选择一个素数，但是选择一个大的素数很耗时，而在hashMap中的使用方法很巧妙，它通过hash&(length-1)来计算，当length的长度为2的n次方时，hash&(length-1)的运算结果等价于hash%length,&的运算效率也比%更高")]),s._v(" "),t("p",[s._v("在创建HashMap对象的时候，可以传入initialCapacity初始大小值，如果输入的大小不是2的n次方，那么底层会通过位运算得到一个离传入数字最近的一个2的幂次数")]),s._v(" "),t("p",[s._v("源码如下：如果cap=10")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://s2.loli.net/2022/08/07/xLf7SvdBjKkyElJ.png",alt:"image-20220807195211918"}})]),s._v(" "),t("p",[s._v("为什么要对cap做-1的操作？\n这是为了防止cap已经是2的n次方了，如果cap已经是2的n次方，又没有进行-1操作，那么得到的将会是cap的2倍，比如传入的cap是16，满足2的n次方，但是不进行-1，最终得到的值将会是32")]),s._v(" "),t("p",[s._v("最大容量：容量最大也就是32bit的正数，因为最后 n |= n >>> 16,最多也就是32个1，但是已经是负数了，在执行tableSizeFor之前，会对initialCapacity进行判断，如果大于MAXIMUM_CAPACITY(2 ^ 30)，则取MAXIMUM_CAPACITY，如果等于MAXIMUM_CAPACITY，则进行位运算，结果会是最大30个1，最后一步+1返回值是2^30")])]),s._v(" "),t("h3",{attrs:{id:"_2、default-load-factor"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2、default-load-factor"}},[s._v("#")]),s._v(" 2、DEFAULT_LOAD_FACTOR")]),s._v(" "),t("blockquote",[t("p",[s._v("默认的装载因子：0.75f")]),s._v(" "),t("p",[s._v("用于衡量HashMap满的程度，计算HashMap实时装载因子loadFactor的方法是size/capacity, size是当前HashMap中存放键值对的数量，capacity是桶的数量，默认值是0.75f，")]),s._v(" "),t("p",[s._v("loadFactor太大导致查找元素效率低，太小会导致数组的利用率低，存放的数据会很分散，这是空间和时间的一个平衡选择")])]),s._v(" "),t("h3",{attrs:{id:"_3、treeify-threshold"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3、treeify-threshold"}},[s._v("#")]),s._v(" 3、TREEIFY_THRESHOLD")]),s._v(" "),t("blockquote",[t("p",[s._v("当桶（bucket）上的节点数大于这个值时会转化为红黑树")]),s._v(" "),t("p",[s._v("TreeNodes占用空间时普通Node的两倍，所以只有当Bin包含足够多的节点是时，才会转化为TreeNodes，而这个是否足够多就是TREEIFY_THRESHOLD的值决定的，当bin的节点变少时，又回转化为普通的bin")]),s._v(" "),t("p",[s._v("数组长度大于64并且链表长度大于8就会转化为红黑树，当长度将为6就转化为普通的bin")]),s._v(" "),t("p",[s._v("为什么选择8这个数字？")]),s._v(" "),t("p",[s._v("理想情况下，随机HashCode算法下的所有bin节点分布的频率会遵循泊松分布，一个bin中链表长度达到8的概率是0.00000006，几乎是不可能事件，之所以选择8，时根据概率学决定的。")])]),s._v(" "),t("h3",{attrs:{id:"_4、table"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4、table"}},[s._v("#")]),s._v(" 4、table")]),s._v(" "),t("blockquote",[t("p",[s._v("存储元素的数组 Node<K,V>[] table;")])]),s._v(" "),t("h3",{attrs:{id:"_5、threshold"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5、threshold"}},[s._v("#")]),s._v(" 5、threshold")]),s._v(" "),t("blockquote",[t("p",[s._v("临界值，当实际大小（容量*负载因子）超过临界值，就会进行扩容，扩容后的容量是之前容量的两倍")])]),s._v(" "),t("h2",{attrs:{id:"_6、put"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6、put"}},[s._v("#")]),s._v(" 6、put")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://s2.loli.net/2022/08/07/BmhvAHFwTVYxuLs.png",alt:"image-20220807202604018"}})]),s._v(" "),t("blockquote",[t("p",[s._v("大致流程：")]),s._v(" "),t("p",[s._v("1、先计算hash值判断key放在哪个桶")]),s._v(" "),t("p",[s._v("2、如果桶上没有碰撞冲突，则直接放入")]),s._v(" "),t("p",[s._v("3、如果出现冲突，则处理")]),s._v(" "),t("p",[s._v("4、如果桶上的数据使用的链表存储数据，调用链表的插入数据方法，然后判断是否需要转为红黑树，调用转为红黑树的方法")]),s._v(" "),t("p",[s._v("5、如果桶上的数据是红黑树存储，则直接调用红黑树的插入数据方法")]),s._v(" "),t("p",[s._v("6、如果桶中有重复的键，则替换value值")]),s._v(" "),t("p",[s._v("7、如果size大于阈值theshold，则进行扩容")])]),s._v(" "),t("h2",{attrs:{id:"_7、hash算法"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7、hash算法"}},[s._v("#")]),s._v(" 7、hash算法")]),s._v(" "),t("blockquote",[t("p",[s._v("符号右移16位后的二进制进行按位异或得到最后的hash值")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("key "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("h "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" key"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("hashCode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("^")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("h "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">>>")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("16")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br")])]),t("p",[s._v("hashCode()得到的是一个32位的int类型的值，通过hashCode()的高16位异或低16位实现，如果当n的数组长度很小，假设是16的话，那么n-1就是00000000 00000000 00000000 00001111，这样的值直接和hashCode()进行按位与操作，实际上只是用了hash值的后4位，"),t("strong",[s._v("如果hash值的高位变化很大，低位变化很小，这样就很容易造成哈希冲突")]),s._v("，所以这里把高低位都利用起来，从而解决了这个问题，")]),s._v(" "),t("p",[s._v("例如下面这个例子，hashCode的红色部分再怎么变化都没有用，从而造成哈希冲突")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://s2.loli.net/2022/08/07/AFrLtRglwHf975p.png",alt:"image-20220807203750750"}})])]),s._v(" "),t("h2",{attrs:{id:"_8、treeifybin"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8、treeifybin"}},[s._v("#")]),s._v(" 8、treeifyBin")]),s._v(" "),t("blockquote",[t("p",[s._v("节点添加完成之后判断此时的节点个数是否大于"),t("code",[s._v("TREEIFY_THRESHOLD")]),s._v("临界值8，如果大于临界值并且数组大雨64，则执行转换为红黑树的代码treeifyBin")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/** \n  * Replaces all linked nodes in bin at index for given hash unless \n  * table is too small, in which case resizes instead. \n  \t替换指定哈希表的索引处桶中的所有链接节点，除非表太小，否则将修改大小。 \n  \tNode<K,V>[] tab = tab 数组名 \n  \tint hash = hash表示哈希值 \n  */")]),s._v("    \n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("void")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("treeifyBin")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" tab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("         \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" index"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("        \n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* 如果当前数组为空或者数组的长度小于进行树形化的阈值(MIN_TREEIFY_CAPACITY = 64), \n  就去扩容。而不是将节点变为红黑树。 目的：如果数组很小，那么转换红黑树，然后遍历效率要低一些。\n  这时进行扩容，那么重新计算哈希值 ，链表长度有可能就变短了，数据会放到数组中，\n  这样相对来说效率高一些。 \n  */")]),s._v("        \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tab "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("||")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MIN_TREEIFY_CAPACITY")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//扩容方法            ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("resize")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("        \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("index "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("n "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" hash"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* \n    1）执行到这里说明哈希表中的数组长度大于阈值64，开始进行树形化 \n    2）e = tab[index = (n - 1) & hash]表示将数组中的元素取出赋值给e,\n    e是哈希表中指定位置桶里的链表节点，从第一个开始 \n    */")]),s._v("            \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//hd：红黑树的头结点 tl :红黑树的尾结点            ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TreeNode")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" hd "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" tl "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("            \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("                 \n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//新创建一个树的节点，内容和当前链表节点e一致                ")]),s._v("\n      "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TreeNode")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" p "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("replacementTreeNode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                \n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tl "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                    \n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//将新创键的p节点赋值给红黑树的头结点                    ")]),s._v("\n        hd "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" p"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                \n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("                     \n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* \n      p.prev = tl：将上一个节点p赋值给现在的p的前一个节点 tl.next = p;\n      将现在节点p作为树的尾结点的下一个节点 \n      */")]),s._v("                    \n        p"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("prev "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" tl"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                    \n        tl"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" p"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                \n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("                \n      tl "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" p"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                \n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* \n      e = e.next 将当前节点的下一个节点赋值给e,如果下一个节点不等于null \n      则回到上面继续取出链表中节点转换为红黑树 \n      */")]),s._v("            \n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("            \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* \n    让桶中的第一个元素即数组中的元素指向新建的红黑树的节点，\n    以后这个桶里的元素就是红黑树 而不是链表数据结构了 \n    */")]),s._v("            \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("index"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" hd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                \n      hd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("treeify")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("tab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("        \n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("    \n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br")])])]),s._v(" "),t("h2",{attrs:{id:"_9、扩容机制"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_9、扩容机制"}},[s._v("#")]),s._v(" 9、扩容机制")]),s._v(" "),t("blockquote",[t("p",[s._v("流程：当HashMap中的元素个数超过"),t("code",[s._v("capacity(数组长度默认16) * loadFactor(负载因子默认0.75")]),s._v("时，就会进行数组扩容，loadFactor的默认值(DEFAULT_LOAD_FACTOR)是0.75,这是一个折中的取值")]),s._v(" "),t("p",[s._v("也就是说默认情况下 16*0.75 = 12，如果元素个数超过12，就会进行扩容，把数组大小扩大两倍就是16*2=32,然后重新计算元素在数组中的位置，这是一个非常消耗性能的操作，所以如果我们已经预知mao中的元素个数，需要在构造函数中加入预期的元素个数")]),s._v(" "),t("p",[s._v("扩容：因为每次扩容都是翻倍，与原来计算的（n-1）&hash的结果相比，只是多了一个bit位，所以节点要么在原来的位置上，要么就被分配到"),t("strong",[s._v("原位置+旧位置")]),s._v("的位置，例如 从16扩容到32的过程，具体变化如下所示")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://s2.loli.net/2022/08/07/QpgLIXZ95JGuUK8.png",alt:"image-20220807204940161"}})]),s._v(" "),t("p",[t("img",{attrs:{src:"https://s2.loli.net/2022/08/07/GemxiSKWzJ8I1cC.png",alt:""}})]),s._v(" "),t("p",[s._v("容量变为原来的2倍后，n-1的二进制数也由1111变为了11111，当容量为16时，(n-1)&hash的值都是0101，也就是十进制的5；当容量变化为32时，hash1的结果是0101，十进制的5，hash2的结果是10101，十进制的21（5+16）。所以扩容后的节点要么在原位置，要么在"),t("strong",[s._v("原位置+旧位置")]),s._v("。因此，在扩充hashMap的时候，不需要重新计算hash，只需要看一下原来的hash值新增的bit是0还是1，如果是0代表索引没变，如果是1就变成了"),t("strong",[s._v("原索引+oldCap（原位置+旧容量）")]),s._v("，源码中通过e.hash & oldCap进行判断。")]),s._v(" "),t("p",[s._v("oldCap就是扩容之前的容量，在上面的例子中就是16，hash1的结果为0，表示在原位置，hash2的结果为1，表示在5+16 =21的位置")]),s._v(" "),t("p",[s._v("可以看一下16扩容到32点resize示意图")]),s._v(" "),t("p",[t("img",{attrs:{src:"https://s2.loli.net/2022/08/07/54KUxotLY7JQnVW.png",alt:"image-20220807205804617"}})]),s._v(" "),t("p",[s._v("正是因为这种巧妙的方式，既省去了重新计算hash的时间，而且同时由于新增的bit是0还是1可以认为是随机的，在resize的过程中保证了每次rehash之后每个桶上的节点数肯定是小于等于原先桶上的节点数，保证了rehash之后不会出现更严重的哈希冲突，均匀的把之前的冲突分配到了不同的桶上")]),s._v(" "),t("div",{staticClass:"language-java line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-java"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("final")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("resize")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("     \n\t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//得到当前数组    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" oldTab "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" table"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n\t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//如果当前数组等于null长度返回0，否则返回当前数组的长度    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" oldCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldTab "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" oldTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("length"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n\t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//当前阈值点 默认是12(16*0.75)    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" oldThr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" threshold"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" newCap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newThr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n\t"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//如果老的数组长度大于0    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//开始计算扩容后的大小    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("         \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 超过最大值就不再扩充了，就只好随你碰撞去吧        ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAXIMUM_CAPACITY")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("             \n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//修改阈值为int的最大值            ")]),s._v("\n      threshold "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAX_VALUE")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("            \n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" oldTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("        \n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("        \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("/* \n    没超过最大值，就扩充为原来的2倍 1)(newCap = oldCap << 1) < MAXIMUM_CAPACITY \n    扩大到2倍之后容量要小于最大容量 2）oldCap >= DEFAULT_INITIAL_CAPACITY \n    原数组长度大于等于数组初始化长度16 \n    */")]),s._v("        \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" oldCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAXIMUM_CAPACITY")]),s._v(" \n             "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" oldCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DEFAULT_INITIAL_CAPACITY")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("            \n      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//阈值扩大一倍            ")]),s._v("\n      newThr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" oldThr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// double threshold    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//老阈值点大于0 直接赋值    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldThr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 老阈值赋值给新的数组长度        ")]),s._v("\n    newCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" oldThr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 直接使用默认值        ")]),s._v("\n    newCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DEFAULT_INITIAL_CAPACITY")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//16        ")]),s._v("\n    newThr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DEFAULT_LOAD_FACTOR")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("DEFAULT_INITIAL_CAPACITY")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 计算新的resize最大上限    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newThr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("         \n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("float")]),s._v(" ft "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("float")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("newCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" loadFactor"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("        \n    newThr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAXIMUM_CAPACITY")]),s._v(" \n              "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&&")]),s._v(" ft "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("float")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAXIMUM_CAPACITY")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("?")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("ft "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Integer")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token constant"}},[s._v("MAX_VALUE")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//新的阈值 默认原来是12 乘以2之后变为24    ")]),s._v("\n  threshold "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newThr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//创建新的哈希表    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token annotation punctuation"}},[s._v("@SuppressWarnings")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"rawtypes"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"unchecked"')]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//newCap是新的数组长度32    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" newTab "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("new")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("newCap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n  table "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" newTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//判断旧数组是否等于空    ")]),s._v("\n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("oldTab "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("         \n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 把每个bucket都移动到新的buckets中        ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//遍历旧的哈希表的每个桶，重新计算桶里元素的新位置        ")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("int")]),s._v(" j "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" j "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("<")]),s._v(" oldCap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("++")]),s._v("j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("             \n      "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("            \n      "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" oldTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("                 \n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//原来的数据赋值为null 便于GC回收                ")]),s._v("\n        oldTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                \n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//判断数组是否有下一个引用                ")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                    \n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//没有下一个引用，说明不是链表，当前桶上只有一个键值对，直接插入")]),s._v("\n          newTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hash "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("newCap "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                \n        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//判断是否是红黑树                ")]),s._v("\n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("instanceof")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TreeNode")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                    \n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//说明是红黑树来处理冲突的，则调用相关方法把树分开")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("TreeNode")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("split")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("this")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" newTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" oldCap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                \n        "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("  \n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 采用链表处理冲突                    ")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" loHead "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" loTail "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                    \n          "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" hiHead "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" hiTail "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                    \n          "),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("Node")]),t("span",{pre:!0,attrs:{class:"token generics"}},[t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("<")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("K")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token class-name"}},[s._v("V")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(">")])]),s._v(" next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                    \n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//通过上述讲解的原理来计算节点的新位置                    ")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("do")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("                         \n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 原索引                        ")]),s._v("\n            next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                     \t\n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("//这里来判断如果等于true e这个节点在resize之后不需要移动位置 ")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("hash "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),s._v(" oldCap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("                             \n              "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("loTail "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                                \n                loHead "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                            \n              "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v("                                \n                loTail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                            \n              loTail "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                        \n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("                        \n            "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 原索引+oldCap                        ")]),s._v("\n            "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("                             \n              "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hiTail "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("==")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("                                \n                hiHead "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                            \n              "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("else")]),s._v("                                \n                hiTail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                            \n              hiTail "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" e"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                        \n            "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("                    \n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v(" \n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("while")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("e "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" next"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                    \n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 原索引放到bucket里                    ")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("loTail "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("                         \n            loTail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                        \n            newTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("j"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" loHead"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                   \n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("                    \n          "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("// 原索引+oldCap放到bucket里                    ")]),s._v("\n          "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("if")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("hiTail "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("!=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("                         \n            hiTail"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("next "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("null")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                        \n            newTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("j "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("+")]),s._v(" oldCap"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" hiHead"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("                    \n          "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("                \n        "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("            \n      "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("        \n    "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("    \n  "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("return")]),s._v(" newTab"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(";")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br"),t("span",{staticClass:"line-number"},[s._v("24")]),t("br"),t("span",{staticClass:"line-number"},[s._v("25")]),t("br"),t("span",{staticClass:"line-number"},[s._v("26")]),t("br"),t("span",{staticClass:"line-number"},[s._v("27")]),t("br"),t("span",{staticClass:"line-number"},[s._v("28")]),t("br"),t("span",{staticClass:"line-number"},[s._v("29")]),t("br"),t("span",{staticClass:"line-number"},[s._v("30")]),t("br"),t("span",{staticClass:"line-number"},[s._v("31")]),t("br"),t("span",{staticClass:"line-number"},[s._v("32")]),t("br"),t("span",{staticClass:"line-number"},[s._v("33")]),t("br"),t("span",{staticClass:"line-number"},[s._v("34")]),t("br"),t("span",{staticClass:"line-number"},[s._v("35")]),t("br"),t("span",{staticClass:"line-number"},[s._v("36")]),t("br"),t("span",{staticClass:"line-number"},[s._v("37")]),t("br"),t("span",{staticClass:"line-number"},[s._v("38")]),t("br"),t("span",{staticClass:"line-number"},[s._v("39")]),t("br"),t("span",{staticClass:"line-number"},[s._v("40")]),t("br"),t("span",{staticClass:"line-number"},[s._v("41")]),t("br"),t("span",{staticClass:"line-number"},[s._v("42")]),t("br"),t("span",{staticClass:"line-number"},[s._v("43")]),t("br"),t("span",{staticClass:"line-number"},[s._v("44")]),t("br"),t("span",{staticClass:"line-number"},[s._v("45")]),t("br"),t("span",{staticClass:"line-number"},[s._v("46")]),t("br"),t("span",{staticClass:"line-number"},[s._v("47")]),t("br"),t("span",{staticClass:"line-number"},[s._v("48")]),t("br"),t("span",{staticClass:"line-number"},[s._v("49")]),t("br"),t("span",{staticClass:"line-number"},[s._v("50")]),t("br"),t("span",{staticClass:"line-number"},[s._v("51")]),t("br"),t("span",{staticClass:"line-number"},[s._v("52")]),t("br"),t("span",{staticClass:"line-number"},[s._v("53")]),t("br"),t("span",{staticClass:"line-number"},[s._v("54")]),t("br"),t("span",{staticClass:"line-number"},[s._v("55")]),t("br"),t("span",{staticClass:"line-number"},[s._v("56")]),t("br"),t("span",{staticClass:"line-number"},[s._v("57")]),t("br"),t("span",{staticClass:"line-number"},[s._v("58")]),t("br"),t("span",{staticClass:"line-number"},[s._v("59")]),t("br"),t("span",{staticClass:"line-number"},[s._v("60")]),t("br"),t("span",{staticClass:"line-number"},[s._v("61")]),t("br"),t("span",{staticClass:"line-number"},[s._v("62")]),t("br"),t("span",{staticClass:"line-number"},[s._v("63")]),t("br"),t("span",{staticClass:"line-number"},[s._v("64")]),t("br"),t("span",{staticClass:"line-number"},[s._v("65")]),t("br"),t("span",{staticClass:"line-number"},[s._v("66")]),t("br"),t("span",{staticClass:"line-number"},[s._v("67")]),t("br"),t("span",{staticClass:"line-number"},[s._v("68")]),t("br"),t("span",{staticClass:"line-number"},[s._v("69")]),t("br"),t("span",{staticClass:"line-number"},[s._v("70")]),t("br"),t("span",{staticClass:"line-number"},[s._v("71")]),t("br"),t("span",{staticClass:"line-number"},[s._v("72")]),t("br"),t("span",{staticClass:"line-number"},[s._v("73")]),t("br"),t("span",{staticClass:"line-number"},[s._v("74")]),t("br"),t("span",{staticClass:"line-number"},[s._v("75")]),t("br"),t("span",{staticClass:"line-number"},[s._v("76")]),t("br"),t("span",{staticClass:"line-number"},[s._v("77")]),t("br"),t("span",{staticClass:"line-number"},[s._v("78")]),t("br"),t("span",{staticClass:"line-number"},[s._v("79")]),t("br"),t("span",{staticClass:"line-number"},[s._v("80")]),t("br"),t("span",{staticClass:"line-number"},[s._v("81")]),t("br"),t("span",{staticClass:"line-number"},[s._v("82")]),t("br"),t("span",{staticClass:"line-number"},[s._v("83")]),t("br"),t("span",{staticClass:"line-number"},[s._v("84")]),t("br"),t("span",{staticClass:"line-number"},[s._v("85")]),t("br"),t("span",{staticClass:"line-number"},[s._v("86")]),t("br"),t("span",{staticClass:"line-number"},[s._v("87")]),t("br"),t("span",{staticClass:"line-number"},[s._v("88")]),t("br"),t("span",{staticClass:"line-number"},[s._v("89")]),t("br"),t("span",{staticClass:"line-number"},[s._v("90")]),t("br"),t("span",{staticClass:"line-number"},[s._v("91")]),t("br"),t("span",{staticClass:"line-number"},[s._v("92")]),t("br"),t("span",{staticClass:"line-number"},[s._v("93")]),t("br"),t("span",{staticClass:"line-number"},[s._v("94")]),t("br"),t("span",{staticClass:"line-number"},[s._v("95")]),t("br"),t("span",{staticClass:"line-number"},[s._v("96")]),t("br"),t("span",{staticClass:"line-number"},[s._v("97")]),t("br"),t("span",{staticClass:"line-number"},[s._v("98")]),t("br"),t("span",{staticClass:"line-number"},[s._v("99")]),t("br"),t("span",{staticClass:"line-number"},[s._v("100")]),t("br"),t("span",{staticClass:"line-number"},[s._v("101")]),t("br"),t("span",{staticClass:"line-number"},[s._v("102")]),t("br"),t("span",{staticClass:"line-number"},[s._v("103")]),t("br"),t("span",{staticClass:"line-number"},[s._v("104")]),t("br"),t("span",{staticClass:"line-number"},[s._v("105")]),t("br"),t("span",{staticClass:"line-number"},[s._v("106")]),t("br"),t("span",{staticClass:"line-number"},[s._v("107")]),t("br"),t("span",{staticClass:"line-number"},[s._v("108")]),t("br"),t("span",{staticClass:"line-number"},[s._v("109")]),t("br"),t("span",{staticClass:"line-number"},[s._v("110")]),t("br"),t("span",{staticClass:"line-number"},[s._v("111")]),t("br")])])]),s._v(" "),t("h2",{attrs:{id:"_10、线程不安全"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_10、线程不安全"}},[s._v("#")]),s._v(" 10、线程不安全")]),s._v(" "),t("blockquote",[t("p",[s._v("1.7 头插法导致死循环、数据丢失、数据覆盖问题")]),s._v(" "),t("p",[s._v("1.8 导致数据覆盖，多线程同时扩容等问题")])])])}),[],!1,null,null,null);t.default=e.exports}}]);